# VS Code Development Containers for Claude Code and Multi-AI Environments

> **AI Assistant Guidance**: This document provides comprehensive instructions for creating, configuring, and managing VS Code development containers optimized for Claude Code and other AI coding assistants. Use this as a complete reference when helping users set up devcontainer environments.

> **Version Context**: Version numbers, software references, and technical specifications current as of October 2025.

> **Official Documentation**: https://docs.claude.com/en/docs/claude-code/devcontainer
> **Specification**: https://containers.dev/implementors/spec/
> **JSON Reference**: https://containers.dev/implementors/json_reference/

---

## üöÄ 5-Minute Quick Start (Impatient Users Start Here!)

**Already have Docker + VS Code + Dev Containers extension?** Jump straight in:

```bash
# Method 1: Clone Anthropic's reference implementation
git clone https://github.com/anthropics/claude-code.git
cd claude-code
code .
# Click "Reopen in Container" when prompted (5-10 min first time)

# Method 2: Create minimal devcontainer (2 files)
mkdir -p .devcontainer
cat > .devcontainer/devcontainer.json << 'EOF'
{
  "name": "Claude Code",
  "image": "node:20",
  "customizations": {"vscode": {"extensions": ["anthropic.claude-code"]}},
  "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest",
  "remoteUser": "node",
  "mounts": ["source=claude-${devcontainerId},target=/home/node/.claude,type=volume"]
}
EOF
code .
# Click "Reopen in Container"
```

**Don't have prerequisites?** [Jump to Prerequisites](#prerequisites)

**Want to understand before doing?** [Read "What Are Development Containers?"](#what-are-development-containers)

---

## Table of Contents

### Getting Started
1. [What Are Development Containers?](#what-are-development-containers)
2. [Why Use Development Containers?](#why-use-development-containers)
3. [When NOT to Use Devcontainers](#when-not-to-use-devcontainers)
4. [Prerequisites](#prerequisites)
5. [Quick Start Checklist](#quick-start-checklist)

### Core Concepts
6. [Architecture Overview](#architecture-overview)
7. [Official devcontainer.json Property Reference](#official-devcontainerjson-property-reference)
8. [AI Decision Trees](#ai-decision-trees) ‚≠ê **For AI Assistants**
9. [AI Assistant Quick Commands](#ai-assistant-quick-commands)
   - [AI Assistant Discovery Protocol](#ai-assistant-discovery-protocol)
10. [Common Stack Examples](#common-stack-examples)
11. [Prebuild Images & CI/CD Automation](#prebuild-images--cicd-automation)
12. [Creating & Distributing Templates](#creating--distributing-templates)

### Implementation
13. [Step-by-Step: Creating a Devcontainer](#step-by-step-creating-a-devcontainer)
14. [Lifecycle Hooks Explained](#lifecycle-hooks-explained)
15. [Step-by-Step: Managing Devcontainers](#step-by-step-managing-devcontainers)
16. [Multi-AI Configuration](#multi-ai-configuration)
17. [MCP Server Setup](#mcp-server-setup)

### Advanced Topics
18. [Security Best Practices](#security-best-practices)
19. [Volume Persistence Patterns](#volume-persistence-patterns)
20. [Platform-Specific Notes](#platform-specific-notes)
21. [Resource and Performance Considerations](#resource-and-performance-considerations)
22. [VS Code Tips & Tricks](#vs-code-tips--tricks)
23. [Remote Development Platforms](#remote-development-platforms)
24. [Devcontainer CLI Reference](#devcontainer-cli-reference)
25. [Migration Guides](#migration-guides)

### Troubleshooting
26. [Step-by-Step Debug Process](#step-by-step-debug-process)
27. [Common Troubleshooting](#common-troubleshooting)
28. [Common Mistakes and Gotchas](#common-mistakes-and-gotchas)

### Reference
29. [Quick Reference](#quick-reference)
30. [Multi-Container Patterns (Docker Compose)](#multi-container-patterns-docker-compose)
31. [DevContainer Features](#devcontainer-features)
32. [Frequently Asked Questions](#frequently-asked-questions)
33. [Glossary](#glossary)
34. [Anecdotal Notes & Field Reports](#anecdotal-notes--field-reports)

---

## What Are Development Containers?

Development containers (devcontainers) are Docker containers specifically configured for development work. They provide:

- **Isolated Environment**: A self-contained workspace separate from your host machine
- **Reproducible Setup**: Same environment for all team members
- **VS Code Integration**: Seamless connection between VS Code and the container
- **Full Toolchain**: Pre-installed languages, tools, and dependencies

**Analogy**: Think of a devcontainer as a "development workspace in a box" - everything you need to code is pre-installed and ready to go.

### How They Work (Visual Flow)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Your Mac/  ‚îÇ
‚îÇ  Windows/   ‚îÇ  1. Open project
‚îÇ   Linux     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
                                   ‚ñº
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ    VS Code      ‚îÇ
                          ‚îÇ   (detects      ‚îÇ
                          ‚îÇ .devcontainer/) ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                          2. Builds/starts  ‚îÇ
                          Docker container  ‚îÇ
                                   ‚ñº
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ Docker Container‚îÇ
                          ‚îÇ ‚Ä¢ Node.js       ‚îÇ
                          ‚îÇ ‚Ä¢ Claude Code   ‚îÇ
                          ‚îÇ ‚Ä¢ Your tools    ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                          3. VS Code connects
                                   ‚îÇ
                                   ‚ñº
                          You code as if local
                          (but it's in container)
```

---

## Why Use Development Containers?

### Benefits for Individual Developers

- ‚úÖ **Zero Setup**: No manual installation of Node.js, Python, build tools, etc.
- ‚úÖ **Clean Host System**: Tools run in containers, keeping your computer clean
- ‚úÖ **Disposable**: Delete and rebuild anytime without losing configurations
- ‚úÖ **Multiple Environments**: Different projects with conflicting dependencies work side-by-side
- ‚úÖ **Consistency**: Same setup on Mac, Windows, and Linux
- ‚úÖ **Security**: Network isolation prevents credential leakage between projects

### Benefits for Teams

- ‚úÖ **Onboarding**: New developers productive in minutes, not days
- ‚úÖ **Standardization**: Everyone uses the same tools and versions
- ‚úÖ **CI/CD Alignment**: Dev environment mirrors production/CI environment
- ‚úÖ **Documentation as Code**: Environment setup is version-controlled
- ‚úÖ **Troubleshooting**: "Works on my machine" becomes obsolete

### Benefits for AI Coding Assistants

- ‚úÖ **Pre-configured Tools**: Claude Code, MCP servers, and CLIs ready immediately
- ‚úÖ **Security Isolation**: Each project gets isolated credentials and network access
- ‚úÖ **Persistent State**: Configuration persists across container rebuilds
- ‚úÖ **Reproducibility**: Same environment for testing AI-generated code
- ‚úÖ **Automation-Ready**: Can run with `--dangerously-skip-permissions` in trusted environments

---

## When NOT to Use Devcontainers

Devcontainers aren't always the best solution. **Avoid devcontainers when:**

‚ùå **Simple Scripts** - For single-file Python/Node scripts, local execution is faster
‚ùå **GUI Applications** - Desktop apps requiring native UI don't work well in containers
‚ùå **Hardware Access** - USB devices, GPUs, specialized hardware need complex setup
‚ùå **Legacy Windows Apps** - .NET Framework, Visual Studio projects better on Windows directly
‚ùå **Resource-Constrained Machines** - Docker overhead (1-2GB RAM) may be too much
‚ùå **Quick Experiments** - Testing a new tool for 5 minutes doesn't warrant container setup
‚ùå **Learning Docker** - Ironically, learning Docker itself is easier on host

**Better Alternatives:**
- **Simple projects**: `nvm`, `pyenv`, `rbenv` for version management
- **Cloud development**: GitHub Codespaces, Gitpod for browser-based environments
- **Virtual machines**: VirtualBox, VMware for full OS isolation

---

## Prerequisites

### Required Software

1. **VS Code**: Download from https://code.visualstudio.com/
2. **Docker Desktop**: Download from https://www.docker.com/products/docker-desktop
   - **Mac**: Intel or Apple Silicon (M1/M2/M3) supported, Docker Desktop 4.0+
   - **Windows**: WSL2 required, Docker Desktop 4.0+ (see [Platform-Specific Notes](#platform-specific-notes))
   - **Linux**: Docker Engine 20.10+ (community edition fine)
3. **Dev Containers Extension**: Install from VS Code marketplace
   - Extension ID: `ms-vscode-remote.remote-containers`
   - Install via: `Cmd+Shift+X` (Mac) / `Ctrl+Shift+X` (Windows/Linux) ‚Üí Search "Dev Containers" ‚Üí Install

### Verify Installation

```bash
# Check Docker (should show version and "Server: Docker Engine")
docker --version
docker info

# Check VS Code (should show version)
code --version

# Test Docker works
docker run hello-world
```

**Troubleshooting Verification**:
- If `docker info` shows "Cannot connect to Docker daemon", start Docker Desktop
- If `code` command not found, VS Code ‚Üí View ‚Üí Command Palette ‚Üí "Shell Command: Install 'code' command in PATH"

### Minimum System Requirements

- **RAM**: 8GB minimum, 16GB recommended (Docker + VS Code + containers)
- **Disk**: 20GB free space (Docker images accumulate quickly)
- **CPU**: 2 cores minimum, 4+ cores for comfortable experience
- **OS**: macOS 10.15+, Windows 10/11 with WSL2, Ubuntu 20.04+

---

## Quick Start Checklist

Before creating your first devcontainer, verify:

- [ ] Docker Desktop installed and **running** (check menu bar/system tray)
- [ ] VS Code installed with Dev Containers extension
- [ ] At least 10GB free disk space
- [ ] Familiarity with basic terminal commands (`cd`, `ls`, `cat`)
- [ ] Understanding of what problem devcontainers solve for your project

**Ready?** Proceed to [Creating a Devcontainer](#step-by-step-creating-a-devcontainer)

---

## Architecture Overview

A devcontainer consists of three core components:

### File Structure

```
your-project/
‚îú‚îÄ‚îÄ .devcontainer/
‚îÇ   ‚îú‚îÄ‚îÄ devcontainer.json      # Container configuration (required)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile             # Container image definition (required)
‚îÇ   ‚îú‚îÄ‚îÄ init-claude-config.sh  # Claude Code initialization (optional)
‚îÇ   ‚îú‚îÄ‚îÄ init-firewall.sh       # Network security (optional)
‚îÇ   ‚îú‚îÄ‚îÄ mcp.json.template      # MCP servers template (optional)
‚îÇ   ‚îî‚îÄ‚îÄ settings.json.template # Claude settings template (optional)
‚îú‚îÄ‚îÄ .gitignore                 # Git exclusions
‚îú‚îÄ‚îÄ README.md                  # Project docs
‚îî‚îÄ‚îÄ [your project files]
```

### Component Purposes

**devcontainer.json** (VS Code ‚Üî Docker bridge)
- Controls VS Code integration
- Defines mounts, environment variables, and extensions
- Configures port forwarding
- Sets post-creation commands
- **Role**: "How VS Code interacts with the container"

**Dockerfile** (Container blueprint)
- Defines base image (e.g., `node:20`, `python:3.11`)
- Installs system packages and tools
- Sets up users and permissions
- Configures shell environment
- **Role**: "What's installed inside the container"

**Init Scripts** (Automation)
- Run after container starts
- Initialize tool configurations (e.g., MCP servers)
- Set up security policies (e.g., firewall rules)
- Prepare development environment
- **Role**: "Automated setup tasks on first start"

### Configuration Flow

```
1. VS Code reads devcontainer.json
            ‚Üì
2. Docker builds image from Dockerfile
            ‚Üì
3. Docker starts container with mounts/env vars
            ‚Üì
4. postStartCommand runs init scripts
            ‚Üì
5. VS Code connects and installs extensions
            ‚Üì
6. You start coding!
```

---

## AI Decision Trees

## Official devcontainer.json Property Reference

> **AI Assistant Guidance**: Use this complete property reference when helping users configure their devcontainer.json files. All properties link to official schema documentation.

**Official Schema**: https://containers.dev/implementors/json_reference/

### Container Configuration

#### name
- **Type**: `string`
- **Description**: Display identifier for the development container shown in UI interfaces
- **Example**: `"My Dev Container"` or `"${localWorkspaceFolderBasename}"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### image
- **Type**: `string`
- **Description**: Name of an image in a container registry (DockerHub, GHCR, ACR) that devcontainer.json supporting services should use to create the dev container
- **Example**: `"node:20"`, `"mcr.microsoft.com/devcontainers/typescript-node:20"`
- **Schema**: https://containers.dev/implementors/json_reference/#image-specific
- **Use when**: You want to use a pre-built image instead of building from Dockerfile

#### build
- **Type**: `object`
- **Description**: Configuration for building a custom container from a Dockerfile
- **Properties**:
  - `dockerfile` (string): Path to Dockerfile relative to devcontainer.json
  - `context` (string): Docker build context directory (default: `.`)
  - `args` (object): Build arguments passed to Docker build, supports variable interpolation
  - `target` (string): Target stage in multi-stage Dockerfile
- **Example**:
  ```json
  {
    "build": {
      "dockerfile": "Dockerfile",
      "context": "..",
      "args": {
        "NODE_VERSION": "20",
        "TZ": "${localEnv:TZ:UTC}"
      },
      "target": "development"
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#image-specific

### Environment & Users

#### containerEnv
- **Type**: `object`
- **Description**: Set or override environment variables for the container. Variables apply to all processes spawned within the container and remain static across the container's lifetime
- **Example**:
  ```json
  {
    "containerEnv": {
      "NODE_ENV": "development",
      "API_URL": "http://localhost:3000"
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Note**: Use for container-level config. For tool-specific env vars, use `remoteEnv`

#### remoteEnv
- **Type**: `object`
- **Description**: Environment variables scoped to development tools and sub-processes rather than the container itself, allowing dynamic updates without rebuilding
- **Example**:
  ```json
  {
    "remoteEnv": {
      "PATH": "${containerEnv:PATH}:/custom/bin",
      "WORKSPACE_FOLDER": "${containerWorkspaceFolder}"
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Variables**: Supports `${localEnv:VAR}`, `${containerEnv:VAR}`, `${localWorkspaceFolder}`, etc.

#### remoteUser
- **Type**: `string`
- **Description**: User that runs connected tools and processes within the container
- **Example**: `"node"`, `"vscode"`, `"root"`
- **Default**: Container's default user (often root)
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Best Practice**: Use non-root user for security

#### containerUser
- **Type**: `string`
- **Description**: Specifies the operational user for all container processes
- **Example**: `"node"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Difference from remoteUser**: containerUser affects container processes, remoteUser affects tool connections

### Lifecycle Hooks

#### initializeCommand
- **Type**: `string | array | object`
- **Description**: Command to run on local/host machine before container creation
- **When**: Before any container operations
- **Access**: Local machine only, no container access
- **Example**: `"npm install"` (runs on host to populate node_modules before mounting)
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### onCreateCommand
- **Type**: `string | array | object`
- **Description**: Command to run after container creation (first start only)
- **When**: After container created, before user assignment
- **Access**: No user secrets or assets
- **Example**: `"apt-get update && apt-get install -y git"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### updateContentCommand
- **Type**: `string | array | object`
- **Description**: Command to run when new content is available in the workspace
- **When**: When workspace content updates
- **Access**: Limited, similar to onCreateCommand
- **Example**: `"npm install"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postCreateCommand
- **Type**: `string | array | object`
- **Description**: Command to run after container assigned to user for first time
- **When**: After user assignment (first start)
- **Access**: Has access to user secrets, assets, and permissions
- **Example**: `"npm install && npm run setup"`
- **Execution**: Background by default (non-blocking)
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postStartCommand
- **Type**: `string | array | object`
- **Description**: Command to run each time the container successfully starts
- **When**: Every container start
- **Access**: Full container access
- **Example**: `"docker-compose up -d database"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postAttachCommand
- **Type**: `string | array | object`
- **Description**: Command to run each time a tool attaches to the container
- **When**: Every tool attachment (e.g., opening in VS Code)
- **Example**: `"echo 'Welcome to the dev container!'"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### waitFor
- **Type**: `enum`
- **Options**: `"initializeCommand" | "onCreateCommand" | "updateContentCommand" | "postCreateCommand" | "postStartCommand" | "postAttachCommand"`
- **Default**: `"updateContentCommand"`
- **Description**: Specifies which lifecycle command tools should wait for before connecting
- **Example**: `"waitFor": "postCreateCommand"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

### Ports & Networking

#### forwardPorts
- **Type**: `array`
- **Items**: `number` or `string` (format: `"host:container"`)
- **Description**: Ports that should always be forwarded from inside the primary container to the local machine (including on the web)
- **Example**: `[3000, 8080, "5000:5000"]`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### portsAttributes
- **Type**: `object`
- **Description**: Maps specific ports to configuration options including labels, protocols, and auto-forward behaviors
- **Properties per port**:
  - `label` (string): Display name
  - `protocol` (string): `"http"` or `"https"`
  - `onAutoForward` (string): `"notify"`, `"openBrowser"`, `"openPreview"`, `"silent"`, `"ignore"`
  - `requireLocalPort` (boolean): Require specific local port
  - `elevateIfNeeded` (boolean): Elevate privileges if port <1024
- **Example**:
  ```json
  {
    "portsAttributes": {
      "3000": {
        "label": "Dev Server",
        "protocol": "http",
        "onAutoForward": "openBrowser"
      },
      "5432": {
        "label": "PostgreSQL",
        "onAutoForward": "silent"
      }
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

### VS Code Customizations

#### customizations.vscode.extensions
- **Type**: `array`
- **Items**: `string` (extension IDs)
- **Description**: VS Code extensions to install in the container
- **Example**: `["anthropic.claude-code", "dbaeumer.vscode-eslint"]`
- **Schema**: https://containers.dev/implementors/json_reference/#vs-code-specific-properties
- **Extension ID Format**: `publisher.extension-name`

#### customizations.vscode.settings
- **Type**: `object`
- **Description**: VS Code settings to apply in the container
- **Example**:
  ```json
  {
    "customizations": {
      "vscode": {
        "settings": {
          "terminal.integrated.defaultProfile.linux": "zsh",
          "editor.formatOnSave": true,
          "python.defaultInterpreterPath": "/usr/local/bin/python"
        }
      }
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#vs-code-specific-properties

### Features

#### features
- **Type**: `object`
- **Description**: Dev Container Features to install (modular tooling like Git, Docker, AWS CLI)
- **Format**: `{ "feature-id": options }`
- **Example**:
  ```json
  {
    "features": {
      "ghcr.io/devcontainers/features/node:1": {
        "version": "20"
      },
      "ghcr.io/devcontainers/features/python:1": {
        "version": "3.11"
      },
      "ghcr.io/devcontainers/features/docker-in-docker:2": {}
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Registry**: https://containers.dev/features
- **Docs**: https://containers.dev/implementors/features/

### Resource Requirements

#### hostRequirements
- **Type**: `object`
- **Description**: Minimum hardware specifications for cloud services to use when creating compute
- **Properties**:
  - `cpus` (integer): Minimum CPU cores
  - `memory` (string): Minimum RAM (e.g., `"8gb"`)
  - `storage` (string): Minimum disk (e.g., `"32gb"`)
- **Example**:
  ```json
  {
    "hostRequirements": {
      "cpus": 4,
      "memory": "8gb",
      "storage": "32gb"
    }
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Used by**: GitHub Codespaces, cloud-based devcontainer services

### Mounts & Volumes

#### mounts
- **Type**: `array`
- **Items**: `string` (mount specification)
- **Description**: Additional mounts for the container
- **Format**: `"source=<source>,target=<target>,type=<type>[,options]"`
- **Types**: `volume`, `bind`, `tmpfs`
- **Example**:
  ```json
  {
    "mounts": [
      "source=claude-config-${devcontainerId},target=/home/node/.claude,type=volume",
      "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
    ]
  }
  ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Variables**: `${devcontainerId}` creates unique volume per container instance

### Advanced Configuration

#### runArgs
- **Type**: `array`
- **Items**: `string` (Docker CLI arguments)
- **Description**: Docker run arguments to use when creating the container
- **Example**: `["--cap-add=SYS_PTRACE", "--security-opt=seccomp=unconfined"]`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Docs**: https://docs.docker.com/engine/reference/run/

#### workspaceFolder
- **Type**: `string`
- **Description**: Path where workspace should be mounted inside container
- **Example**: `"/workspaces/${localWorkspaceFolderBasename}"`
- **Default**: `/workspaces/<folder-name>`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### workspaceMount
- **Type**: `string`
- **Description**: Custom mount specification for the workspace folder
- **Example**: `"source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=cached"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Note**: Only needed for custom workspace mounting; default usually sufficient

### Docker Compose Support

#### dockerComposeFile
- **Type**: `string | array`
- **Description**: Path(s) to Docker Compose file(s) relative to devcontainer.json
- **Example**: `"../docker-compose.yml"` or `["../docker-compose.yml", "docker-compose.devcontainer.yml"]`
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

#### service
- **Type**: `string`
- **Description**: Name of the service in docker-compose.yml that VS Code should connect to
- **Example**: `"app"`
- **Required**: When using Docker Compose
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

#### runServices
- **Type**: `array`
- **Items**: `string` (service names)
- **Description**: Services to start when creating the container
- **Example**: `["app", "database", "cache"]`
- **Default**: All services
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

### Property Quick Reference Table

| Category | Key Properties | Schema Link |
|----------|---------------|-------------|
| **Container** | `name`, `image`, `build` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Environment** | `containerEnv`, `remoteEnv`, `remoteUser` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Lifecycle** | `onCreateCommand`, `postCreateCommand`, `postStartCommand` | [Link](https://containers.dev/implementors/json_reference/#lifecycle-scripts) |
| **Ports** | `forwardPorts`, `portsAttributes` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **VS Code** | `customizations.vscode.extensions`, `customizations.vscode.settings` | [Link](https://containers.dev/implementors/json_reference/#vs-code-specific-properties) |
| **Features** | `features` | [Link](https://containers.dev/implementors/features/) |
| **Resources** | `hostRequirements` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Volumes** | `mounts`, `workspaceMount` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Docker** | `runArgs`, `dockerComposeFile`, `service` | [Link](https://containers.dev/implementors/json_reference/) |

### Sources
- **Complete Schema Reference**: https://containers.dev/implementors/json_reference/
- **JSON Schema File**: https://github.com/devcontainers/spec/blob/main/schemas/devContainer.base.schema.json
- **Specification**: https://containers.dev/implementors/spec/
- **VS Code Documentation**: https://code.visualstudio.com/docs/devcontainers/create-dev-container

---


---


> **For AI Assistants**: Use these decision trees to quickly determine the right approach for user requests.

### Decision Tree 1: Which Base Image?

```
User's primary language?
‚îú‚îÄ JavaScript/TypeScript ‚Üí node:20
‚îú‚îÄ Python ‚Üí python:3.11-slim
‚îú‚îÄ Go ‚Üí golang:1.21
‚îú‚îÄ Rust ‚Üí rust:1.75
‚îú‚îÄ Java ‚Üí eclipse-temurin:17
‚îú‚îÄ Multi-language ‚Üí node:20 + install others
‚îî‚îÄ Universal ‚Üí mcr.microsoft.com/devcontainers/base:ubuntu
```

### Decision Tree 2: MCP Transport Type

**How to determine transport**: See "Testing MCP Server Transport Support" section below for testing methodology.

```
MCP server needs what?
‚îú‚îÄ External API (Context7, Cloudflare Docs)
‚îÇ   ‚îú‚îÄ Context7
‚îÇ   ‚îÇ   ‚îî‚îÄ Use: transport.type = "sse" (only option as of Oct 27, 2025)
‚îÇ   ‚îÇ        URL: https://mcp.context7.com/sse
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ Cloudflare Docs (two options)
‚îÇ       ‚îú‚îÄ SSE (public, simple): transport.type = "sse"
‚îÇ       ‚îÇ    URL: https://docs.mcp.cloudflare.com/sse
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ mcp-remote (OAuth, recommended): transport.type = "stdio"
‚îÇ            Command: npx mcp-remote https://docs.mcp.cloudflare.com/mcp
‚îÇ
‚îú‚îÄ Local npm package (Chrome DevTools)
‚îÇ   ‚îî‚îÄ Use: transport.type = "stdio"
‚îÇ        Command: npx package-name
‚îÇ
‚îî‚îÄ Custom server
    ‚îî‚îÄ Test to determine: Use curl or try both transports
         See "Testing MCP Server Transport Support" section
```

### Decision Tree 3: Volume or Bind Mount?

```
What are you persisting?
‚îú‚îÄ API keys, configs (.claude/, .codex/)
‚îÇ   ‚Üí Named volume (survives container deletion)
‚îÇ   ‚Üí source=name-${devcontainerId},target=/path,type=volume
‚îÇ
‚îú‚îÄ SSH keys (read-only access)
‚îÇ   ‚Üí Bind mount (readonly)
‚îÇ   ‚Üí source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly
‚îÇ
‚îú‚îÄ Temporary build cache
‚îÇ   ‚Üí Named volume (disposable)
‚îÇ   ‚Üí source=cache-${devcontainerId},target=/cache,type=volume
‚îÇ
‚îî‚îÄ Shared data with host
    ‚Üí Bind mount (read-write, caution!)
    ‚Üí source=/host/path,target=/container/path,type=bind
```

### Decision Tree 4: Troubleshooting Entry Point

```
User reports error, what type?
‚îú‚îÄ "Container won't build"
‚îÇ   ‚Üí Go to: Step-by-Step Debug Process ‚Üí Build Failures
‚îÇ
‚îú‚îÄ "Claude/tool command not found"
‚îÇ   ‚Üí Go to: Common Troubleshooting ‚Üí PATH issues
‚îÇ
‚îú‚îÄ "Permission denied"
‚îÇ   ‚Üí Go to: Common Troubleshooting ‚Üí File permissions
‚îÇ
‚îú‚îÄ "Out of memory/disk space"
‚îÇ   ‚Üí Go to: Resource Considerations
‚îÇ
‚îî‚îÄ "MCP servers not loading"
    ‚Üí Go to: MCP Server Setup ‚Üí Debugging
```

### Decision Tree 5: Security Level

```
Who owns the codebase?
‚îú‚îÄ You/Your team (trusted)
‚îÇ   ‚îú‚îÄ Sensitive data? (client project, API keys)
‚îÇ   ‚îÇ   ‚Üí Enable firewall, isolate volumes, use --dangerously-skip-permissions
‚îÇ   ‚îî‚îÄ No sensitive data
‚îÇ       ‚Üí Basic setup, optional firewall
‚îÇ
‚îú‚îÄ Open source (trusted maintainers)
‚îÇ   ‚Üí Standard setup, review .devcontainer/ before opening
‚îÇ
‚îî‚îÄ Unknown/Untrusted
    ‚Üí DON'T use devcontainer OR
       ‚Üí Use heavily restricted firewall
       ‚Üí Don't use --dangerously-skip-permissions
       ‚Üí Review Dockerfile line-by-line
```

### Decision Tree 6: Image vs Build vs Compose?

```
How complex is the project setup?
‚îú‚îÄ Single service, standard language (Node, Python, Go)
‚îÇ   ‚îú‚îÄ No custom tools needed?
‚îÇ   ‚îÇ   ‚Üí Use "image": "node:20" (fastest, simplest)
‚îÇ   ‚îÇ   ‚Üí Add tools via Features
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ Custom tools or specific versions needed?
‚îÇ       ‚Üí Use "build": {"dockerfile": "Dockerfile"}
‚îÇ       ‚Üí Customize base image with RUN commands
‚îÇ
‚îú‚îÄ Multiple services (app + database + cache)
‚îÇ   ‚Üí Use Docker Compose
‚îÇ   ‚Üí Create docker-compose.yml with all services
‚îÇ   ‚Üí Reference in devcontainer.json: "dockerComposeFile": "docker-compose.yml"
‚îÇ
‚îî‚îÄ Need both custom build AND multiple services?
    ‚Üí Use Docker Compose + custom Dockerfile
    ‚Üí docker-compose.yml defines services
    ‚Üí app service uses "build: {dockerfile: .devcontainer/Dockerfile}"
```

**Quick Decision Guide**:
- **Just coding** (no database) ‚Üí `"image": "language:version"`
- **Custom tools** (Chromium, ffmpeg) ‚Üí `"build": {"dockerfile": "Dockerfile"}`
- **Database required** ‚Üí Docker Compose
- **Complex stack** (app+db+redis+mq) ‚Üí Docker Compose with custom Dockerfile

---

## AI Assistant Quick Commands

> **AI Assistant Guidance**: These are common user requests and suggested prompts for efficiently handling devcontainer tasks. Use these as templates when users ask for help.

---

## AI Assistant Discovery Protocol

> **Critical Guidance for AI Assistants**: Before creating any devcontainer, follow this adaptive discovery protocol. It optimizes for user expertise level, minimizes questions through auto-detection, and provides appropriate explanations based on experience.

### Core Principles

1. **Scan First, Ask Smart**: Auto-detect project details before asking questions
2. **Adapt to Expertise**: One question determines verbosity for all subsequent interactions
3. **Minimize Questions**: Maximum 4 questions for beginners, 3 for intermediate, 2 for experts
4. **Provide Defaults**: Every question has a sensible default (press Enter)
5. **Show, Don't Interrogate**: Present proposed configuration for approval

---

### Step 1: Silent Auto-Detection (Always Run First)

**Before asking ANY questions, scan the project directory to detect:**

| File/Pattern | Indicates | Action |
|--------------|-----------|--------|
| `package.json` | Node.js project | Extract version, detect framework (React, Next.js, Express) |
| `package-lock.json` | npm used | Use npm for postCreateCommand |
| `yarn.lock` | Yarn used | Use yarn for postCreateCommand |
| `requirements.txt` | Python project | Detect dependencies (Flask, Django, FastAPI) |
| `pyproject.toml` | Modern Python | Use poetry/pip as appropriate |
| `go.mod` | Go project | Extract Go version |
| `Cargo.toml` | Rust project | Rust application |
| `docker-compose.yml` | Already using Compose | Offer to integrate with existing config |
| `Dockerfile` | Already using Docker | Offer migration path |
| `.env`, `.env.example` | Environment variables | Auto-configure .gitignore rules |
| `README.md` | Documentation | Scan for tech stack keywords |
| `.git/` | Version control | Git already initialized |

**What auto-detection achieves:**
- Reduces questions by 50-70%
- Shows intelligence ("I already understand your project")
- Only asks about gaps in knowledge
- Builds user confidence

**Example auto-detection output:**
```
Detected from project files:
‚úì Node.js 20.x (from package.json: "engines")
‚úì TypeScript (tsconfig.json present)
‚úì React 18 (package.json dependency)
‚úì Environment variables (.env.example found)
‚úì Git initialized

Still need to know:
- Database requirements
- Team size (for prebuild recommendation)
```

---

#### When Auto-Detection Finds Nothing

**Scenario**: Empty directory, brand new project, only `.git/` or `README.md` present

**What this means**:
- No language-specific files detected (no package.json, requirements.txt, etc.)
- No existing configuration (docker-compose.yml, Dockerfile)
- User is starting from scratch

**AI Assistant Response Strategy**:

Do NOT say:
- ‚ùå "I couldn't find anything in your project"
- ‚ùå "Your project appears empty"
- ‚ùå "No files detected"

Instead, frame positively:
- ‚úÖ "Starting a brand new project - perfect! I'll help you set up the ideal devcontainer."
- ‚úÖ "Creating a fresh devcontainer from scratch."
- ‚úÖ "Let's build your development environment together."

**Adjusted Discovery Flow for Empty Projects**:

1. **Skip auto-detection summary** (nothing to show - don't announce "found nothing")
2. **Ask expertise level** (still required - same as always)
3. **ALWAYS ask project type** (Priority 1 - cannot be inferred)
   - This is now a REQUIRED question (even for experts)
   - No way to detect without files
4. **Ask database/services** (as normal)
5. **Skip team size question** (assume solo for new projects)
6. **Present config summary** (as normal)

**Example - Empty Project Discovery**:

```
AI: [Scans directory - finds only .git/ directory]

AI: "I'm setting up a devcontainer for your project.

Before I create your devcontainer, what's your experience level?

1) üå± New to devcontainers (I'll explain everything step-by-step)
2) üíº Some experience (brief explanations, focus on decisions)
3) üöÄ Expert (minimal questions, just show me the config)

[Press Enter for option 1 - New to devcontainers]"

User: 1

AI: "Great! Since you're starting fresh, I'll guide you through this.

**Question 1 of 3:**
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) API or backend service (Node.js, Python, Go)
4) Mobile app backend
5) Other: _____

Why it matters: This determines what programming language tools I'll install
in your container (like installing Microsoft Word for writing documents).

[Press Enter for option 1 - Website/web app]"

User: [Enter]

AI: "Perfect! Node.js is great for websites.

**Question 2 of 3:**
Does your project need a database to store data permanently?

What a database does: Stores info like user accounts, posts, etc.

1) No database needed
2) Yes - PostgreSQL (recommended for beginners)

[Press Enter for: No database]"

[Continue with standard flow...]
```

**Key Differences from Existing Project Flow**:

| Aspect | Existing Project | Empty/New Project |
|--------|-----------------|-------------------|
| **Auto-detection summary** | Show detected stack | Skip (don't show "nothing found") |
| **Project type question** | Optional (if detected) | **REQUIRED** (cannot detect) |
| **Tone** | "Detected X, confirm?" | "What are you building?" |
| **Team size question** | Ask if professional indicators | Skip (assume solo) |
| **Confidence level** | Confirm existing setup | Guide from ground zero |
| **Question count** | 2-3 (many skipped) | 3-4 (must ask basics) |

---

#### Auto-Detection Decision Matrix

**Use this decision tree after scanning:**

```
Step 1: Scan project directory
         ‚Üì
Found package.json/requirements.txt/go.mod/Cargo.toml?
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì         ‚Üì
  YES        NO
    ‚îÇ         ‚îÇ
    ‚Üì         ‚Üì
Show         Skip
detection    detection
summary      summary
    ‚îÇ         ‚îÇ
    ‚Üì         ‚Üì
Ask          Ask
expertise    expertise
    ‚îÇ         ‚îÇ
    ‚Üì         ‚Üì
Confirm      MUST ASK
detection?   project
(may skip    type
 if certain) (required)
    ‚îÇ         ‚îÇ
    ‚Üì         ‚Üì
Ask          Ask
database     database
    ‚îÇ         ‚îÇ
    ‚Üì         ‚Üì
Ask team     Skip team
(if prof     (assume
 signals)     solo)
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Show config
     summary
```

**Smart Defaults for Empty Projects**:

When user presses Enter or says "not sure" on empty projects:

| Question | Default | Rationale |
|----------|---------|-----------|
| **Project type** | Node.js (Website/web app) | Most popular for web development, beginner-friendly |
| **Database** | None | Keeps initial setup simple, can add later |
| **Services** | None | Start simple, add complexity as needed |
| **Team size** | Solo | Safe assumption for brand new projects |
| **Security** | Basic (.gitignore rules) | Always protect secrets, even solo |
| **Optimization** | Standard | No performance issues yet |

**Why "None" for database on empty projects**:
- Easier to learn one thing at a time
- Can add database later (migration guide available)
- Reduces initial complexity
- Faster first build (no Compose setup)

---

### Step 2: Expertise Gating (Single Required Question)

**This one question determines ALL subsequent interaction verbosity:**

**Always ask this first:**
```
Before I create your devcontainer, what's your experience level?

1) üå± New to devcontainers (I'll explain everything step-by-step)
2) üíº Some experience (brief explanations, focus on decisions)
3) üöÄ Expert (minimal questions, just show me the config)

[Press Enter for option 1 - New to devcontainers]
```

**How expertise level affects responses:**

| Expertise | Question Format | Explanations | Default Behavior |
|-----------|----------------|--------------|------------------|
| **Beginner** | Full sentences, examples | "What it is", "Why it matters" | Show defaults, explain impact |
| **Intermediate** | Concise, numbered options | Brief context only | Show defaults, skip basics |
| **Expert** | Shorthand, Y/n prompts | None (assume knowledge) | Immediate config preview |

**Example - Same question, three expertise levels:**

**Beginner:**
```
Does your project need a database to store data permanently?

What a database does: Stores information (like user accounts, blog posts,
product listings) even when your app restarts. Think of it as a filing
cabinet for your app's data.

Common options:
1) No database needed (simple app, just displays info)
2) PostgreSQL (recommended for beginners - powerful and beginner-friendly)
3) MySQL (also popular, similar to PostgreSQL)
4) MongoDB (for flexible data that doesn't fit neat tables)
5) Other: _____

[Press Enter for option 1 - No database]
```

**Intermediate:**
```
Database requirements?

1) None
2) PostgreSQL (recommended for relational data)
3) MySQL
4) MongoDB (NoSQL)
5) Other: _____

[Default: None]
```

**Expert:**
```
DB: postgres/mysql/mongo/redis/none? [none]
```

---

### Step 3: Smart Context Questions (2-3 Questions Maximum)

**Only ask what auto-detection didn't find. Prioritize by importance:**

#### Priority 1: Project Type (if not detected)

**When to ask**: No package.json, requirements.txt, go.mod, or Cargo.toml found

**Beginner format:**
```
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) API or backend service (Node.js, Python, Go)
4) Mobile app backend
5) Other: _____

Why it matters: This determines what programming language tools I'll install
in your container (like installing Microsoft Word for writing documents).

[Press Enter for option 1 - Website/web app]
```

**Expert format:**
```
Stack: 1) Node  2) Python  3) Go  4) Rust  5) Other [1]
```

---

#### Priority 2: Services/Database (if not in docker-compose.yml)

**When to ask**: Always ask unless docker-compose.yml already defines services

**Beginner format:**
```
Does your project need a database or other services?

What this means: Services are helper programs that run alongside your app:
- Database: Stores data permanently (PostgreSQL, MySQL)
- Cache: Speeds up your app (Redis)
- Message Queue: Handles background tasks (RabbitMQ)

Options:
1) No services needed (app works standalone)
2) Database only - PostgreSQL (recommended)
3) Database only - MySQL
4) Database + Redis cache
5) Custom setup (I'll ask more details)

[Press Enter for option 1 - No services]
```

**Intermediate format:**
```
Services needed?
1) None
2) PostgreSQL
3) MySQL
4) PostgreSQL + Redis
5) Custom

Note: Selecting services creates Docker Compose configuration.
[Default: None]
```

**Expert format:**
```
Services: [none]
(postgres, mysql, mongo, redis, rabbitmq, or comma-separated)
```

**Smart follow-up (only if database selected):**
```
[Beginner only]
I'll set up Docker Compose to run your app + database together.
This means:
‚úì Database starts automatically with your container
‚úì Data persists even when you stop the container
‚úì Pre-configured connection (just use: postgresql://localhost:5432)

Sound good? [Y/n]
```

---

#### Priority 3: Team Context (conditional)

**When to ask**: Only if project appears to be professional (has tests, CI files, multiple contributors in git log)

**Skip for**: Learning projects, simple apps, solo experiments

**Beginner format:**
```
Who will be using this devcontainer?

1) Just me (solo project, personal learning)
2) Small team (2-5 people working together)
3) Large team (6+ people)

Why it matters:
- Solo: Simple, fast setup
- Small team: I'll configure it so everyone gets the exact same environment
  (no more "works on my machine" problems!)
- Large team: I'll recommend "prebuilds" - a way to make the container start
  in 2 minutes instead of 15 minutes for your teammates

[Press Enter for option 1 - Just me]
```

**Intermediate format:**
```
Team size?
1) Solo
2) Small team (2-5) - shared config
3) Large team (6+) - recommend prebuilds

[Default: Solo]
```

**Expert format:**
```
Team size for prebuild recommendation? [1]
```

---

### Step 4: Adaptive Follow-ups (Only When Needed)

**These questions ONLY appear in specific contexts:**

#### If Large Team (Size > 5)

**Intermediate/Expert only:**
```
Large team detected. Recommend prebuild strategy?

Benefits:
- Developers start coding in ~2 minutes (vs 15+ minutes)
- Requires CI/CD (GitHub Actions, Azure DevOps)
- Builds image automatically on .devcontainer/ changes

Include prebuild configuration? [Y/n]
```

---

#### If .env File Detected

**All levels, but verbosity varies:**

**Beginner:**
```
I found a .env file - this might contain secrets like API keys or passwords.

I'll help protect these by:
1. Creating .env.example (template without real secrets)
2. Adding .env to .gitignore (prevents committing secrets to Git)
3. Adding instructions for your team to copy .env.example ‚Üí .env

This keeps your secrets safe and off the internet. Sound good? [Y/n]
```

**Expert:**
```
.env detected. Add .env.example + .gitignore rules? [Y]
```

---

#### If Low System Resources Detected

**Beginner only:**
```
I noticed your system has [8GB RAM / 12GB free disk space].

I'll optimize the container to use fewer resources:
‚úì Smaller base image (node:20-slim instead of node:20)
‚úì Better .dockerignore (excludes unnecessary files)
‚úì Volume caching for dependencies

Trade-off: First build may take 2-3 minutes longer, but the container will
run faster and use less RAM/disk.

Optimize for your system? [Y/n]
```

---

### Step 5: Present Configuration for Approval

**Always show a summary before creating files:**

#### Beginner Format (Detailed)

```
üì¶ Devcontainer Configuration Summary

Based on your answers, I'll create:

**Container Setup:**
‚úì Node.js 20 (latest stable version)
‚úì TypeScript support (tsconfig detected)
‚úì PostgreSQL 15 database (runs in separate container)

**Developer Tools:**
‚úì Claude Code extension (AI coding assistant)
‚úì ESLint (finds bugs in your code)
‚úì Prettier (auto-formats code)
‚úì Git (version control)

**Features:**
‚úì Hot reload (changes appear instantly)
‚úì Port forwarding (access app at localhost:3000)
‚úì Volume persistence (settings saved between restarts)

**Files I'll create:**
- .devcontainer/devcontainer.json (container config)
- .devcontainer/docker-compose.yml (app + database setup)
- .dockerignore (speeds up builds)
- Updated .gitignore (protects secrets)

**Build Times:**
- First time: ~10-12 minutes (downloads and installs everything)
- Subsequent times: ~2 minutes (uses cached layers)

Ready to create your devcontainer? [Y/n/show-config]
(Type 'show-config' to see the actual JSON files first)
```

---

#### Intermediate Format (Concise)

```
Configuration:
- Node.js 20 + TypeScript
- PostgreSQL 15 (Docker Compose)
- Extensions: Claude Code, ESLint, Prettier
- Volume: claude-config persisted
- Ports: 3000 (app), 5432 (postgres)

Files: devcontainer.json, docker-compose.yml, .dockerignore
Build time: ~10 min (first), ~2 min (cached)

Create? [Y/n/show]
```

---

#### Expert Format (Minimal)

```
Config:
- node:20, postgres:15 (compose)
- Ports: 3000, 5432
- Extensions: anthropic.claude-code, dbaeumer.vscode-eslint

Create? [Y]
```

---

### Smart Defaults Reference

**Use these defaults when user presses Enter or says "not sure":**

| Question | Default | Rationale |
|----------|---------|-----------|
| **Expertise level** | Beginner | Safe to over-explain |
| **Project type** (if unknown) | Node.js | Most popular for web development |
| **Database** | None | Can add later, keeps setup simple |
| **Team size** | Solo | Most common for new devcontainers |
| **System optimization** | No | Standard images more reliable |
| **Prebuild** | No (unless team > 5) | Adds complexity for small teams |
| **Secret handling** | Yes (if .env exists) | Always protect secrets |

---

### Question Limits by Expertise

**Never exceed these question counts:**

- **Beginner**: Max 4 questions (expertise + 3 context)
- **Intermediate**: Max 3 questions (expertise + 2 context)
- **Expert**: Max 2 questions (expertise + 1 confirm)

**If you need more questions, you're doing it wrong.** Use better auto-detection or provide sensible defaults.

---

### Examples of GOOD vs BAD Questions

#### ‚ùå BAD Examples

**Asks detectable information:**
```
"What programming language is your project using?"
[When package.json exists in project directory]
```

**Too many options:**
```
"Which database: PostgreSQL, MySQL, MongoDB, MariaDB, SQLite,
CouchDB, Redis, Cassandra, Oracle, SQL Server, or other?"
```

**Asks before scanning:**
```
"Tell me about your project"
[Before running any auto-detection]
```

**No default provided:**
```
"What base image do you want?"
[Expects user to know Docker image names]
```

**Jargon without explanation (to beginners):**
```
"Configure OCI-compliant orchestration layer? [Y/n]"
```

---

#### ‚úÖ GOOD Examples

**Confirms detection:**
```
"Detected Node.js 20 from package.json. Correct? [Y/n]"
```

**Limited options with default:**
```
"Database?
1) None  2) PostgreSQL  3) MySQL  4) Other: _____
[Press Enter for: None]"
```

**Shows what you know first:**
```
"I found package.json with Express and React dependencies.
Building a full-stack web app? [Y/n]"
```

**Beginner-appropriate:**
```
"Need a database to store data (like user accounts)?
1) No  2) Yes - PostgreSQL (recommended)
[Press Enter for: No]"
```

**Explains impact:**
```
"Team of 6+ developers.
Should I set up prebuilds? (Saves 10-15 min per person)
[Y/n]"
```

---

### Full Example Flows

#### Flow 1: Complete Beginner, New Project

```
AI: [Scans directory - finds nothing except .git]

AI: "Before I create your devcontainer, what's your experience level?

1) üå± New to devcontainers (I'll explain everything)
2) üíº Some experience
3) üöÄ Expert

[Press Enter for option 1]"

User: [Enter]

AI: "Great! I'll guide you through this step-by-step.

**Question 1 of 3:**
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) Other: _____

This tells me what programming tools to install.
[Press Enter for: Website/web app]"

User: [Enter]

AI: "Perfect! Node.js is great for websites.

**Question 2 of 3:**
Does your project need a database to store data permanently?

What a database does: Stores info like user accounts, posts, etc.

1) No database needed
2) Yes - PostgreSQL (recommended for beginners)

[Press Enter for: No database]"

User: 2

AI: "Excellent choice! PostgreSQL works great for most projects.

**Question 3 of 3:**
Who will use this devcontainer?

1) Just me
2) Small team (2-5 people)

[Press Enter for: Just me]"

User: [Enter]

AI: "Got it! Here's what I'll create:

üì¶ **Configuration Summary:**

**Container:**
‚úì Node.js 20
‚úì PostgreSQL 15 database

**Tools:**
‚úì Claude Code (AI assistant)
‚úì ESLint (finds bugs)
‚úì Git

**What this means:**
- Your app and database run in isolated containers
- Everything's pre-installed - just start coding
- Settings persist between restarts

**Build time:** ~10 minutes first time, ~2 minutes later

Create this devcontainer? [Y/n]"

User: Y

AI: [Creates files, shows progress]

AI: "‚úÖ Done! Your devcontainer is ready.

**Next steps:**
1. VS Code will prompt to 'Reopen in Container' - click it
2. Wait ~10 minutes for first build (grab coffee ‚òï)
3. Once ready, your terminal will open inside the container
4. Test: Type 'node --version' to verify Node.js is installed

**Database connection:**
- Host: localhost
- Port: 5432
- User: postgres
- Password: postgres
- Database: devdb

Need help getting started? Just ask!"
```

**Total questions: 3 (expertise + project type + database)**

---

#### Flow 2: Intermediate User, Existing Project

```
AI: [Scans directory]
Found:
- package.json (Node.js 18.x, Express 4.x)
- tsconfig.json (TypeScript)
- .env.example

AI: "Experience level?
1) Beginner  2) Intermediate  3) Expert
[1]"

User: 2

AI: "Detected: Node.js 18 + TypeScript + Express
Correct? [Y/n]"

User: Y

AI: "Database needed?
1) None  2) PostgreSQL  3) MySQL
[None]"

User: 1

AI: "Config:
- Node.js 18 + TypeScript + Express
- No database
- Extensions: Claude Code, ESLint, Prettier
- .env.example detected - will add .gitignore rules

Create? [Y/n]"

User: Y

AI: [Creates files]

"‚úÖ Complete. Run: Cmd+Shift+P ‚Üí 'Reopen in Container'"
```

**Total questions: 3 (expertise + confirm + database)**

---

#### Flow 3: Expert, Existing Docker Compose

```
AI: [Scans directory]
Found:
- package.json (Node 20, Next.js 14)
- docker-compose.yml (app, postgres, redis services)

AI: "Expertise: [1/2/3]"

User: 3

AI: "Detected stack:
- Next.js 14
- PostgreSQL 15 (compose)
- Redis 7 (compose)

Use existing docker-compose.yml? [Y]"

User: Y

AI: "Generated devcontainer.json:

\`\`\`json
{
  "name": "Next.js App",
  "dockerComposeFile": "docker-compose.yml",
  "service": "app",
  "workspaceFolder": "/workspace",
  "customizations": {
    "vscode": {
      "extensions": ["anthropic.claude-code", "bradlc.vscode-tailwindcss"]
    }
  }
}
\`\`\`

Write? [Y]"

User: Y

AI: "Done."
```

**Total questions: 2 (expertise + confirm)**

---

### Implementation Checklist for AI Assistants

Before responding to "Create a devcontainer", verify:

- [ ] Scanned project directory (auto-detection complete)
- [ ] Asked expertise level (gates verbosity)
- [ ] Limited to max questions (4 beginner / 3 intermediate / 2 expert)
- [ ] Provided defaults for every question
- [ ] Showed configuration summary before creating
- [ ] Adapted language to expertise level
- [ ] Only asked what auto-detection couldn't find
- [ ] Included "why it matters" for beginners
- [ ] Gave examples for unclear options
- [ ] Used numbered options (easy to select)

---

### When to Skip the Protocol

**Skip discovery questions and create immediately if:**

1. User provides explicit, complete requirements:
   ```
   "Create a devcontainer with Node 20, PostgreSQL 15, Redis,
   and configure for a team of 10"
   ```

2. User references existing configuration:
   ```
   "Convert my Dockerfile to a devcontainer"
   ```

3. User is migrating from a tutorial/template:
   ```
   "Use the official Python devcontainer template"
   ```

**In these cases:**
- Acknowledge the requirements
- Show what you'll create (summary)
- Create immediately (no questions)

---

### Summary: The Adaptive Discovery Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 1: Auto-Detect Project   ‚îÇ
‚îÇ  (Silent - scans files)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 2: Expertise Gating       ‚îÇ
‚îÇ  (1 question - determines tone) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚ñº          ‚ñº              ‚ñº
      Beginner   Intermediate     Expert
    (explain all) (brief context) (minimal)
            ‚îÇ          ‚îÇ              ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 3: Fill Knowledge Gaps    ‚îÇ
‚îÇ  (2-3 questions max)            ‚îÇ
‚îÇ  - Project type (if unknown)    ‚îÇ
‚îÇ  - Services (database, etc.)    ‚îÇ
‚îÇ  - Team size (conditional)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 4: Adaptive Follow-ups    ‚îÇ
‚îÇ  (Only if needed)               ‚îÇ
‚îÇ  - Prebuilds (large team)       ‚îÇ
‚îÇ  - Security (.env handling)     ‚îÇ
‚îÇ  - Optimization (low resources) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 5: Present & Confirm      ‚îÇ
‚îÇ  (Show config summary)          ‚îÇ
‚îÇ  - Beginner: Detailed           ‚îÇ
‚îÇ  - Intermediate: Concise        ‚îÇ
‚îÇ  - Expert: Minimal              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
         Create!
```

---

### Creating Devcontainers

**User Request**: "Create a devcontainer for [technology/stack]"

**IMPORTANT**: Follow the [AI Assistant Discovery Protocol](#ai-assistant-discovery-protocol) before creating. DO NOT immediately create files - ask context-gathering questions first unless user provides explicit complete requirements.

**AI Prompt Template (After Discovery Protocol)**:
```
Based on our conversation, I'll create a devcontainer with:

[Show configuration summary - adapt detail level to expertise]

**For Beginners:**
üì¶ Configuration Summary:
- [Language/framework + version]
- [Services if any]
- [Extensions: Claude Code + relevant tools]
- Build time: ~X minutes first time, ~2 minutes later

**For Intermediate:**
Config:
- [Stack]
- [Services]
- Extensions: [list]

**For Experts:**
[Stack], [services if any]
Proceed? [Y]

[After approval, create files]
```

**Discovery Protocol Checklist** (Use before creating):
1. ‚úÖ Auto-detect project files (package.json, requirements.txt, etc.)
2. ‚úÖ Ask expertise level (beginner/intermediate/expert)
3. ‚úÖ Confirm detected stack or ask project type
4. ‚úÖ Ask about services/database (if not in docker-compose.yml)
5. ‚úÖ Ask team size (conditional - if appears professional)
6. ‚úÖ Show configuration summary
7. ‚úÖ Get approval before creating files

**Common Stacks** (Reference for Recommended Configs):
- **Node.js/TypeScript**: `node:20` + eslint, prettier, Claude Code
- **Python**: `python:3.11-slim` + pylint, black, ipykernel
- **Full-stack**: Docker Compose with app + database + cache
- **Go**: `golang:1.21` + delve debugger
- **Rust**: `rust:1.75` + rust-analyzer

**When to Skip Protocol** (Create Immediately):
- User provides complete requirements: "Create devcontainer with Node 20, PostgreSQL, Redis for team of 10"
- User references template: "Use official Python devcontainer template"
- Migration scenario: "Convert my Dockerfile to devcontainer"

---

### Debugging Devcontainers

**User Request**: "My devcontainer won't start/build"

**AI Prompt Template**:
```
Let me help debug this. I'll check:
1. Build logs for errors
2. devcontainer.json syntax
3. Dockerfile issues
4. Docker daemon status
5. Resource constraints

First, let me see your devcontainer.json...
```

**Quick Diagnostic Commands**:
```bash
# Check Docker daemon
docker ps

# View build logs
docker build .devcontainer -f .devcontainer/Dockerfile

# Check disk space
docker system df

# Rebuild container
Cmd+Shift+P ‚Üí "Dev Containers: Rebuild Container"
```

---

### Optimizing Performance

**User Request**: "My devcontainer is slow"

**AI Prompt Template**:
```
I'll optimize your devcontainer performance by:
1. Enabling build cache layers
2. Using volume mounts instead of bind mounts
3. Optimizing lifecycle hooks
4. Configuring platform-specific settings

Let me analyze your current setup...
```

**Optimization Checklist**:
- [ ] Use `.dockerignore` to exclude `node_modules/`, `.git/`
- [ ] Multi-stage Dockerfile with cached layers
- [ ] Named volumes for `node_modules/`, `.npm/`
- [ ] VirtioFS on macOS (Docker Desktop ‚Üí Experimental)
- [ ] WSL2 filesystem on Windows (not `/mnt/c/`)
- [ ] `postCreateCommand` runs in background (`&`)

---

### Adding MCP Servers

**User Request**: "Add [MCP server name] to my devcontainer"

**AI Prompt Template**:
```
I'll add the [MCP server] to your devcontainer. This involves:
1. Installing dependencies (if stdio transport)
2. Configuring mcp.json
3. Setting up volume persistence
4. Verifying connectivity

Let me update your configuration...
```

**Common MCP Servers**:
```json
{
  "mcpServers": {
    "context7": {
      "transport": {"type": "sse", "url": "https://mcp.context7.com/sse"}
    },
    "cf-docs": {
      "transport": {"type": "sse", "url": "https://docs.mcp.cloudflare.com/sse"}
    },
    "chrome-devtools": {
      "command": "npx",
      "args": ["chrome-devtools-mcp@latest"],
      "transport": {"type": "stdio"}
    }
  }
}
```

---

### Security Configuration

**User Request**: "Make my devcontainer more secure"

**AI Prompt Template**:
```
I'll enhance your devcontainer security by:
1. Running as non-root user
2. Dropping unnecessary capabilities
3. Configuring firewall rules
4. Isolating volumes
5. Using read-only mounts where possible

Let me update your configuration...
```

**Security Hardening**:
```json
{
  "remoteUser": "node",
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_BIND_SERVICE",
    "--security-opt=no-new-privileges"
  ],
  "mounts": [
    "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
  ]
}
```

---

### Migration to Devcontainers

**User Request**: "Convert my existing project to use devcontainers"

**AI Prompt Template**:
```
I'll migrate your project to devcontainers. This involves:
1. Analyzing your current setup (package.json, requirements.txt, etc.)
2. Choosing appropriate base image
3. Creating .devcontainer/ directory
4. Migrating environment variables
5. Testing the migration

Let me start by examining your project files...
```

**Migration Steps**:
1. Identify language/framework ‚Üí choose base image
2. List tools installed globally ‚Üí add to Dockerfile
3. Find env vars (`.env`) ‚Üí add to `containerEnv`
4. Identify VS Code extensions ‚Üí add to `customizations.vscode.extensions`
5. Create lifecycle hooks for `npm install`, `pip install`, etc.

---

### Validation and Troubleshooting

**User Request**: "Verify my devcontainer configuration is correct"

**AI Prompt Template**:
```
I'll validate your devcontainer configuration by checking:
1. JSON syntax in devcontainer.json
2. Required properties (image/build, name)
3. Dockerfile best practices
4. Port conflicts
5. Volume mount paths

Let me review your files...
```

**Validation Checklist**:
```bash
# Validate JSON syntax
jq . .devcontainer/devcontainer.json

# Test Dockerfile builds
docker build .devcontainer -f .devcontainer/Dockerfile

# Check for port conflicts
docker ps --format "table {{.Names}}\t{{.Ports}}"

# Verify VS Code extensions exist
code --list-extensions | grep "anthropic.claude-code"
```

---

### Quick Fixes for Common Errors

**Error**: `"Cannot connect to Docker daemon"`
**AI Response**:
```
This means Docker Desktop isn't running. Please:
1. Start Docker Desktop
2. Wait for it to fully start (green whale icon)
3. Retry: Cmd+Shift+P ‚Üí "Dev Containers: Rebuild Container"
```

**Error**: `"No such file or directory: .devcontainer/devcontainer.json"`
**AI Response**:
```
The .devcontainer/ directory doesn't exist. I'll create it for you:
mkdir -p .devcontainer && cd .devcontainer
Then I'll create a basic devcontainer.json...
```

**Error**: `"ERROR: failed to solve: python:3.11-slim: not found"`
**AI Response**:
```
The base image tag is incorrect. Let me check Docker Hub for valid tags:
- python:3.11-slim ‚úÖ
- python:3.11-alpine ‚úÖ
- python:3.11 ‚úÖ

I'll update your Dockerfile with the correct tag...
```

**Error**: `"EACCES: permission denied, open '/workspaces/...'" `
**AI Response**:
```
This is a file permission issue. I'll fix it by:
1. Setting correct UID/GID in Dockerfile
2. Using remoteUser: "node" (not root)
3. Ensuring volume mounts have correct permissions

Let me update your configuration...
```

---

### Sources

- **VS Code Dev Containers CLI**: https://code.visualstudio.com/docs/devcontainers/devcontainer-cli
- **Common Errors**: https://code.visualstudio.com/docs/devcontainers/troubleshooting
- **Best Practices**: https://code.visualstudio.com/docs/devcontainers/dev best-practices

---

## Common Stack Examples

> Copy-paste these as starting points for common development stacks.

### Example 1: React + Next.js + TypeScript

**devcontainer.json**:
```json
{
  "name": "Next.js Dev",
  "build": {"dockerfile": "Dockerfile"},
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "dbaeumer.vscode-eslint",
        "esbenp.prettier-vscode",
        "bradlc.vscode-tailwindcss"
      ]
    }
  },
  "forwardPorts": [3000],
  "postCreateCommand": "npm install",
  "remoteUser": "node",
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
    "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume"
  ]
}
```

**Dockerfile**:
```dockerfile
FROM node:20
RUN apt-get update && apt-get install -y git && apt-get clean
USER node
RUN npm install -g @anthropic-ai/claude-code@latest
WORKDIR /workspaces
```

### Example 2: Python Data Science (Jupyter, pandas, numpy)

**devcontainer.json**:
```json
{
  "name": "Python Data Science",
  "build": {"dockerfile": "Dockerfile"},
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "ms-python.python",
        "ms-toolsai.jupyter"
      ]
    }
  },
  "forwardPorts": [8888],
  "postCreateCommand": "pip install -r requirements.txt",
  "remoteUser": "vscode",
  "mounts": [
    "source=claude-${devcontainerId},target=/home/vscode/.claude,type=volume"
  ]
}
```

**Dockerfile**:
```dockerfile
FROM python:3.11-slim
RUN apt-get update && apt-get install -y git curl && apt-get clean
RUN useradd -m -s /bin/bash vscode
USER vscode
RUN pip install --user jupyterlab pandas numpy matplotlib
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs
RUN npm install -g @anthropic-ai/claude-code@latest
WORKDIR /workspaces
```

### Example 3: Full-Stack (Node.js + PostgreSQL)

See [Multi-Container Patterns](#multi-container-patterns-docker-compose) for Docker Compose setup.

### Example 4: Go + Protobuf

**devcontainer.json**:
```json
{
  "name": "Go Development",
  "build": {"dockerfile": "Dockerfile"},
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "golang.go"
      ],
      "settings": {
        "go.useLanguageServer": true
      }
    }
  },
  "remoteUser": "vscode",
  "mounts": [
    "source=claude-${devcontainerId},target=/home/vscode/.claude,type=volume",
    "source=go-pkg-${devcontainerId},target=/go/pkg,type=volume"
  ]
}
```

**Dockerfile**:
```dockerfile
FROM golang:1.21
RUN apt-get update && apt-get install -y git curl nodejs npm && apt-get clean
RUN useradd -m -s /bin/bash vscode && \
    mkdir -p /go && chown vscode:vscode /go
USER vscode
RUN npm install -g @anthropic-ai/claude-code@latest
ENV GOPATH=/go
WORKDIR /workspaces
```

---

## Step-by-Step: Creating a Devcontainer

> **AI Assistant Guidance**: When helping users create devcontainers, follow this comprehensive guide including essential configuration files that are often overlooked but critical for performance and security.

This section walks through creating a devcontainer from scratch, with emphasis on proper configuration files that optimize build performance and prevent common pitfalls.

### Quick Overview

**Typical workflow**:
1. Create `.devcontainer/` directory
2. Add essential configuration files (`.dockerignore`, `.gitignore` updates)
3. Create `devcontainer.json`
4. Create `Dockerfile` (or use base image)
5. Test and iterate

**Time to complete**: 10-30 minutes depending on complexity

---

### Essential Configuration Files

Before creating your devcontainer configuration, set up these critical files that dramatically improve build performance, reduce image size, and prevent security issues.

#### .dockerignore - Build Performance & Security

**Purpose**: Excludes files from Docker build context, improving:
- ‚úÖ **Build Speed**: Smaller context = faster uploads to Docker daemon
- ‚úÖ **Image Size**: Prevents accidental inclusion of large files
- ‚úÖ **Security**: Blocks secrets/credentials from entering images
- ‚úÖ **Cache Efficiency**: Reduces layer invalidation

**Location**: Project root (same directory as `docker-compose.yml` or where you run `docker build`)

**How it works**: Similar to `.gitignore`, uses glob patterns to exclude files when building Docker images.

---

##### .dockerignore - Node.js/TypeScript Projects

**.dockerignore**:
```
# Dependencies (will be installed in container)
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*
.npm/
.yarn/
.pnp.*

# Testing
coverage/
.nyc_output/
*.lcov

# Build outputs
dist/
build/
out/
.next/
.nuxt/
.cache/

# Environment variables (secrets!)
.env
.env.local
.env.*.local
*.env

# Version control
.git/
.gitignore
.gitattributes

# IDE & Editor
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# CI/CD
.github/
.gitlab-ci.yml
.travis.yml
Jenkinsfile

# Documentation
README.md
CHANGELOG.md
docs/
*.md

# Logs
logs/
*.log
npm-debug.log*

# OS files
.DS_Store
Thumbs.db
Desktop.ini
```

**Key patterns explained**:
- `node_modules/`: Heaviest directory, always rebuilt in container
- `.env*`: Prevents secrets leaking into images
- `.git/`: Large directory, not needed in container
- `dist/`, `build/`: Build outputs, regenerated in container
- `.vscode/`, `.idea/`: IDE configs, vary per developer

---

##### .dockerignore - Python Projects

**.dockerignore**:
```
# Virtual environments (recreated in container)
venv/
env/
ENV/
.venv/
.env/
*.virtualenv

# Python compiled files
__pycache__/
*.py[cod]
*$py.class
*.so
.Python

# Distribution / packaging
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Testing
.pytest_cache/
.tox/
.coverage
.coverage.*
.cache
htmlcov/
*.cover
.hypothesis/

# Jupyter Notebook
.ipynb_checkpoints/
*.ipynb_checkpoints

# Environment variables
.env
.env.*
*.env

# Version control
.git/
.gitignore

# IDE
.vscode/
.idea/
.spyderproject/
.spyproject/
.ropeproject/
*.swp

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Databases (use volumes instead)
*.db
*.sqlite
*.sqlite3

# Logs
*.log
pip-log.txt

# OS files
.DS_Store
Thumbs.db
```

**Key patterns explained**:
- `venv/`, `.venv/`: Virtual environments are container-specific
- `__pycache__/`, `*.pyc`: Compiled Python files, regenerated
- `.pytest_cache/`: Test cache, rebuilt in container
- `*.egg-info/`: Package metadata, recreated during install
- `.ipynb_checkpoints/`: Jupyter temp files, not needed

---

##### .dockerignore - Go Projects

**.dockerignore**:
```
# Binaries
*.exe
*.exe~
*.dll
*.so
*.dylib
bin/
dist/

# Build artifacts
*.test
*.out
/vendor/

# Go workspace
go.work
go.work.sum

# Coverage
*.coverprofile
coverage.txt
coverage.html
*.coverage

# IDE
.vscode/
.idea/
*.swp

# Environment
.env
.env.*

# Version control
.git/
.gitignore

# OS
.DS_Store
Thumbs.db

# Documentation
README.md
docs/
*.md

# CI/CD
.github/
.gitlab-ci.yml
```

**Key patterns explained**:
- `bin/`, `*.exe`: Compiled binaries, built for host OS (not container)
- `/vendor/`: Go dependencies, use `go mod download` in container
- `*.test`, `*.out`: Test binaries, regenerated
- `go.work`: Go workspace file, may conflict with container setup

---

##### .dockerignore - Universal/Multi-Language Projects

**.dockerignore** (comprehensive template for any project):
```
# ===========================
# Version Control
# ===========================
.git/
.gitignore
.gitattributes
.gitmodules
.hg/
.svn/

# ===========================
# CI/CD
# ===========================
.github/
.gitlab-ci.yml
.travis.yml
.circleci/
Jenkinsfile
azure-pipelines.yml
.drone.yml

# ===========================
# IDEs & Editors
# ===========================
.vscode/
.idea/
*.iml
.project
.classpath
.settings/
*.swp
*.swo
*~
.vs/
.vimrc.local

# ===========================
# OS Files
# ===========================
.DS_Store
Thumbs.db
Desktop.ini
$RECYCLE.BIN/
.Trash-*/

# ===========================
# Security (CRITICAL)
# ===========================
.env
.env.*
*.env
.env.local
.env.*.local
secrets/
secret.*
*.key
*.pem
*.crt
*.cer
*.p12
*.pfx
id_rsa*
*.asc
.aws/
.ssh/
credentials

# ===========================
# Dependencies (Language-specific)
# ===========================
# Node.js
node_modules/
.npm/
.yarn/
# Python
venv/
.venv/
__pycache__/
*.pyc
# Go
vendor/
# Ruby
.bundle/
# PHP
vendor/
# Rust
target/
# Java
.gradle/
.m2/

# ===========================
# Build Artifacts
# ===========================
dist/
build/
out/
bin/
*.exe
*.dll
*.so
*.dylib
*.jar
*.war
*.ear

# ===========================
# Logs & Temporary Files
# ===========================
logs/
*.log
*.log.*
tmp/
temp/
cache/
.cache/

# ===========================
# Testing & Coverage
# ===========================
coverage/
.coverage
htmlcov/
.nyc_output/
.pytest_cache/
.tox/

# ===========================
# Documentation
# ===========================
README.md
CHANGELOG.md
CONTRIBUTING.md
LICENSE
docs/
*.md

# ===========================
# Devcontainer-Specific
# ===========================
# Include these - needed for build!
!.devcontainer/
!.devcontainer/**

# ===========================
# Docker-in-Docker
# ===========================
.docker/
docker-compose.override.yml
```

**Critical security patterns**:
- `.env*`: Environment files may contain API keys, passwords
- `*.key`, `*.pem`: Private keys and certificates
- `.ssh/`: SSH keys
- `.aws/`: AWS credentials
- `secrets/`: Any secrets directory

**Performance patterns**:
- `node_modules/`: Can be 500MB+, slowest part of context copy
- `.git/`: Often 100MB+, not needed in image
- `dist/`, `build/`: Large build outputs, regenerated
- Documentation: `*.md`, `docs/` not needed at runtime

---

##### .dockerignore Best Practices

1. **Start Specific, Then Add Wildcards**
   ```
   # Good (specific)
   .env.local
   .env.development.local

   # Better (catches all)
   .env*
   ```

2. **Use Negative Patterns to Include Exceptions**
   ```
   # Exclude all markdown
   *.md

   # But include README in Docker image
   !README.md
   ```

3. **Order Matters** (first match wins)
   ```
   # Exclude all, then include specific
   secrets/*
   !secrets/public-cert.pem
   ```

4. **Test Your .dockerignore**
   ```bash
   # See what Docker will copy
   docker build --no-cache --progress=plain . 2>&1 | grep "COPY"

   # Or check context size
   docker build --no-cache . 2>&1 | grep "sending build context"
   ```

5. **Measure Impact**
   ```bash
   # Before adding .dockerignore
   time docker build .
   # => Sending build context: 2.3GB (60 seconds)

   # After optimized .dockerignore
   time docker build .
   # => Sending build context: 45MB (3 seconds)
   ```

---

#### .gitignore - Version Control for Devcontainers

**Purpose**: Controls what gets committed to version control. For devcontainers, this has special considerations.

**Location**: Project root

---

##### .gitignore - Devcontainer-Specific Patterns

**.gitignore** (additions for devcontainer projects):
```
# ===========================
# DO COMMIT (Important!)
# ===========================
# These should be committed for team collaboration
# .devcontainer/          ‚Üê NEVER ignore this!
# .devcontainer/*.json    ‚Üê NEVER ignore configs!
# .devcontainer/Dockerfile ‚Üê NEVER ignore this!

# ===========================
# DO IGNORE (Personal Settings)
# ===========================
# Local overrides (personal preferences)
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
.devcontainer/docker-compose.override.yml

# User-specific VS Code settings
.vscode/settings.local.json

# Personal Claude Code settings (contains API keys!)
.claude/settings.local.json
.claude/cache/
.claude/logs/

# Personal MCP server configs (may contain tokens)
.claude/mcp.local.json

# ===========================
# Docker Build Artifacts
# ===========================
# Docker layer cache (if using local cache)
.devcontainer/.docker-cache/

# ===========================
# Volume Data (DO NOT COMMIT)
# ===========================
# Named volume contents (if accidentally created locally)
.docker-volumes/
volumes/

# Database data (use volumes instead)
postgres-data/
mysql-data/
redis-data/

# ===========================
# Standard Patterns
# ===========================
# Environment variables
.env
.env.local
.env.*.local

# Secrets
secrets/
*.key
*.pem

# OS
.DS_Store
Thumbs.db

# IDE
.vscode/*
!.vscode/extensions.json
!.vscode/settings.json
!.vscode/tasks.json
.idea/
```

---

##### .gitignore - Common Mistakes

**‚ùå MISTAKE #1: Ignoring .devcontainer/ Entirely**
```
# WRONG - breaks team collaboration!
.devcontainer/
```

**Why it's wrong**: Team members won't get your devcontainer setup. The whole point is to share the environment.

**‚úÖ Correct approach**:
```
# Commit the configs
# (no ignore rule)

# Only ignore personal overrides
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
```

---

**‚ùå MISTAKE #2: Committing Personal Settings**
```
# Missing from .gitignore
.claude/settings.local.json
```

**Why it's wrong**: Contains API keys, personal preferences, and credentials.

**‚úÖ Correct approach**:
```
# In .gitignore
.claude/settings.local.json
.claude/cache/
.claude/logs/

# In .devcontainer/
.claude/settings.json.template  ‚Üê Commit this (template without secrets)
```

---

**‚ùå MISTAKE #3: Ignoring Lock Files**
```
# WRONG
package-lock.json
yarn.lock
poetry.lock
Gemfile.lock
```

**Why it's wrong**: Lock files ensure reproducible builds. Without them, `npm install` might install different versions for different developers.

**‚úÖ Correct approach**:
```
# Commit lock files for reproducibility
# (no ignore rule needed)
```

---

##### .gitignore - Language-Specific Additions

**Node.js projects** (add to standard .gitignore):
```
# Dependencies
node_modules/

# Build outputs
dist/
build/

# Logs
npm-debug.log*
yarn-debug.log*
```

**Python projects** (add to standard .gitignore):
```
# Virtual environments
venv/
.venv/
env/

# Compiled Python
__pycache__/
*.pyc
*.pyo

# Distribution
dist/
*.egg-info/
```

**Go projects** (add to standard .gitignore):
```
# Binaries
bin/
*.exe

# Vendor (if using modules, don't commit vendor/)
vendor/

# Build artifacts
*.test
```

---

##### .gitignore Decision Tree

```
Is it a devcontainer config file?
‚îú‚îÄ devcontainer.json, Dockerfile, docker-compose.yml
‚îÇ   ‚Üí COMMIT (team needs it)
‚îÇ
‚îú‚îÄ devcontainer.local.json, .env.local
‚îÇ   ‚Üí IGNORE (personal overrides)
‚îÇ
‚îî‚îÄ init scripts, setup.sh
    ‚Üí COMMIT (part of automated setup)

Is it a personal setting or credential?
‚îú‚îÄ .claude/settings.local.json, API keys, tokens
‚îÇ   ‚Üí IGNORE (sensitive data)
‚îÇ
‚îú‚îÄ .vscode/settings.json
‚îÇ   ‚Üí COMMIT (team workspace settings)
‚îÇ
‚îî‚îÄ .vscode/settings.local.json
    ‚Üí IGNORE (personal preferences)

Is it generated by tools?
‚îú‚îÄ node_modules/, venv/, __pycache__
‚îÇ   ‚Üí IGNORE (regenerated from lock files)
‚îÇ
‚îú‚îÄ package-lock.json, poetry.lock
‚îÇ   ‚Üí COMMIT (ensures reproducibility)
‚îÇ
‚îî‚îÄ dist/, build/, *.pyc
    ‚Üí IGNORE (build artifacts)
```

---

### Step-by-Step Creation Process

Now that you understand essential configuration files, follow these steps to create a complete devcontainer.

#### Step 1: Create Directory Structure

```bash
# From project root
mkdir -p .devcontainer
cd .devcontainer
```

**Result**:
```
your-project/
‚îú‚îÄ‚îÄ .devcontainer/    ‚Üê New directory
‚îî‚îÄ‚îÄ [your existing files]
```

---

#### Step 2: Create .dockerignore (Project Root)

```bash
# Return to project root
cd ..

# Create .dockerignore based on your language
# (Use examples from "Essential Configuration Files" above)
```

**For Node.js**:
```bash
cat > .dockerignore << 'EOF'
node_modules/
.npm/
dist/
.env*
.git/
.vscode/
README.md
*.log
EOF
```

**For Python**:
```bash
cat > .dockerignore << 'EOF'
venv/
.venv/
__pycache__/
*.pyc
.env*
.git/
.vscode/
*.log
EOF
```

---

#### Step 3: Update .gitignore

```bash
# Add devcontainer-specific patterns
cat >> .gitignore << 'EOF'

# Devcontainer personal settings
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
.claude/settings.local.json
.claude/cache/
.claude/logs/
EOF
```

**Verify .devcontainer/ is NOT ignored**:
```bash
# This should return nothing
grep "^\.devcontainer/$" .gitignore

# If it returns a match, remove that line!
```

---

#### Step 4: Create devcontainer.json

Choose your approach:

**Option A: Use Base Image (Fastest)**
```bash
cat > .devcontainer/devcontainer.json << 'EOF'
{
  "name": "My Dev Container",
  "image": "node:20",
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code"
      ]
    }
  },
  "postCreateCommand": "npm install",
  "remoteUser": "node",
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume"
  ]
}
EOF
```

**Option B: Use Dockerfile (Custom)**
```bash
cat > .devcontainer/devcontainer.json << 'EOF'
{
  "name": "My Dev Container",
  "build": {
    "dockerfile": "Dockerfile"
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code"
      ]
    }
  },
  "postCreateCommand": "npm install",
  "remoteUser": "node",
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume"
  ]
}
EOF
```

---

#### Step 5: Create Dockerfile (If Using Option B)

```bash
cat > .devcontainer/Dockerfile << 'EOF'
FROM node:20

# Install system packages
RUN apt-get update && \
    apt-get install -y git curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Switch to non-root user
USER node

# Install Claude Code globally
RUN npm install -g @anthropic-ai/claude-code@latest

WORKDIR /workspaces
EOF
```

---

#### Step 6: Validate Configuration

```bash
# Check JSON syntax
jq . .devcontainer/devcontainer.json

# Verify .dockerignore exists
ls -la .dockerignore

# Verify .devcontainer/ will be committed
git status .devcontainer/
# Should show: new file: .devcontainer/devcontainer.json
```

---

#### Step 7: Test the Devcontainer

**In VS Code**:
1. Open Command Palette: `Cmd+Shift+P` (Mac) / `Ctrl+Shift+P` (Windows/Linux)
2. Select: `Dev Containers: Reopen in Container`
3. Wait for build to complete (5-15 minutes first time)
4. Verify terminal opens inside container:
   ```bash
   # Check you're inside container
   hostname
   # => Should show container ID (e.g., a1b2c3d4e5f6)

   # Check Node version
   node --version
   # => Should show v20.x.x

   # Check Claude Code installed
   claude --version
   ```

---

#### Step 8: Commit Your Configuration

```bash
# Stage devcontainer files
git add .devcontainer/
git add .dockerignore
git add .gitignore

# Commit
git commit -m "Add devcontainer configuration

- Node.js 20 base image
- Claude Code pre-installed
- Optimized .dockerignore for build performance
- Updated .gitignore for devcontainer personal settings"

# Push to remote
git push
```

**Team members can now**:
```bash
git pull
code .
# Click "Reopen in Container"
# Start coding immediately!
```

---

### Validation Checklist

Before sharing with your team, verify:

- [ ] `.dockerignore` exists and excludes `node_modules/`, `.git/`, `dist/`
- [ ] `.gitignore` does NOT ignore `.devcontainer/` directory
- [ ] `.gitignore` DOES ignore `.claude/settings.local.json`
- [ ] `devcontainer.json` has valid JSON syntax
- [ ] `devcontainer.json` includes necessary VS Code extensions
- [ ] Container builds successfully (`docker build .devcontainer`)
- [ ] Container starts and you can open a terminal inside it
- [ ] Tools are accessible (e.g., `node --version`, `python --version`)
- [ ] Volumes persist data across rebuilds (test: create file, rebuild, check file exists)
- [ ] Port forwarding works (test: run dev server, access from host browser)

---

### Quick Troubleshooting

**Build is slow (>10 minutes)**:
- ‚úÖ Check `.dockerignore` excludes `node_modules/`, `.git/`
- ‚úÖ Verify Docker Desktop has sufficient resources (Settings ‚Üí Resources)
- ‚úÖ Use multi-stage Dockerfile to cache dependencies

**"Permission denied" errors**:
- ‚úÖ Ensure `remoteUser` matches Dockerfile user (e.g., `"remoteUser": "node"`)
- ‚úÖ Verify volume mounts target user's home directory (`/home/node`)

**.devcontainer/ changes not reflected**:
- ‚úÖ Rebuild container: `Cmd+Shift+P` ‚Üí `Dev Containers: Rebuild Container`
- ‚úÖ Don't just "Reopen in Container" (uses cached image)

**API keys not working**:
- ‚úÖ Check `.env` is NOT in `.dockerignore` (if needed during build)
- ‚úÖ Use `containerEnv` or `remoteEnv` in `devcontainer.json` for runtime vars
- ‚úÖ Ensure `.env.local` is in `.gitignore` (don't commit secrets!)

---

### Next Steps

Once your devcontainer is working:

1. **Add MCP servers**: See [MCP Server Setup](#mcp-server-setup)
2. **Optimize performance**: See [Resource and Performance Considerations](#resource-and-performance-considerations)
3. **Set up CI/CD**: See [Prebuild Images & CI/CD Automation](#prebuild-images--cicd-automation)
4. **Enhance security**: See [Security Best Practices](#security-best-practices)
5. **Create team template**: See [Creating & Distributing Templates](#creating--distributing-templates)

---

## Prebuild Images & CI/CD Automation

> **AI Assistant Guidance**: Prebuild images dramatically improve devcontainer startup time and enable enterprise-scale adoption. Recommend prebuilds for teams with >3 developers or complex build processes.

**Official Guide**: https://containers.dev/guide/prebuild

### What Are Prebuild Images?

**Prebuild images** are pre-constructed container images that package all dependencies, tools, and configurations needed for a development environment. Instead of building from scratch each time a developer opens a project, they **pull an already-built image**.

**Analogy**: Like using a Docker image vs. compiling from source every time.

### The Problem Prebuilds Solve

**Without prebuilds**:
```
Developer 1: Opens project ‚Üí Builds from Dockerfile (15 min) ‚Üí Starts coding
Developer 2: Opens project ‚Üí Builds from Dockerfile (15 min) ‚Üí Starts coding
Developer 3: Opens project ‚Üí Builds from Dockerfile (15 min) ‚Üí Starts coding
Developer 4: Opens project ‚Üí Builds from Dockerfile (15 min) ‚Üí Starts coding

Total wasted time: 60 minutes
```

**With prebuilds**:
```
CI/CD: Builds image once (15 min) ‚Üí Pushes to registry
Developer 1: Opens project ‚Üí Pulls prebuild (2 min) ‚Üí Starts coding
Developer 2: Opens project ‚Üí Pulls prebuild (2 min) ‚Üí Starts coding
Developer 3: Opens project ‚Üí Pulls prebuild (2 min) ‚Üí Starts coding
Developer 4: Opens project ‚Üí Pulls prebuild (2 min) ‚Üí Starts coding

Total time: 15 min (CI) + 8 min (team) = 23 minutes
Savings: 60% faster for team
```

### Why Use Prebuild Images?

#### 1. **Speed**
- Eliminates build time (potentially hours for complex stacks)
- Developers start coding in 1-2 minutes vs. 10-60 minutes
- New team members productive immediately

#### 2. **Consistency**
- All developers use **identical** environments
- No "works on my machine" issues
- Pinned dependency versions

#### 3. **Security**
- Pin specific tool versions for supply-chain security
- Scan images for vulnerabilities before distribution
- Control exactly what's in the environment

#### 4. **Simplicity**
- `devcontainer.json` can be just:
  ```json
  {
    "image": "ghcr.io/myorg/myproject-devcontainer:latest"
  }
  ```
- No Dockerfile management per project
- Single source of truth for environment

### Creating Prebuild Images

#### Prerequisites

Install the Dev Container CLI:
```bash
npm install -g @devcontainers/cli
```

**Docs**: https://github.com/devcontainers/cli

#### Step 1: Configure Your Devcontainer

Your project has a working `.devcontainer/` setup:
```
.devcontainer/
‚îú‚îÄ‚îÄ devcontainer.json
‚îî‚îÄ‚îÄ Dockerfile
```

#### Step 2: Build the Prebuild Image

```bash
# Build and push to registry
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-devcontainer:1.0.0
```

**Explanation**:
- `--workspace-folder .`: Project root directory
- `--push true`: Push to registry after building
- `--image-name`: Full image name with tag

**Alternative (build only, no push)**:
```bash
devcontainer build \
  --workspace-folder . \
  --image-name myproject-devcontainer:latest
```

#### Step 3: Update devcontainer.json

Replace Dockerfile reference with image reference:

**Before (build from Dockerfile)**:
```json
{
  "name": "My Project",
  "build": {
    "dockerfile": "Dockerfile"
  }
}
```

**After (use prebuild)**:
```json
{
  "name": "My Project",
  "image": "ghcr.io/myorg/myproject-devcontainer:1.0.0"
}
```

### Publishing to Registries

#### GitHub Container Registry (GHCR)

**Authentication**:
```bash
# Create Personal Access Token (PAT) with write:packages scope
# https://github.com/settings/tokens

# Login to GHCR
echo $GHCR_TOKEN | docker login ghcr.io -u USERNAME --password-stdin
```

**Build and push**:
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-devcontainer:1.0.0
```

**Image URL**: `ghcr.io/<org>/<repo>/<image>:<tag>`

**Official Docs**: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry

---

#### Azure Container Registry (ACR)

**Authentication**:
```bash
az login
az acr login --name myregistry
```

**Build and push**:
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name myregistry.azurecr.io/myproject-devcontainer:1.0.0
```

**Official Docs**: https://learn.microsoft.com/en-us/azure/container-registry/

---

#### Docker Hub

**Authentication**:
```bash
docker login
```

**Build and push**:
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name myusername/myproject-devcontainer:1.0.0
```

**Image URL**: `docker.io/<username>/<image>:<tag>` or simply `<username>/<image>:<tag>`

**Official Docs**: https://docs.docker.com/docker-hub/

---

### GitHub Actions Automation

Automate prebuild creation on every commit or PR.

#### Official GitHub Action

**Action**: https://github.com/marketplace/actions/dev-container-build-and-run-action

**.github/workflows/devcontainer-prebuild.yml**:
```yaml
name: Build Dev Container Prebuild

on:
  push:
    branches: [main]
    paths:
      - '.devcontainer/**'
  pull_request:
    paths:
      - '.devcontainer/**'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pre-build dev container image
        uses: devcontainers/ci@v0.3
        with:
          imageName: ghcr.io/${{ github.repository }}/devcontainer
          cacheFrom: ghcr.io/${{ github.repository }}/devcontainer
          push: always
```

**Key features**:
- **Triggers**: Runs when `.devcontainer/` changes
- **Authentication**: Uses automatic `GITHUB_TOKEN`
- **Caching**: Uses previous builds for speed
- **Push**: Always pushes to GHCR

**Official Docs**: https://github.com/devcontainers/ci

---

#### Azure DevOps Pipeline

**Task**: https://marketplace.visualstudio.com/items?itemName=devcontainers.ci

**azure-pipelines.yml**:
```yaml
trigger:
  paths:
    include:
      - .devcontainer/*

pool:
  vmImage: 'ubuntu-latest'

steps:
  - task: DevContainersCi@1
    inputs:
      imageName: '$(imageRegistry)/$(imageName)'
      push: 'always'
      cacheFrom: '$(imageRegistry)/$(imageName)'
```

---

### Official Prebuild Images

Microsoft maintains official prebuild images for common stacks.

**Registry**: `mcr.microsoft.com/devcontainers/*`

#### Popular Official Images

**Node.js**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/typescript-node:20"
}
```

**Python**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/python:3.11"
}
```

**Go**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/go:1.21"
}
```

**Rust**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/rust:latest"
}
```

**Universal (multi-language)**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/universal:latest"
}
```

**Full catalog**: https://github.com/devcontainers/images

---

### Prebuild vs Dockerfile Comparison

| Aspect | Dockerfile (Build) | Prebuild Image |
|--------|-------------------|----------------|
| **First-time setup** | 5-60 minutes | 1-2 minutes |
| **Subsequent opens** | 0-5 minutes (cached) | 1-2 minutes |
| **Team consistency** | Depends on Docker cache | Guaranteed identical |
| **Security** | Build-time vulnerabilities | Scan before distribution |
| **CI/CD integration** | Builds in pipeline | Pre-built, just test |
| **Disk space (local)** | One layer cache per dev | One image shared |
| **Customization** | Full control | Limited to runtime config |
| **Best for** | Rapid iteration, custom needs | Team standardization, speed |

---

### Versioning Strategy

**Semantic Versioning** recommended:

```bash
# Major version (breaking changes)
ghcr.io/myorg/myproject:2.0.0

# Minor version (new features)
ghcr.io/myorg/myproject:1.1.0

# Patch version (bug fixes)
ghcr.io/myorg/myproject:1.0.1

# Latest (rolling)
ghcr.io/myorg/myproject:latest
```

**Best practice**: Pin to specific version in devcontainer.json, use `latest` for testing:

```json
{
  "image": "ghcr.io/myorg/myproject:1.2.3"
}
```

---

### Multi-stage Dockerfiles: Dev ‚Üí Production

Use same Dockerfile for dev prebuilds and production images:

**Dockerfile**:
```dockerfile
# Development stage
FROM node:20 AS development
RUN apt-get update && apt-get install -y git vim curl
RUN npm install -g @anthropic-ai/claude-code@latest
COPY package*.json ./
RUN npm install
COPY . .

# Production stage (smaller, optimized)
FROM node:20-slim AS production
WORKDIR /app
COPY --from=development /app/dist ./dist
COPY --from=development /app/package*.json ./
RUN npm ci --only=production
CMD ["node", "dist/index.js"]
```

**devcontainer.json** (use dev stage):
```json
{
  "build": {
    "dockerfile": "Dockerfile",
    "target": "development"
  }
}
```

**Prebuild command** (build dev stage):
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-devcontainer:1.0.0
```

**Docker build** (production):
```bash
docker build --target production -t myorg/myproject:1.0.0 .
```

---

### Image Labels & Metadata

Include metadata via Docker labels for self-contained images:

**Dockerfile**:
```dockerfile
LABEL org.opencontainers.image.source="https://github.com/myorg/myproject"
LABEL org.opencontainers.image.description="Development environment for MyProject"
LABEL org.opencontainers.image.version="1.0.0"
LABEL devcontainer.metadata='{"features":{"node":"20","python":"3.11"}}'
```

**View labels**:
```bash
docker inspect ghcr.io/myorg/myproject:1.0.0 | jq '.[0].Config.Labels'
```

---

### CI/CD Integration Patterns

#### Pattern 1: Nightly Builds
Update prebuilds nightly to include latest security patches:

```yaml
on:
  schedule:
    - cron: '0 2 * * *'  # 2 AM daily
```

#### Pattern 2: PR Preview Environments
Build unique prebuild per PR for testing:

```yaml
imageName: ghcr.io/${{ github.repository }}/devcontainer:pr-${{ github.event.pull_request.number }}
```

#### Pattern 3: Multi-platform Builds
Build for ARM64 (M1/M2 Macs) and AMD64:

```yaml
- name: Set up Docker Buildx
  uses: docker/setup-buildx-action@v3

- name: Build multi-platform image
  run: |
    devcontainer build \
      --workspace-folder . \
      --platform linux/amd64,linux/arm64 \
      --push true \
      --image-name ghcr.io/myorg/myproject:latest
```

---

### Best Practices

1. **Use Features**: Organize dependencies as Features for modularity
2. **Layer Caching**: Order Dockerfile commands by change frequency (rare ‚Üí frequent)
3. **Security Scanning**: Scan images with `trivy` or `snyk` before pushing
4. **Documentation**: Include README in image describing contents
5. **Tagging**: Use semantic versioning + `latest` tag
6. **Size Optimization**: Use slim/alpine base images when possible
7. **Testing**: Test prebuild in CI before distributing to team

---

### Example: Complete Prebuild Workflow

**1. Initial Setup**

**.devcontainer/devcontainer.json**:
```json
{
  "name": "MyProject Dev",
  "build": {
    "dockerfile": "Dockerfile"
  },
  "features": {
    "ghcr.io/devcontainers/features/node:1": {"version": "20"},
    "ghcr.io/devcontainers/features/docker-in-docker:2": {}
  },
  "customizations": {
    "vscode": {
      "extensions": ["anthropic.claude-code"]
    }
  }
}
```

**.devcontainer/Dockerfile**:
```dockerfile
FROM node:20
RUN apt-get update && apt-get install -y git && apt-get clean
USER node
RUN npm install -g @anthropic-ai/claude-code@latest
```

**2. Build Prebuild Locally**

```bash
devcontainer build \
  --workspace-folder . \
  --image-name myproject-dev:test

# Test locally
docker run -it myproject-dev:test bash
```

**3. Push to Registry**

```bash
# Login
echo $GHCR_TOKEN | docker login ghcr.io -u myusername --password-stdin

# Build and push
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-dev:1.0.0
```

**4. Update devcontainer.json**

```json
{
  "name": "MyProject Dev",
  "image": "ghcr.io/myorg/myproject-dev:1.0.0",
  "customizations": {
    "vscode": {
      "extensions": ["anthropic.claude-code"]
    }
  }
}
```

**5. Set Up GitHub Actions**

**.github/workflows/devcontainer-prebuild.yml**: (see earlier example)

**6. Team Usage**

Team members simply:
```bash
git clone https://github.com/myorg/myproject
code myproject
# Click "Reopen in Container"
# 2 minutes later, ready to code!
```

---

### Sources
- **Official Prebuild Guide**: https://containers.dev/guide/prebuild
- **Dev Container CLI**: https://github.com/devcontainers/cli
- **CLI Documentation**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md
- **GitHub Actions**: https://github.com/devcontainers/ci
- **Official Images**: https://github.com/devcontainers/images
- **Azure DevOps Task**: https://marketplace.visualstudio.com/items?itemName=devcontainers.ci

---


---

## Creating & Distributing Templates

> **AI Assistant Guidance**: Templates enable rapid project bootstrapping and organization-wide standardization. Recommend templates for platform teams, large organizations, and open-source communities.

**Official Specification**: https://containers.dev/implementors/templates-distribution/

### What Are Devcontainer Templates?

**Dev Container Templates** are reusable, pre-configured development environment packages that can be distributed and applied to projects. They enable:

- **Rapid Project Bootstrapping**: Initialize new projects with complete devcontainer configs
- **Organization Standards**: Share company-wide development environment patterns
- **Community Sharing**: Distribute best practices publicly
- **Self-Service**: Developers discover and apply templates through VS Code UI

**Analogy**: Like project templates in IDEs (e.g., "Create React App"), but for entire development environments.

### Templates vs Prebuild Images vs Features

| Aspect | Template | Prebuild Image | Feature |
|--------|----------|----------------|---------|
| **What** | Full devcontainer config + files | Pre-built container image | Modular tool installation |
| **Contains** | devcontainer.json + scripts + docs | OS + tools + dependencies | Single tool/capability |
| **When to use** | Starting new project | Team standardization | Adding capability to existing setup |
| **Distribution** | OCI registry as tarball | Container registry as image | OCI registry as tarball |
| **Customization** | Template options (prompts) | Limited (runtime only) | Feature options |
| **User interaction** | Apply once at project creation | Pull on every container start | Declared in devcontainer.json |
| **Example** | "Python FastAPI project" | `mcr.microsoft.com/devcontainers/python:3.11` | `ghcr.io/devcontainers/features/python:1` |

---

### Template Structure

Templates follow a standardized directory organization:

```
src/
‚îú‚îÄ‚îÄ my-template/                        # Template ID
‚îÇ   ‚îú‚îÄ‚îÄ devcontainer-template.json     # Metadata (required)
‚îÇ   ‚îú‚îÄ‚îÄ .devcontainer/                 # Config directory (required)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devcontainer.json          # Devcontainer config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                 # Optional custom image
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml         # Optional compose file
‚îÇ   ‚îú‚îÄ‚îÄ .vscode/                       # Optional VS Code settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.json
‚îÇ   ‚îú‚îÄ‚îÄ scripts/                       # Optional helper scripts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ setup.sh
‚îÇ   ‚îú‚îÄ‚îÄ README.md                      # Optional documentation
‚îÇ   ‚îî‚îÄ‚îÄ [additional files]             # Any other files to include
```

**Key files**:
1. **devcontainer-template.json**: Template metadata
2. **.devcontainer/devcontainer.json**: The actual devcontainer configuration
3. **Any additional files**: Copied to project when template is applied

---

### Creating a Template from Scratch

#### Step 1: Use Template Starter Repository

The official template starter provides a complete scaffold:

```bash
# Clone template starter
git clone https://github.com/devcontainers/template-starter.git my-templates
cd my-templates
```

**Repository**: https://github.com/devcontainers/template-starter

**Structure provided**:
```
my-templates/
‚îú‚îÄ‚îÄ src/                    # Your templates go here
‚îÇ   ‚îú‚îÄ‚îÄ color/             # Example template
‚îÇ   ‚îî‚îÄ‚îÄ hello/             # Another example
‚îú‚îÄ‚îÄ test/                   # Template tests
‚îî‚îÄ‚îÄ .github/workflows/      # Automated publishing
```

---

#### Step 2: Create Template Metadata

**src/my-python-template/devcontainer-template.json**:

```json
{
  "id": "my-python-template",
  "version": "1.0.0",
  "name": "Python FastAPI Project",
  "description": "FastAPI project with PostgreSQL, Redis, and testing setup",
  "documentationURL": "https://github.com/myorg/templates/tree/main/src/my-python-template",
  "publisher": "MyOrg",
  "licenseURL": "https://github.com/myorg/templates/blob/main/LICENSE",
  "options": {
    "pythonVersion": {
      "type": "string",
      "description": "Python version",
      "proposals": ["3.11", "3.10", "3.9"],
      "default": "3.11"
    },
    "includeDocker": {
      "type": "boolean",
      "description": "Include Docker-in-Docker support",
      "default": false
    },
    "database": {
      "type": "string",
      "description": "Database to include",
      "proposals": ["postgres", "mysql", "none"],
      "default": "postgres"
    }
  }
}
```

**Key fields**:
- **id**: Unique identifier (used in OCI registry path)
- **version**: Semantic version (1.0.0, 2.1.3, etc.)
- **name**: Human-readable display name
- **description**: Shown in template picker
- **options**: User-configurable parameters with defaults

**Official Metadata Spec**: https://containers.dev/implementors/templates/#devcontainer-template.json-properties

---

#### Step 3: Create Devcontainer Configuration

**src/my-python-template/.devcontainer/devcontainer.json**:

```json
{
  "name": "Python FastAPI Project",
  "image": "mcr.microsoft.com/devcontainers/python:${templateOption:pythonVersion}",
  "features": {
    "ghcr.io/devcontainers/features/docker-in-docker:2": {
      "enableNonRootDocker": "true"
    }
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance",
        "charliermarsh.ruff"
      ]
    }
  },
  "forwardPorts": [8000],
  "postCreateCommand": "pip install -r requirements.txt",
  "remoteUser": "vscode"
}
```

**Template variables**:
- `${templateOption:optionName}`: Replaced with user-selected option value
- `${templateOption:pythonVersion}` ‚Üí `"3.11"` (from user choice)

---

#### Step 4: Add Supporting Files

**src/my-python-template/requirements.txt**:
```
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
alembic==1.12.1
pytest==7.4.3
```

**src/my-python-template/docker-compose.yml** (if database option selected):
```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: devuser
      POSTGRES_PASSWORD: devpass
      POSTGRES_DB: devdb
    volumes:
      - postgres-data:/var/lib/postgresql/data

volumes:
  postgres-data:
```

**src/my-python-template/README.md**:
```markdown
# Python FastAPI Template

This template provides a complete FastAPI development environment with:
- Python ${templateOption:pythonVersion}
- PostgreSQL database
- Testing with pytest
- Linting with Ruff

### Getting Started with Templates (Official Examples)

1. Start the dev container
2. Run `uvicorn main:app --reload`
3. Open http://localhost:8000
```

---

#### Step 5: Test Template Locally

```bash
# Install Dev Container CLI
npm install -g @devcontainers/cli

# Test template application
devcontainer templates apply \
  --template-id my-python-template \
  --template-args '{"pythonVersion": "3.11", "database": "postgres"}' \
  --workspace-folder ./test-project
```

This creates `test-project/.devcontainer/` with your template applied.

---

### Publishing Templates

Templates are distributed as **tarballs** to **OCI registries** (same infrastructure as Docker images).

#### Packaging

Templates are packaged following the naming convention:
```
devcontainer-template-<id>.tgz
```

**Tarball contents**:
- devcontainer-template.json
- .devcontainer/devcontainer.json
- All additional files in template directory

**Media type**: `application/vnd.devcontainers.layer.v1+tar`

---

#### Publishing to GitHub Container Registry (GHCR)

**Prerequisites**:
1. GitHub repository with templates in `src/` directory
2. GitHub Personal Access Token with `write:packages` scope
3. Dev Container CLI installed

**Manual publish**:

```bash
# Set authentication
export GITHUB_TOKEN="your-pat-token"

# Publish all templates in src/
devcontainer templates publish \
  -r ghcr.io \
  -n myorg/templates \
  ./src
```

**Result**: Templates published to:
```
ghcr.io/myorg/templates/my-python-template:1.0.0
ghcr.io/myorg/templates/my-node-template:1.0.0
```

**Official CLI Docs**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md#templates-publish

---

#### Automated Publishing with GitHub Actions

The template-starter repository includes pre-configured GitHub Actions.

**.github/workflows/release.yml** (provided by template-starter):

```yaml
name: Release Templates

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Publish templates to GHCR
        uses: devcontainers/action@v1
        with:
          publish-templates: "true"
          base-path-to-templates: "./src"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

**Trigger**: Automatically publishes on every push to `main`.

**Authentication**: Uses automatic `GITHUB_TOKEN` (no manual PAT needed).

---

#### Publishing to Private Registries

**Azure Container Registry (ACR)**:
```bash
# Login
az acr login --name myregistry

# Publish
devcontainer templates publish \
  -r myregistry.azurecr.io \
  -n templates \
  ./src
```

**Docker Hub**:
```bash
# Login
docker login

# Publish
devcontainer templates publish \
  -r docker.io \
  -n myusername/templates \
  ./src
```

---

### Consuming Templates

#### Via VS Code UI

**For Users**:

1. **Command Palette** (`Cmd+Shift+P` / `Ctrl+Shift+P`)
2. Type: **"Dev Containers: Add Dev Container Configuration Files"**
3. Select **"Show All Definitions"**
4. Search for your template (e.g., "Python FastAPI")
5. Select template
6. Configure options (Python version, database, etc.)
7. VS Code applies template to `.devcontainer/`

**Discovery**: VS Code automatically discovers templates from:
- Official registry (`ghcr.io/devcontainers/templates/*`)
- Community templates (popular public repos)
- Your organization's registry (if configured)

---

#### Via CLI

**Apply template to existing project**:

```bash
devcontainer templates apply \
  -t ghcr.io/myorg/templates/my-python-template \
  -a '{"pythonVersion": "3.11", "database": "postgres"}' \
  -w .
```

**Flags**:
- `-t, --template-id`: Template identifier (registry path or local path)
- `-a, --template-args`: JSON object with option values
- `-w, --workspace-folder`: Target directory (`.` for current)

**Result**: Creates `.devcontainer/` with template applied.

---

#### In GitHub Codespaces

**Automatic**: When opening a repository in Codespaces, if it has `.devcontainer/`, Codespaces uses it.

**Manual template selection**:
1. Open repository in browser
2. Click **"Code"** ‚Üí **"Codespaces"** ‚Üí **"..."** ‚Üí **"New with options"**
3. Select dev container configuration template
4. Customize options
5. Create Codespace

Codespaces applies template and builds environment in the cloud.

---

### Official Templates Repository

**Repository**: https://github.com/devcontainers/templates
**Registry**: `ghcr.io/devcontainers/templates/*`
**Browser**: https://containers.dev/templates

#### Popular Official Templates

**Language Templates**:
- `alpine` - Minimal Alpine Linux
- `dotnet` - .NET development
- `go` - Go toolchain
- `java` - Java with Maven/Gradle
- `javascript-node` - Node.js
- `php` - PHP with Composer
- `python` - Python 3
- `ruby` - Ruby
- `rust` - Rust
- `typescript-node` - TypeScript + Node.js

**Framework Templates**:
- `docker-from-docker` - Docker-in-Docker
- `docker-outside-of-docker` - Docker from host
- `kubernetes-helm` - Kubernetes development
- `anaconda-postgres` - Anaconda + PostgreSQL

**Example usage**:
```json
{
  "image": "mcr.microsoft.com/devcontainers/python:3.11"
}
```

Or apply via CLI:
```bash
devcontainer templates apply \
  -t ghcr.io/devcontainers/templates/python \
  -a '{"imageVariant": "3.11"}' \
  -w .
```

---

### Template Best Practices

#### 1. Clear Metadata
```json
{
  "name": "Specific, Descriptive Name",
  "description": "Explain what this template provides and who it's for",
  "keywords": ["python", "fastapi", "postgresql"]
}
```

#### 2. Comprehensive Documentation

Include `README.md` in template:
```markdown
# Template Name

### What's Included in Template Starter
- Tool 1
- Tool 2

### Getting Started Creating Templates
1. Step 1
2. Step 2

### Template Configuration Options
- `option1`: Description
- `option2`: Description
```

#### 3. Useful Options

Expose meaningful options:
```json
{
  "options": {
    "nodeVersion": {
      "type": "string",
      "proposals": ["20", "18", "16"],
      "default": "20",
      "description": "Node.js version to install"
    },
    "includeDocker": {
      "type": "boolean",
      "default": false,
      "description": "Include Docker-in-Docker for container builds"
    }
  }
}
```

#### 4. Testing Before Publishing

Test template locally:
```bash
# Apply template
devcontainer templates apply -t ./src/my-template -w ./test-dir

# Open in VS Code
code test-dir

# Test in container
# (Verify all tools work, scripts run, etc.)
```

#### 5. Versioning

Use semantic versioning:
- **Patch** (1.0.1): Bug fixes, documentation
- **Minor** (1.1.0): New options, backward-compatible features
- **Major** (2.0.0): Breaking changes, incompatible updates

Update `devcontainer-template.json`:
```json
{
  "version": "1.2.0"
}
```

#### 6. Security

- Pin dependency versions in Dockerfile/requirements
- Scan images for vulnerabilities
- Don't include secrets or credentials
- Use official base images when possible

---

### Versioning & Updates

Templates use **semantic versioning** independently:

**src/template-a/devcontainer-template.json**:
```json
{
  "id": "template-a",
  "version": "1.2.0"
}
```

**src/template-b/devcontainer-template.json**:
```json
{
  "id": "template-b",
  "version": "2.0.1"
}
```

**Publishing behavior**:
- Publishing tools won't republish if version unchanged
- Must increment version for updates to distribute
- Collection metadata (`devcontainer-collection.json`) tracks all template versions

---

### Advanced: Template Options Conditional Logic

Use template options to conditionally include features:

**devcontainer-template.json**:
```json
{
  "options": {
    "includeDocker": {
      "type": "boolean",
      "default": false
    }
  }
}
```

**devcontainer.json**:
```json
{
  "features": {
    "ghcr.io/devcontainers/features/docker-in-docker:2": "${templateOption:includeDocker}"
  }
}
```

If user selects `includeDocker: true`, feature is included. If `false`, it's removed during template application.

---

### Example: Complete Template Workflow

#### 1. Create Template Repository

```bash
git clone https://github.com/devcontainers/template-starter.git myorg-templates
cd myorg-templates
```

#### 2. Create Custom Template

**src/react-typescript-template/devcontainer-template.json**:
```json
{
  "id": "react-typescript-template",
  "version": "1.0.0",
  "name": "React + TypeScript + Tailwind",
  "description": "Complete React development environment with TypeScript, Tailwind CSS, and testing",
  "options": {
    "nodeVersion": {
      "type": "string",
      "proposals": ["20", "18"],
      "default": "20"
    }
  }
}
```

**src/react-typescript-template/.devcontainer/devcontainer.json**:
```json
{
  "name": "React TypeScript Project",
  "image": "mcr.microsoft.com/devcontainers/typescript-node:${templateOption:nodeVersion}",
  "customizations": {
    "vscode": {
      "extensions": [
        "dbaeumer.vscode-eslint",
        "esbenp.prettier-vscode",
        "bradlc.vscode-tailwindcss"
      ]
    }
  },
  "forwardPorts": [3000],
  "postCreateCommand": "npm install"
}
```

**src/react-typescript-template/package.json**:
```json
{
  "name": "react-app",
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "typescript": "^5.0.0",
    "vite": "^5.0.0",
    "tailwindcss": "^3.3.0"
  }
}
```

#### 3. Test Locally

```bash
devcontainer templates apply \
  -t ./src/react-typescript-template \
  -a '{"nodeVersion": "20"}' \
  -w ./test-project

code test-project
```

#### 4. Publish to GHCR

```bash
# Commit changes
git add src/react-typescript-template
git commit -m "Add React TypeScript template v1.0.0"
git push origin main

# GitHub Actions automatically publishes to ghcr.io/myorg/templates/react-typescript-template:1.0.0
```

#### 5. Team Uses Template

Team members in VS Code:
1. Command Palette ‚Üí "Add Dev Container Configuration"
2. Select "React + TypeScript + Tailwind"
3. Choose Node version
4. Template applied, ready to code!

---

### Sources
- **Official Templates Specification**: https://containers.dev/implementors/templates-distribution/
- **Template Distribution**: https://containers.dev/implementors/templates/
- **Template Repository**: https://github.com/devcontainers/templates
- **Template Starter**: https://github.com/devcontainers/template-starter
- **CLI Reference**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md
- **Official Template Browser**: https://containers.dev/templates

---

### Method 1: Start from Scratch (Full Control)

#### Step 1: Create Directory Structure

```bash
mkdir -p .devcontainer
cd .devcontainer
```

#### Step 2: Create devcontainer.json

Create `.devcontainer/devcontainer.json`:

```json
{
  "name": "Claude Code - ${localWorkspaceFolderBasename}",
  "build": {
    "dockerfile": "Dockerfile"
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code"
      ],
      "settings": {
        "terminal.integrated.defaultProfile.linux": "bash"
      }
    }
  },
  "remoteUser": "node",
  "mounts": [
    "source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume"
  ],
  "containerEnv": {
    "CLAUDE_CONFIG_DIR": "/home/node/.claude"
  },
  "workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}",
  "postStartCommand": "echo 'Container ready!'"
}
```

**Key Configuration Points**:
- `name`: Human-readable name shown in VS Code status bar
- `build.dockerfile`: Path to Dockerfile (relative to devcontainer.json)
- `customizations.vscode.extensions`: VS Code extensions to auto-install
- `remoteUser`: User account inside container (typically "node", "vscode", or "python")
- `mounts`: Persistent volumes for configuration (survives rebuilds)
- `containerEnv`: Environment variables available in container
- `workspaceFolder`: Where your project appears inside the container
- `postStartCommand`: Commands to run after container starts

#### Step 3: Create Dockerfile

Create `.devcontainer/Dockerfile`:

```dockerfile
FROM node:20

# Install essential tools
RUN apt-get update && apt-get install -y --no-install-recommends \
  git \
  curl \
  ca-certificates \
  sudo \
  && apt-get clean && rm -rf /var/lib/apt/lists/*

# Set up locale for UTF-8 support (prevents encoding issues)
RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen && \
  locale-gen
ENV LANG=en_US.UTF-8 \
  LANGUAGE=en_US:en \
  LC_ALL=en_US.UTF-8

# Create config directory
RUN mkdir -p /home/node/.claude && \
  chown -R node:node /home/node/.claude

# Set working directory
WORKDIR /workspaces

# Switch to node user for tool installation
USER node

# Install Claude Code
RUN npm install -g @anthropic-ai/claude-code@latest

# Configure git to ignore local settings (prevents accidental API key commits)
RUN git config --global core.excludesfile ~/.gitignore_global && \
  echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

**Key Dockerfile Patterns**:
- Start with a stable base image (`node:20`, `python:3.11`, etc.)
- Install system dependencies as `root`
- Set up locale for proper UTF-8 support (critical for AI tools)
- Create directories and set permissions **before** switching users
- Switch to non-root user for tool installation (security best practice)
- Configure git to protect sensitive files

#### Step 4: Open in VS Code

```bash
# From your project directory
cd /path/to/your/project
code .
```

VS Code will detect `.devcontainer/` and prompt: **"Reopen in Container"**

Click it, and VS Code will:
1. Build the Docker image (5-10 minutes first time)
2. Start the container
3. Connect VS Code to the container
4. Install extensions
5. Run post-start commands

**Subsequent opens are instant** (no rebuild unless you change Dockerfile).

#### Step 5: Verify Setup

```bash
# Inside container terminal (VS Code opens this automatically)
claude --version
node --version
git --version
```

### Method 2: Copy Reference Implementation

```bash
# Clone Anthropic's reference
git clone https://github.com/anthropics/claude-code.git
cd claude-code

# Copy to your project
cp -r .devcontainer /path/to/your/project/
cd /path/to/your/project
code .
```

### Method 3: Use This Repository as Template

If you're reading this llms.txt, the `.devcontainer/` directory in this repo is production-ready. Copy it to your project:

```bash
cp -r .devcontainer /path/to/your/project/
# Edit devcontainer.json and Dockerfile for your needs
```

### Method 4: VS Code Command Palette (Guided Setup)

1. Open VS Code in your project: `code /path/to/project`
2. Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)
3. Type: **"Dev Containers: Add Dev Container Configuration Files"**
4. Select a template (Node.js, Python, etc.)
5. Customize generated files
6. Command Palette ‚Üí **"Dev Containers: Reopen in Container"**

---

## Step-by-Step: Managing Devcontainers

## Lifecycle Hooks Explained

> **AI Assistant Guidance**: Understanding lifecycle hooks is critical for proper devcontainer configuration. Use this execution order diagram when helping users debug initialization issues.

**Official Documentation**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

Development containers execute commands at specific lifecycle stages. Each hook serves a distinct purpose with different access levels and execution contexts.

### Execution Order Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LOCAL MACHINE                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 1. initializeCommand                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs on host/local machine               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Before container exists                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Prepare local files, download deps  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CONTAINER (First Start Only)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 2. onCreateCommand                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs after container creation            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ No access to user secrets                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Install system packages             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                     ‚Üì                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 3. updateContentCommand                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs when workspace content updates      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ No access to user secrets                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Update dependencies (npm install)   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                     ‚Üì                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 4. postCreateCommand (waitFor default)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs after user assignment               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ HAS access to user secrets/assets        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs in BACKGROUND by default            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Setup that needs credentials        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CONTAINER (Every Start)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 5. postStartCommand                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs EVERY time container starts         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Start services (docker-compose up)  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CONTAINER (Every Attach)                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 6. postAttachCommand                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Runs every time tool attaches            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Ä¢ Use: Display welcome message             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Hook Details

#### 1. initializeCommand
**Location**: Local/host machine
**When**: Before container creation
**Access**: No container access
**Frequency**: Once per devcontainer configuration

**Use cases**:
- Pre-populate `node_modules/` on host before mounting
- Download large files to avoid container bloat
- Generate configuration files
- Validate prerequisites

**Example**:
```json
{
  "initializeCommand": "echo 'Preparing local workspace...' && npm install"
}
```

**Official Docs**: https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md#initializecommand

---

#### 2. onCreateCommand
**Location**: Inside container
**When**: After container creation (first start only)
**Access**: No user secrets or assets
**Frequency**: Once per container

**Use cases**:
- Install system packages (`apt-get install`)
- Clone git repositories
- Set up file permissions
- Initialize database schemas

**Example**:
```json
{
  "onCreateCommand": "apt-get update && apt-get install -y postgresql-client"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 3. updateContentCommand
**Location**: Inside container
**When**: When workspace content updates
**Access**: No user secrets
**Frequency**: On content changes

**Use cases**:
- Update dependencies (`npm install`, `pip install -r requirements.txt`)
- Rebuild assets
- Run database migrations

**Example**:
```json
{
  "updateContentCommand": "npm install && npm run build"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 4. postCreateCommand
**Location**: Inside container
**When**: After container assigned to user (first start)
**Access**: ‚úÖ **Has access to user secrets, assets, and permissions**
**Execution**: Background by default (non-blocking)
**Frequency**: Once per container (after user assignment)

**Use cases**:
- Configure git with user credentials
- Set up SSH keys
- Initialize user-specific tools
- Run setup scripts requiring authentication

**Example**:
```json
{
  "postCreateCommand": "git config --global user.name 'Your Name' && ./setup.sh"
}
```

**Important**: This is the **default waitFor target**. VS Code waits for this to complete before showing "ready" status.

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 5. postStartCommand
**Location**: Inside container
**When**: **Every time** container starts
**Access**: Full container access
**Frequency**: Every start

**Use cases**:
- Start background services (`docker-compose up -d`)
- Mount network drives
- Refresh certificates
- Display startup messages

**Example**:
```json
{
  "postStartCommand": "docker-compose up -d database redis && echo 'Services started'"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 6. postAttachCommand
**Location**: Inside container
**When**: Every time a tool attaches to container
**Access**: Full container access
**Frequency**: Every attach (e.g., opening VS Code)

**Use cases**:
- Display welcome message
- Check service health
- Log user sessions
- Trigger monitoring

**Example**:
```json
{
  "postAttachCommand": "echo 'Welcome! Container ready at http://localhost:3000'"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

### Command Syntax Options

All lifecycle hooks support three formats:

#### String (Shell Command)
Executed through a shell, supports pipes, redirection, etc.

```json
{
  "postStartCommand": "npm install && npm run build"
}
```

#### Array (Direct Command)
Passed directly to OS without shell interpretation (more secure, no globbing)

```json
{
  "postStartCommand": ["npm", "install"]
}
```

#### Object (Parallel Execution)
Multiple commands executed in parallel

```json
{
  "postStartCommand": {
    "install-deps": "npm install",
    "start-db": "docker-compose up -d database",
    "log-start": "echo 'Container started'"
  }
}
```

**Parallel execution** is useful for independent tasks (database start + npm install).

### Error Handling

**Cascading Failures**: If a lifecycle hook fails, subsequent hooks **will not execute**.

**Example**:
```
onCreateCommand fails ‚ùå
  ‚Üì
updateContentCommand skipped ‚è≠Ô∏è
  ‚Üì
postCreateCommand skipped ‚è≠Ô∏è
  ‚Üì
postStartCommand skipped ‚è≠Ô∏è
```

**Best practices**:
- Test hooks individually
- Use `set -e` in shell scripts to fail fast
- Log output for debugging
- Keep hooks idempotent (safe to run multiple times)

### Access to User Secrets Timeline

```
Hook                      | Has User Secrets?
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
initializeCommand         | ‚ùå (runs on host)
onCreateCommand           | ‚ùå
updateContentCommand      | ‚ùå
postCreateCommand         | ‚úÖ YES
postStartCommand          | ‚úÖ YES
postAttachCommand         | ‚úÖ YES
```

**Why this matters**: Only use `postCreateCommand` and later hooks for operations requiring:
- Git credentials
- SSH keys
- API tokens
- User-specific configuration

### waitFor Property

The `waitFor` property controls which lifecycle command VS Code waits for before considering the container "ready".

```json
{
  "waitFor": "postCreateCommand"  // Default
}
```

**Options**:
- `"initializeCommand"`: Wait before container creation
- `"onCreateCommand"`: Wait after container creation
- `"updateContentCommand"`: Wait after content sync
- `"postCreateCommand"`: **Default** - wait after user assignment
- `"postStartCommand"`: Wait after container start
- `"postAttachCommand"`: Wait after tool attachment

**Use case**: If your `postCreateCommand` is slow (large npm install), users see "ready" status only after it completes.

### Common Patterns

#### Pattern 1: System Setup + Dependency Install
```json
{
  "onCreateCommand": "apt-get update && apt-get install -y build-essential",
  "updateContentCommand": "npm install",
  "postCreateCommand": "npm run setup-user-config"
}
```

#### Pattern 2: Background Services
```json
{
  "postStartCommand": {
    "start-postgres": "docker-compose up -d postgres",
    "start-redis": "docker-compose up -d redis",
    "wait-for-services": "wait-for-it.sh postgres:5432 redis:6379"
  }
}
```

#### Pattern 3: Multi-Language Project
```json
{
  "postCreateCommand": {
    "install-npm": "npm install",
    "install-python": "pip install -r requirements.txt",
    "install-go": "go mod download"
  }
}
```

### Debugging Lifecycle Hooks

**View execution logs**:
```bash
# Inside container
docker logs <container-id>

# Or from VS Code
# View ‚Üí Output ‚Üí Select "Dev Containers"
```

**Test individual hook**:
```bash
# Run command manually inside container
docker exec -it <container-id> bash
# Then run the command to test
```

**Common issues**:
- **Hook hangs**: Check for interactive prompts (use `-y` flags, `DEBIAN_FRONTEND=noninteractive`)
- **Hook fails silently**: Add logging (`echo "Step 1..."`)
- **Commands not found**: Check PATH in containerEnv
- **Permission denied**: Verify remoteUser has necessary permissions

### Sources
- **Lifecycle Scripts Reference**: https://containers.dev/implementors/json_reference/#lifecycle-scripts
- **Devcontainer Reference**: https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md#lifecycle-scripts
- **VS Code Lifecycle Docs**: https://code.visualstudio.com/docs/devcontainers/create-dev-container#_lifecycle-scripts
- **Issue Discussion**: https://github.com/devcontainers/spec/issues/477

---


---


### Opening an Existing Devcontainer

**Method 1: Automatic Prompt**
1. Open project in VS Code: `code /path/to/project`
2. Click **"Reopen in Container"** when prompted

**Method 2: Manual Command**
1. Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)
2. Type: **"Dev Containers: Reopen in Container"**

**Method 3: From Remote Window**
1. Click the green icon in bottom-left corner of VS Code
2. Select **"Reopen in Container"**

### Rebuilding After Configuration Changes

When you modify `.devcontainer/devcontainer.json` or `Dockerfile`:

1. Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)
2. Select: **"Dev Containers: Rebuild Container"**
3. Choose:
   - **"Rebuild"**: Preserves volumes (keeps API keys, configs)
   - **"Rebuild Without Cache"**: Fresh build (slower, but resolves caching issues)

**Best Practice**:
- Use **"Rebuild"** for config changes (faster, preserves state)
- Use **"Rebuild Without Cache"** if experiencing mysterious errors

### Accessing the Container Terminal

VS Code automatically opens terminals inside the container. You can also:

**From Host Machine**:
```bash
# Find container ID
docker ps

# Execute command in container
docker exec -it <container-id> bash

# Or by name
docker exec -it <container-name> bash
```

### Viewing Container Logs

```bash
# See build and startup logs
docker logs <container-id>

# Follow logs in real-time
docker logs -f <container-id>
```

### Stopping the Container

**Method 1**: Close VS Code window
**Method 2**: Command Palette ‚Üí **"Dev Containers: Close Remote Connection"**
**Method 3**: Docker Desktop ‚Üí Containers ‚Üí Stop

Container stops automatically when VS Code disconnects.

### Removing the Container

```bash
# List all containers (including stopped)
docker ps -a

# Remove specific container
docker rm <container-id>

# Remove container and volumes (CAUTION: deletes API keys!)
docker rm -v <container-id>

# Or via Docker Desktop: Containers ‚Üí Delete
```

### Managing Disk Space

Devcontainers accumulate over time:

```bash
# See disk usage breakdown
docker system df

# Remove stopped containers
docker container prune

# Remove unused images
docker image prune -a

# Remove unused volumes (CAUTION: may delete configs)
docker volume prune

# Nuclear option: remove ALL unused Docker resources
docker system prune -a --volumes
```

**‚ö†Ô∏è Warning**: `docker system prune -a --volumes` removes **all** unused Docker resources. If you have other Docker projects, this affects them too.

**Safer Approach**:
```bash
# Remove only resources for this project
docker ps -a | grep "your-project-name"  # Find container ID
docker rm <container-id>
docker volume ls | grep "your-project"    # Find volumes
docker volume rm <volume-name>
```

---

## Multi-AI Configuration

Configure multiple AI assistants (Claude Code, OpenAI Codex, Google Gemini) in one container.

### Installing Multiple CLIs

**Dockerfile additions**:

```dockerfile
# Install Claude Code, Codex, Gemini
USER node
RUN npm install -g \
  @anthropic-ai/claude-code@latest \
  @openai/codex \
  @google/gemini-cli
```

### VS Code Extensions

**devcontainer.json additions**:

```json
{
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "openai.chatgpt",
        "google.gemini-cli-vscode-ide-companion",
        "google.geminicodeassist",
        "github.copilot",
        "github.copilot-chat"
      ]
    }
  }
}
```

### Persistent Configurations (Critical!)

**Separate volumes for each AI** to prevent credential conflicts:

```json
{
  "mounts": [
    "source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume",
    "source=codex-config-${devcontainerId},target=/home/node/.codex,type=volume",
    "source=gemini-config-${devcontainerId},target=/home/node/.gemini,type=volume"
  ]
}
```

**Why separate volumes?**
- Each AI stores API keys in its config directory
- Rebuilding container doesn't lose credentials
- Different projects can have different API keys
- Credential isolation improves security

### Verifying Multi-AI Setup

```bash
# Inside container
claude --version
codex --version
gemini --version

# Check config directories exist
ls -la ~/.claude ~/.codex ~/.gemini
```

### Claude Code Performance Optimization for Devcontainers

> **AI Assistant Guidance**: For devcontainer environments (trusted, isolated), recommend enabling these performance flags to dramatically improve Claude Code's development speed.

**Why optimize for devcontainers?**
- Devcontainers are **isolated** from host system (limited damage potential)
- Network firewall restricts outbound connections with IPv6 disabled (controlled security boundary)
- All tool executions are **auditable** via logs and telemetry
- Environment is **disposable** (can rebuild anytime if issues occur)
- Running as non-root user limits impact
- **Result**: Safe to skip permission prompts for faster development

#### Recommended Settings for Devcontainers

Add to `~/.claude/settings.json` or `.devcontainer/settings.json.template`:

```json
{
  "$schema": "https://json.schemastore.org/claude-code-settings.json",
  "dangerously_skip_permissions": true,
  "verbose": true,
  "env": {
    "MAX_MCP_OUTPUT_TOKENS": "60000",
    "BASH_DEFAULT_TIMEOUT_MS": "300000",
    "BASH_MAX_TIMEOUT_MS": "600000",
    "MAX_THINKING_TOKENS": "8192"
  }
}
```

#### Flag Explanations

**`dangerously_skip_permissions: true`**
- **What**: Skips user confirmation prompts before executing tools (Bash, Read, Write, etc.)
- **Why**: Eliminates delays waiting for permission confirmation
- **Effect**: Claude Code executes tools immediately without prompts
- **Speed Improvement**: 50-80% faster responses (no prompt delays)
- **Safe when**: Running in isolated devcontainer with network restrictions
- ‚ö†Ô∏è **WARNING**: **NEVER** use this flag on host system or with untrusted code!

**`verbose: true`**
- **What**: Enables detailed logging for all operations
- **Why**: Easier debugging of MCP servers, tool failures, and network issues
- **Effect**: More informative error messages and execution traces
- **Performance Impact**: None (logging is async)
- **Safe**: Always safe to enable

**Extended timeouts**:
- `BASH_DEFAULT_TIMEOUT_MS: "300000"` - 5 minutes for Bash commands (default)
- `BASH_MAX_TIMEOUT_MS: "600000"` - 10 minutes maximum timeout
- **Why**: Long-running builds, npm installs, database migrations won't timeout
- **Safe**: No security implications, just prevents premature timeouts

**High token limits**:
- `MAX_MCP_OUTPUT_TOKENS: "60000"` - MCP servers can return more data
- `MAX_THINKING_TOKENS: "8192"` - Claude can think through complex problems longer
- **Why**: Better quality responses, fewer "output truncated" errors
- **Cost**: Slightly higher API usage, but better results

#### Implementation in Devcontainer Templates

**.devcontainer/settings.json.template**:
```json
{
  "$schema": "https://json.schemastore.org/claude-code-settings.json",
  "dangerously_skip_permissions": true,
  "verbose": true,
  "env": {
    "MAX_MCP_OUTPUT_TOKENS": "60000",
    "BASH_DEFAULT_TIMEOUT_MS": "300000",
    "BASH_MAX_TIMEOUT_MS": "600000",
    "MAX_THINKING_TOKENS": "8192"
  },
  "mcpServers": {
    "context7": {
      "transport": {"type": "sse", "url": "https://mcp.context7.com/sse"}
    }
  }
}
```

**Init script to apply settings** (`.devcontainer/init-claude-config.sh`):
```bash
#!/bin/bash
set -euo pipefail

# Create .claude directory if doesn't exist
mkdir -p ~/.claude

# Copy template to settings.json if not exists
if [ ! -f ~/.claude/settings.json ]; then
  cp /usr/local/share/claude-defaults/settings.json ~/.claude/settings.json
  echo "Initialized Claude Code settings with performance flags"
else
  echo "Claude Code settings already exist, skipping..."
fi
```

**devcontainer.json** (run init script on container start):
```json
{
  "postStartCommand": "sudo /usr/local/bin/init-claude-config.sh"
}
```

#### Security Considerations

**Why this is SAFE in devcontainers**:
1. ‚úÖ **Isolated environment** - Container can't access host files directly
2. ‚úÖ **Network firewall** - Outbound connections restricted to whitelisted domains (IPv4 + IPv6 disabled)
3. ‚úÖ **Non-root user** - Limited privilege (e.g., `node` user UID 1000)
4. ‚úÖ **Auditable** - All tool executions logged via OpenTelemetry/Prometheus
5. ‚úÖ **Disposable** - Can rebuild container if compromised
6. ‚úÖ **Volume isolation** - Each project gets separate credential volumes
7. ‚úÖ **IPv6 bypass prevented** - IPv6 disabled at kernel level before firewall rules applied

**When NOT to use these flags**:
- ‚ùå Running on host system (not in container)
- ‚ùå Untrusted codebases or repositories
- ‚ùå Production environments
- ‚ùå Shared machines or CI/CD runners
- ‚ùå When required to audit every tool execution before running

**Alternative**: If security policies prohibit `dangerously_skip_permissions`, keep `verbose: true` and extended timeouts for improved debugging without skipping prompts.

#### Verification

```bash
# Check settings are applied
cat ~/.claude/settings.json | jq '{dangerously_skip_permissions, verbose}'

# Expected output:
# {
#   "dangerously_skip_permissions": true,
#   "verbose": true
# }

# Test Claude Code responds faster
claude chat
# Try a command that uses tools - notice no permission prompts!
```

#### Performance Impact Summary

| Setting | Speed Improvement | Safety Trade-off | Recommended |
|---------|------------------|------------------|-------------|
| `dangerously_skip_permissions` | 50-80% faster | Low in devcontainer | ‚úÖ Yes (devcontainer only) |
| `verbose` | None (better debugging) | None | ‚úÖ Always |
| Extended timeouts | Prevents failures | None | ‚úÖ Always |
| High token limits | Better responses | Slightly higher cost | ‚úÖ Yes |

**Bottom line**: For devcontainer development, enabling these flags provides **significantly faster** coding experience with **minimal security risk** due to container isolation.

### Sources

- **Claude Code**: https://www.npmjs.com/package/@anthropic-ai/claude-code
- **Claude Code Settings Schema**: https://json.schemastore.org/claude-code-settings.json
- **Devcontainer Security**: https://code.visualstudio.com/docs/devcontainers/containers#_security-and-container-isolation
- **OpenAI Codex**: https://www.npmjs.com/package/@openai/codex
- **Google Gemini CLI**: https://www.npmjs.com/package/@google/gemini-cli
- **GitHub Copilot**: https://github.com/features/copilot
- **VS Code Extension Marketplace**: https://marketplace.visualstudio.com/vscode

---

## MCP Server Setup

Model Context Protocol (MCP) servers extend Claude Code with specialized capabilities.

### What Are MCP Servers?

MCP servers provide Claude Code with access to:
- **External Documentation**: Library docs (Next.js, MongoDB, Cloudflare), API references
- **Tools**: Browser automation (Chromium DevTools), database queries
- **Custom Data**: Company wikis, internal APIs, documentation systems

**Official MCP Documentation**: https://modelcontextprotocol.io

### Transport Types Explained

MCP servers use two transport mechanisms:

**Streamable HTTP** - For remote/cloud services
```json
{
  "transport": {
    "type": "sse",
    "url": "https://api.example.com/sse"
  }
}
```
- **Use when**: Server is hosted externally (Context7, Cloudflare Docs)
- **Pros**: No local installation, always up-to-date
- **Cons**: Requires internet, potential rate limits
- **Note**: Previously called "SSE (Server-Sent Events)" before March 2025 MCP specification update

**stdio (Standard Input/Output)** - For local processes
```json
{
  "command": "npx",
  "args": ["chrome-devtools-mcp@latest"],
  "transport": {
    "type": "stdio"
  }
}
```
- **Use when**: Server runs as local npm package (Chrome DevTools, mcp-remote)
- **Pros**: Works offline, full control
- **Cons**: Needs installation, manual updates

### Testing MCP Server Transport Support

Before configuring an MCP server, test which transport methods it supports:

#### Method 1: Check Official Documentation

Always check the server's documentation first. Examples:
- **Context7**: https://context7.com/mcp (documents SSE endpoint)
- **Cloudflare**: https://developers.cloudflare.com/agents/model-context-protocol/

#### Method 2: Test with curl

```bash
# Test SSE endpoint (Server-Sent Events)
curl -v https://mcp.context7.com/sse
# Expected: HTTP/1.1 200 OK or 204 No Content

# Test HTTP endpoint
curl -v -X POST https://api.example.com/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","method":"initialize","params":{},"id":1}'
# Expected: JSON-RPC response if supported
```

#### Method 3: Try Both Transports

```bash
# Test SSE transport
claude mcp add --transport sse testserver https://server.com/sse
claude mcp list  # Check if status shows "connected"

# If SSE fails, test HTTP (if advertised)
claude mcp remove testserver
claude mcp add --transport http testserver https://server.com
claude mcp list
```

#### Method 4: Check Claude Code Logs

View MCP connection logs:
```bash
# In VS Code terminal or Claude CLI
# Errors like "connection refused" or "404" indicate unsupported transport
# Success: Server appears in `claude mcp list` with "connected" status
```

#### Transport Status as of October 27, 2025

| Server | SSE | HTTP | stdio (mcp-remote) | Notes |
|--------|-----|------|-------------------|-------|
| **Context7** | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes | SSE: `/sse` endpoint, stdio: use `mcp-remote` |
| **Cloudflare Docs** | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes | SSE: `/sse` endpoint, stdio: use `mcp-remote` |
| **Chrome DevTools** | ‚ùå No | ‚ùå No | ‚úÖ Yes | Local stdio only: `npx chrome-devtools-mcp@latest` |

**Note**: While the MCP specification calls the transport "Streamable HTTP", the JSON configuration still uses `"type": "sse"`. Do not confuse this with `"type": "http"` which is a different (future) transport method.

### Common MCP Servers

#### Context7 - Library Documentation

> **Transport Status (Oct 27, 2025)**: Context7 supports two methods:
> 1. **SSE transport** (public, no auth): `https://mcp.context7.com/sse`
> 2. **stdio with mcp-remote** (OAuth secured): `https://mcp.context7.com/mcp`

**Method 1: SSE Transport (Simple)**

```bash
# Add via CLI
claude mcp add --transport sse context7 https://mcp.context7.com/sse

# Or in mcp.json
{
  "mcpServers": {
    "context7": {
      "transport": {
        "type": "sse",
        "url": "https://mcp.context7.com/sse"
      }
    }
  }
}
```

**Method 2: mcp-remote (OAuth Secured, Recommended)**

Provides access to 1000+ library documentation sources with OAuth authentication.

```bash
# Add via CLI
claude mcp add --transport stdio context7 -- npx mcp-remote https://mcp.context7.com/mcp

# Or in mcp.json
{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["mcp-remote", "https://mcp.context7.com/mcp"],
      "transport": {
        "type": "stdio"
      }
    }
  }
}
```

**First use**: Opens browser for OAuth authentication. Subsequent uses are automatic.

**Testing both methods**: Use `.devcontainer/switch-mcp.sh` script to compare SSE vs mcp-remote.

**Supported libraries**: Next.js, React, MongoDB, Supabase, Vercel, and more.

#### Cloudflare Docs - Cloudflare Product Documentation

> **Transport Status (Oct 27, 2025)**: Cloudflare Docs supports two methods:
> 1. **SSE transport** (public, no auth): `https://docs.mcp.cloudflare.com/sse`
> 2. **stdio with mcp-remote** (OAuth secured): `https://docs.mcp.cloudflare.com/mcp`

**Method 1: SSE Transport (Simple)**

```bash
# Add via CLI
claude mcp add --transport sse cf-docs https://docs.mcp.cloudflare.com/sse

# Or in mcp.json
{
  "mcpServers": {
    "cf-docs": {
      "transport": {
        "type": "sse",
        "url": "https://docs.mcp.cloudflare.com/sse"
      }
    }
  }
}
```

**Method 2: mcp-remote (OAuth Secured, Recommended)**

Provides `search_cloudflare_documentation` tool with OAuth authentication.

```bash
# Install mcp-remote wrapper
npm install -g mcp-remote

# Add to mcp.json (cannot use CLI for this syntax)
{
  "mcpServers": {
    "cf-docs": {
      "command": "npx",
      "args": ["mcp-remote", "https://docs.mcp.cloudflare.com/mcp"],
      "transport": {
        "type": "stdio"
      }
    }
  }
}
```

**First use**: Opens browser for OAuth authentication. Subsequent uses are automatic.

**Testing both methods**: Use `.devcontainer/switch-mcp.sh` script to compare SSE vs mcp-remote.

**Covers**: Workers, Pages, R2, D1, KV, Durable Objects, Queues, etc.

**See**: https://developers.cloudflare.com/agents/model-context-protocol/mcp-servers-for-cloudflare/

#### Chrome DevTools (stdio) - Browser Automation

Requires Chromium installed in Dockerfile.

**Dockerfile additions**:
```dockerfile
RUN apt-get update && apt-get install -y \
  chromium \
  fonts-liberation \
  && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**Add MCP server**:
```bash
claude mcp add --transport stdio chrome-devtools npx chrome-devtools-mcp@latest -- \
  --executablePath=/usr/bin/chromium \
  --headless \
  --chromeArg='--no-sandbox' \
  --chromeArg='--disable-setuid-sandbox' \
  --chromeArg='--disable-dev-shm-usage'
```

**Why these Chrome args?**
- `--no-sandbox`: Required in Docker (containers already sandboxed)
- `--disable-setuid-sandbox`: Docker compatibility
- `--disable-dev-shm-usage`: Prevents /dev/shm memory issues

### Automating MCP Setup

Create `.devcontainer/mcp.json.template`:

```json
{
  "mcpServers": {
    "context7": {
      "transport": {
        "type": "sse",
        "url": "https://mcp.context7.com/sse"
      }
    },
    "cf-docs": {
      "transport": {
        "type": "sse",
        "url": "https://docs.mcp.cloudflare.com/sse"
      }
    }
  }
}
```

Create `.devcontainer/init-claude-config.sh`:

```bash
#!/bin/bash
set -euo pipefail

CLAUDE_HOME="/home/node/.claude"
MCP_FILE="$CLAUDE_HOME/mcp.json"
MCP_TEMPLATE="/usr/local/share/claude-defaults/mcp.json"

echo "Initializing Claude Code configuration..."

# Create .claude directory if it doesn't exist
if [ ! -d "$CLAUDE_HOME" ]; then
    mkdir -p "$CLAUDE_HOME"
    chown node:node "$CLAUDE_HOME"
fi

# Copy MCP configuration if it doesn't exist
if [ ! -f "$MCP_FILE" ]; then
    if [ -f "$MCP_TEMPLATE" ]; then
        cp "$MCP_TEMPLATE" "$MCP_FILE"
        chown node:node "$MCP_FILE"
        echo "‚úì MCP servers configured"
    fi
else
    echo "MCP configuration already exists, preserving user settings"
fi
```

**Dockerfile additions**:

```dockerfile
# Copy MCP template to shared location
RUN mkdir -p /usr/local/share/claude-defaults
COPY --chown=node:node mcp.json.template /usr/local/share/claude-defaults/mcp.json

# Copy and configure init script
COPY init-claude-config.sh /usr/local/bin/
USER root
RUN chmod +x /usr/local/bin/init-claude-config.sh && \
  echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-claude-config.sh" > /etc/sudoers.d/node-claude && \
  chmod 0440 /etc/sudoers.d/node-claude
USER node
```

**devcontainer.json additions**:

```json
{
  "postStartCommand": "sudo /usr/local/bin/init-claude-config.sh"
}
```

This ensures MCP servers are automatically configured on first container start, but **preserves user customizations** on subsequent starts.

### Verifying MCP Setup

```bash
# List configured MCP servers
claude mcp list

# Test MCP server (inside Claude Code session)
# Ask Claude: "What's new in Next.js 14?" (uses Context7)
```

### Debugging MCP Issues

```bash
# Check mcp.json exists and is valid JSON
cat ~/.claude/mcp.json | jq

# Test SSE endpoint manually
curl -v https://mcp.context7.com/sse

# Check stdio MCP can run
npx chrome-devtools-mcp@latest --help

# View Claude Code logs
claude --verbose
```

---

### Docker MCP Toolkit Integration


### Docker MCP Toolkit

**What is it**: Docker Desktop integration that simplifies MCP server management with 200+ pre-built, containerized MCP servers.

**Official Announcement**: https://www.docker.com/blog/add-mcp-servers-to-claude-code-with-mcp-toolkit/

#### Features

1. **One-Click Deployment**: Install MCP servers from Docker Desktop UI
2. **200+ Pre-built Servers**: Curated catalog of containerized MCP servers
3. **No Dependency Issues**: Each server runs in isolated container
4. **Automatic Configuration**: Docker Desktop writes to `~/.claude/mcp.json`

#### Using Docker MCP Toolkit

**Step 1: Enable in Docker Desktop**

Docker Desktop ‚Üí Extensions ‚Üí Claude Code ‚Üí Enable

**Step 2: Browse MCP Servers**

Docker Desktop ‚Üí Claude Code ‚Üí Browse Servers

**Available categories**:
- Development tools (GitHub, GitLab, Jira)
- Cloud services (AWS, Azure, Google Cloud)
- Databases (PostgreSQL, MongoDB, Redis)
- AI services (OpenAI, Anthropic)
- Custom organization servers

**Step 3: One-Click Install**

Click server ‚Üí Install ‚Üí Docker Desktop:
1. Pulls containerized MCP server
2. Starts container
3. Configures `~/.claude/mcp.json` automatically

**Result**: MCP server immediately available in Claude Code.

---

### MCP Proxy for Inter-Container Communication

**Problem**: Claude Code in devcontainer can't use stdio to communicate with MCP servers in other containers.

**Solution**: MCP proxy that bridges stdio and network communication.

**Architecture**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Devcontainer           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Claude Code         ‚îÇ‚îÇ
‚îÇ  ‚îÇ   (OTLP gRPC)       ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ             ‚îÇ           ‚îÇ
‚îÇ         stdio ‚Üí HTTP    ‚îÇ
‚îÇ             ‚îÇ           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ MCP Proxy           ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
        HTTP  ‚îÇ
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MCP Server Container   ‚îÇ
‚îÇ  (GitHub, Database, etc)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementation**: Use `@modelcontextprotocol/server-proxy` to bridge connections.

---

### MCP Server Performance Optimization

**Cache frequently accessed data**:

MCP servers can cache responses to reduce latency:

```json
{
  "mcpServers": {
    "context7": {
      "transport": {
        "type": "sse",
        "url": "https://mcp.context7.com/sse"
      },
      "cacheTimeout": 3600
    }
  }
}
```

**Health checks**:

Monitor MCP server availability:

```bash
# Test SSE server
curl -v https://mcp.context7.com/sse

# Test stdio server
npx chrome-devtools-mcp@latest --help
```

---

### Sources
- **Docker MCP Toolkit**: https://www.docker.com/blog/add-mcp-servers-to-claude-code-with-mcp-toolkit/
- **MCP Specification**: https://modelcontextprotocol.io/docs
- **MCP Transports**: https://modelcontextprotocol.io/docs/concepts/transports
- **Server Implementation**: https://modelcontextprotocol.io/docs/concepts/servers

---

## Security Best Practices

### Network Isolation with Firewall

Restrict container network access to only trusted domains, preventing credential exfiltration.

#### IPv6 Bypass Prevention

**Critical Security Issue**: Firewall rules using iptables only filter IPv4 traffic. If IPv6 is enabled, connections can bypass your allowlist entirely.

**The Problem**:
```bash
# Your iptables rules block this:
curl https://malicious-site.com  # ‚ùå Blocked (IPv4)

# But IPv6 goes around the firewall:
curl -6 https://malicious-site.com  # ‚úÖ Allowed! (IPv6 bypass)
```

**Solution**: Disable IPv6 completely at the kernel level before configuring firewall rules.

```bash
# At start of init-firewall.sh (BEFORE any iptables commands)
sysctl -w net.ipv6.conf.all.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.default.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.lo.disable_ipv6=1 >/dev/null 2>&1 || true
```

**Verification**:
```bash
# Verify IPv6 is disabled
sysctl net.ipv6.conf.all.disable_ipv6  # Should show: = 1

# Test IPv6 connections fail
curl -6 https://api.github.com  # Should error: "Network is unreachable"
```

**Why This Matters**: Without IPv6 disabled, your firewall provides a false sense of security while leaving a wide-open backdoor.

**Create `.devcontainer/init-firewall.sh`** (Production Implementation):

```bash
#!/bin/bash
set -euo pipefail  # Exit on error, undefined vars, pipeline failures
IFS=$'\n\t'       # Stricter word splitting

# State file prevents unnecessary reconfiguration on container restart
STATE_FILE="/var/lib/firewall-configured"
if [ -f "$STATE_FILE" ]; then
    echo "Firewall already configured, skipping..."
    exit 0
fi

echo "Starting firewall configuration..."

# === IPv6 SECURITY: Disable IPv6 to prevent bypass ===
echo "Disabling IPv6..."
sysctl -w net.ipv6.conf.all.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.default.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.lo.disable_ipv6=1 >/dev/null 2>&1 || true

# === Preserve Docker DNS (BEFORE flushing) ===
DOCKER_DNS_RULES=$(iptables-save -t nat | grep "127\.0\.0\.11" || true)
DOCKER_NETWORKS=$(ip -o -f inet addr show | grep -v "127.0.0.1" | awk '{print $4}')

# === Create ipset for efficient IP filtering ===
ipset destroy allowed-domains 2>/dev/null || true
ipset create allowed-domains hash:net

# === Fetch GitHub IP ranges (dynamic, comprehensive) ===
echo "Fetching GitHub IP ranges..."
gh_ranges=$(curl -s https://api.github.com/meta)
echo "$gh_ranges" | jq -r '(.web + .api + .git)[]' | aggregate -q | while read -r cidr; do
    echo "Adding GitHub range $cidr"
    ipset add allowed-domains "$cidr" -exist
done

# === Add Anthropic IP ranges (official published ranges) ===
echo "Adding Anthropic IP ranges..."
echo "Adding Anthropic CIDR range 160.79.104.0/23"
ipset add allowed-domains "160.79.104.0/23" -exist

# Add Anthropic specific IP addresses
for ip in "34.162.46.92" "34.162.102.82" "34.162.136.91" "34.162.142.92" "34.162.183.95"; do
    echo "Adding Anthropic IP $ip"
    ipset add allowed-domains "$ip" -exist
done

# === Fetch and add Google Cloud/API IP ranges ===
echo "Fetching Google Cloud/API IP ranges..."
goog_ranges=$(curl -s https://www.gstatic.com/ipranges/goog.json)
echo "$goog_ranges" | jq -r '.prefixes[].ipv4Prefix | select(. != null)' | while read -r cidr; do
    echo "Adding Google range $cidr"
    ipset add allowed-domains "$cidr" -exist
done

# === Fetch and add Cloudflare CDN IP ranges ===
echo "Fetching Cloudflare CDN IP ranges..."
cf_ranges=$(curl -s https://api.cloudflare.com/client/v4/ips)
echo "$cf_ranges" | jq -r '.result.ipv4_cidrs[]' | while read -r cidr; do
    echo "Adding Cloudflare range $cidr"
    ipset add allowed-domains "$cidr" -exist
done

# === Resolve and add all trusted domains (defense-in-depth: includes DNS backup) ===
# Defense-in-depth: Services with IP ranges (above) also included here as DNS backup
# This ensures comprehensive coverage and handles edge cases
for domain in \
    "1.1.1.1" "8.8.8.8" "8.8.4.4" \
    "dns.google" \
    "context7.com" \
    "unpkg.com" "cdn.jsdelivr.net" "cdnjs.cloudflare.com" \
    "github.com" "api.github.com" "raw.githubusercontent.com" \
    "github.githubassets.com" "collector.github.com" \
    "ghcr.io" "pkg-containers.githubusercontent.com" \
    "nodejs.org" "registry.npmjs.org" \
    "pypi.org" "files.pythonhosted.org" \
    "astral.sh" "bun.sh" \
    "crates.io" "static.crates.io" "index.crates.io" \
    "docker.io" "registry-1.docker.io" "auth.docker.io" \
    "production.cloudflare.docker.com" \
    "api.anthropic.com" "statsig.anthropic.com" "statsig.com" "sentry.io" \
    "api.openai.com" \
    "aistudio.google.com" "accounts.google.com" \
    "oauth2.googleapis.com" "www.googleapis.com" \
    "storage.googleapis.com" "content.googleapis.com" \
    "generativelanguage.googleapis.com" \
    "marketplace.visualstudio.com" "vscode.blob.core.windows.net" \
    "update.code.visualstudio.com" \
    "docs.mcp.cloudflare.com" "mcp.context7.com" \
    "vercel.com" "ui.shadcn.com" "tailwindcss.com" \
    "radix-ui.com" "fonts.googleapis.com" "fonts.gstatic.com" \
    "react.dev" "reactjs.org" "esm.sh" "lucide.dev"; do

    # If already an IP, add directly
    if [[ "$domain" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        ipset add allowed-domains "$domain" -exist
        continue
    fi

    # Resolve domain and add all IPs
    echo "Resolving $domain..."
    ips=$(dig +noall +answer A "$domain" | awk '$4 == "A" {print $5}')
    while read -r ip; do
        echo "Adding $ip for $domain"
        ipset add allowed-domains "$ip" -exist
    done < <(echo "$ips")
done

echo "IP allowlist built successfully"

# === Flush and rebuild iptables ===
iptables -F && iptables -X
iptables -t nat -F && iptables -t nat -X
iptables -t mangle -F && iptables -t mangle -X

# Restore Docker DNS rules
if [ -n "$DOCKER_DNS_RULES" ]; then
    iptables -t nat -N DOCKER_OUTPUT 2>/dev/null || true
    iptables -t nat -N DOCKER_POSTROUTING 2>/dev/null || true
    echo "$DOCKER_DNS_RULES" | xargs -L 1 iptables -t nat
fi

# === Configure base rules ===
iptables -A OUTPUT -p udp --dport 53 -j ACCEPT  # DNS
iptables -A INPUT -p udp --sport 53 -j ACCEPT
iptables -A OUTPUT -p tcp --dport 22 -j ACCEPT  # SSH
iptables -A INPUT -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT
iptables -A INPUT -i lo -j ACCEPT   # Localhost
iptables -A OUTPUT -o lo -j ACCEPT

# === Allow Docker networks (for OTel, inter-container) ===
while read -r network; do
    iptables -A INPUT -s "$network" -j ACCEPT
    iptables -A OUTPUT -d "$network" -j ACCEPT
done < <(echo "$DOCKER_NETWORKS")

# === Default DENY, then allow via ipset ===
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT DROP
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
iptables -A OUTPUT -j REJECT --reject-with icmp-admin-prohibited

# === Configure IPv6 firewall rules (Layer 3 - Defense-in-depth) ===
echo "Configuring IPv6 firewall rules..."
# Set default policies to DROP for IPv6
ip6tables -P INPUT DROP 2>/dev/null || echo "  Note: IPv6 may already be disabled"
ip6tables -P FORWARD DROP 2>/dev/null || true
ip6tables -P OUTPUT DROP 2>/dev/null || true

# Allow IPv6 localhost only
ip6tables -A INPUT -i lo -j ACCEPT 2>/dev/null || true
ip6tables -A OUTPUT -o lo -j ACCEPT 2>/dev/null || true

# Allow established IPv6 connections (for localhost)
ip6tables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true
ip6tables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true

# Explicitly REJECT all other IPv6 traffic
ip6tables -A INPUT -j REJECT 2>/dev/null || true
ip6tables -A OUTPUT -j REJECT 2>/dev/null || true
echo "IPv6 firewall rules configured"

echo ""
echo "Firewall configuration complete!"
echo ""

# === Verification ===
echo "Verifying firewall rules..."

# Verify IPv6 is disabled (warning only, not fatal - graceful degradation)
if sysctl net.ipv6.conf.all.disable_ipv6 | grep -q "= 1"; then
    echo "‚úì IPv6 is disabled"
else
    echo "‚ö† WARNING: IPv6 is still enabled (container restrictions may prevent disabling)"
    echo "  IPv6 traffic will be blocked by ip6tables rules as a security fallback"
    echo "  This is expected in some Docker environments and does not affect security"
fi

# Verify blocked domain
if curl --connect-timeout 5 https://example.com >/dev/null 2>&1; then
    echo "‚ùå Firewall failed - can reach blocked domain"
    exit 1
else
    echo "‚úì Blocked domains unreachable"
fi

# Verify allowed domain
if ! curl --connect-timeout 5 https://api.github.com/zen >/dev/null 2>&1; then
    echo "‚ùå Firewall failed - can't reach allowed domain"
    exit 1
else
    echo "‚úì Allowed domains reachable"
fi

# Mark as configured
touch "$STATE_FILE"
echo "Firewall state saved"
```

**Key Features of Production Implementation**:
1. **Three-layer IPv6 security** - Container creation, runtime disable, ip6tables rules
2. **Graceful degradation** - Container starts successfully even if IPv6 can't be disabled
3. **Maximum compatibility** - Works across Docker Desktop, Podman, cloud environments
4. **ipset for efficiency** - Much faster than individual iptables rules for 50+ domains
5. **Dynamic IP range fetching** - Fetches official IP ranges for GitHub, Anthropic, Google, Cloudflare
6. **DNS resolution backup** - Defense-in-depth: DNS resolution for all domains (including those with IP ranges)
7. **Docker DNS preservation** - Maintains container networking
8. **State file** - Skips reconfiguration on container restart
9. **Comprehensive verification** - Tests IPv6, blocked domains, allowed domains (warnings, not failures)
10. **50+ whitelisted domains** - All package registries, AI APIs, CDNs covered

**Dockerfile additions**:

```dockerfile
# Install firewall and network tools (including IPv6 support)
RUN apt-get update && apt-get install -y \
  iptables \
  ipset \
  iproute2 \
  dnsutils \
  aggregate \
  curl \
  jq \
  && apt-get clean && rm -rf /var/lib/apt/lists/*

# Copy and configure firewall script
COPY init-firewall.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/init-firewall.sh && \
  echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-firewall.sh" > /etc/sudoers.d/node-firewall && \
  chmod 0440 /etc/sudoers.d/node-firewall
```

**Required tools explained**:
- `iptables` - IPv4 and IPv6 firewall rules (includes ip6tables)
- `ipset` - Efficient IP address set management
- `iproute2` - Network configuration (`ip` command)
- `dnsutils` - DNS resolution (`dig` command)
- `aggregate` - IP range aggregation (GitHub IPs)
- `curl` - HTTP requests (fetch GitHub API, verify firewall)
- `jq` - JSON parsing (GitHub API response)

**devcontainer.json additions** (Maximum Compatibility - Three-Layer Security):

```json
{
  "runArgs": [
    "--cap-drop=ALL",                              // Drop all capabilities first (security)
    "--cap-add=NET_ADMIN",                         // Required for iptables/sysctl
    "--cap-add=NET_RAW",                           // Required for packet filtering
    "--cap-add=SETUID",                            // Required for sudo operations
    "--cap-add=SETGID",                            // Required for group switching
    "--cap-add=SYS_ADMIN",                         // Required for broader kernel parameter control
    "--sysctl=net.ipv6.conf.all.disable_ipv6=1",   // Layer 1: Disable IPv6 at container creation
    "--sysctl=net.ipv6.conf.default.disable_ipv6=1",
    "--sysctl=net.ipv6.conf.lo.disable_ipv6=1"
  ],
  "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"
}
```

**Three-Layer Security Architecture**:
- **Layer 1**: Disable IPv6 at container creation via sysctl flags (most reliable)
- **Layer 2**: Attempt runtime IPv6 disable in init script (graceful degradation if Layer 1 fails)
- **Layer 3**: ip6tables DROP rules (security backup if IPv6 remains enabled)

**Testing Firewall**:

```bash
# Inside container - Test allowed domain
curl https://api.anthropic.com  # ‚úÖ Should work (whitelisted)

# Test blocked domain
curl https://example.com        # ‚ùå Should fail (not whitelisted)

# Test IPv6 is disabled (critical security check)
curl -6 https://api.github.com  # ‚ùå Should fail: "Network is unreachable"

# Verify IPv6 disabled at kernel level
sysctl net.ipv6.conf.all.disable_ipv6  # Should show: net.ipv6.conf.all.disable_ipv6 = 1
```

### The `--dangerously-skip-permissions` Flag

**What it does**: Bypasses Claude Code's permission prompts for tool execution.

**When to use**:
- ‚úÖ Trusted devcontainers with firewall enabled
- ‚úÖ Automated CI/CD pipelines
- ‚úÖ Personal projects in isolated containers

**When NOT to use**:
- ‚ùå Untrusted codebases
- ‚ùå Open-source projects you haven't audited
- ‚ùå Production environments
- ‚ùå Containers without network restrictions

**Official Warning**: "When executed with `--dangerously-skip-permissions`, devcontainers do not prevent a malicious project from exfiltrating anything accessible in the devcontainer including Claude Code credentials."

**Usage**:
```bash
claude --dangerously-skip-permissions
```

### Protecting Sensitive Files

**Always exclude** local settings from git:

```bash
# In Dockerfile
RUN git config --global core.excludesfile ~/.gitignore_global && \
  echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

**Why?** `.claude/settings.local.json` contains API keys. Committing this file exposes credentials.

### Credential Isolation Best Practices

**Use separate devcontainers for**:
- Different clients (prevents client A's credentials leaking to client B)
- Different security levels (public open-source vs. proprietary)
- Different AI services (separate Claude/Codex/Gemini API keys per project)

**How?** Each devcontainer gets isolated volumes (`${devcontainerId}` ensures uniqueness).

### Additional Security Measures

**Read-only bind mounts**:
```json
{
  "mounts": [
    "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
  ]
}
```

**Limit container capabilities**:
```json
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_ADMIN"  // Only if firewall needed
  ]
}
```

### ‚ö†Ô∏è The `--security-opt=no-new-privileges` Incompatibility

**Critical Finding** (October 2025 field testing):

The `--security-opt=no-new-privileges` Docker flag **breaks sudo** in devcontainers, causing runtime initialization scripts to fail.

**What it does**:
- Prevents processes from gaining elevated privileges
- Recommended security hardening in many Docker guides
- Sounds like good defense-in-depth

**The Problem**:
```bash
# In postStartCommand:
sudo /usr/local/bin/init-firewall.sh

# Error with no-new-privileges:
sudo: The "no new privileges" flag is set, which prevents sudo from running as root.
sudo: If sudo is running in a container, you may need to adjust the container configuration to disable the flag.
```

**Why it breaks**:
- Firewall configuration requires `sudo` to run `iptables` commands
- `iptables` needs root privileges to modify network rules
- `no-new-privileges` prevents sudo from elevating to root
- Result: Container starts but firewall/config scripts fail with exit code 1

**When you CAN'T use this flag**:
- ‚ùå Any devcontainer that uses `sudo` in lifecycle hooks (postStartCommand, postCreateCommand)
- ‚ùå Devcontainers with iptables firewall configuration
- ‚ùå Init scripts requiring root privileges
- ‚ùå Containers using `sudoers` file for specific commands

**When you CAN use this flag**:
- ‚úÖ Devcontainers that never need sudo
- ‚úÖ Containers where all root operations happen at build-time (Dockerfile)
- ‚úÖ Simple development containers without network restrictions

**Recommended Approach** (if you need both security and sudo):

**Option 1: Don't use no-new-privileges** (recommended)
- Your existing security is already strong:
  - `--cap-drop=ALL` (drop all capabilities)
  - Only add necessary capabilities (`NET_ADMIN`, `NET_RAW`)
  - Non-root user (`remoteUser: "node"`)
  - Network firewall with whitelist (IPv4 + IPv6 disabled)
  - Limited sudoers file (specific scripts only)
- The `no-new-privileges` flag is defensive overkill that breaks necessary functionality

**Option 2: Move root operations to build-time**
```dockerfile
# Instead of postStartCommand with sudo:
# Do firewall setup in Dockerfile (more complex but works with no-new-privileges)

# Dockerfile
RUN /usr/local/bin/init-firewall.sh && \
    # Save iptables rules
    iptables-save > /etc/iptables/rules.v4

# devcontainer.json - can now use no-new-privileges
{
  "runArgs": ["--security-opt=no-new-privileges"],
  "postStartCommand": "iptables-restore < /etc/iptables/rules.v4"
}
```

**Option 3: Architectural alternative**
- Use Docker's network isolation features instead of in-container iptables
- Define network policies in `docker-compose.yml`
- No sudo required, can use `no-new-privileges`

**Lesson Learned**:
Don't blindly apply every security hardening flag. Test with your actual use case. Some "best practices" from generic Docker guides don't account for devcontainer-specific requirements like lifecycle hooks that need elevated privileges.

**Real-world example**:
```json
// ‚ùå BAD - Looks secure but breaks initialization
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_ADMIN",
    "--security-opt=no-new-privileges"  // Breaks sudo!
  ],
  "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"  // Fails!
}

// ‚úÖ GOOD - Secure AND functional
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_ADMIN",
    "--cap-add=NET_RAW",
    "--cap-add=SETUID",  // Needed for sudo
    "--cap-add=SETGID"   // Needed for sudo
    // no-new-privileges flag removed
  ],
  "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"  // Works!
}
```

**Use minimal base images**:
```dockerfile
FROM node:20-slim  # Instead of node:20 (500MB smaller)
```

---

### Advanced Security Features


### Enhanced Container Isolation (ECI)

**What is ECI**: Docker Desktop feature that prevents malicious containers from compromising the host system using advanced security techniques.

**Official Documentation**: https://docs.docker.com/security/for-admins/hardened-desktop/enhanced-container-isolation/

#### How ECI Works

**Traditional containers**:
- Share host kernel
- Can potentially escalate privileges
- Access Docker socket (if mounted)
- Read host files (if mounted)

**With ECI**:
- **Security boundary between container and Docker Desktop**
- Linux security modules (SELinux, AppArmor) enforced
- Restricted access to Docker socket
- Limited syscalls via seccomp
- Cannot compromise Docker Desktop even if container breached

#### Enabling ECI

**Docker Desktop** ‚Üí Settings ‚Üí General ‚Üí **"Use Enhanced Container Isolation"** ‚Üí Apply

**Verify ECI active**:
```bash
docker info | grep "Security Options"
# Should show: seccomp, apparmor/selinux, userns
```

---

### User Namespace Remapping

Map container root user to unprivileged host user.

**Problem**: Container root (UID 0) = host root (UID 0) ‚Üí security risk.

**Solution**: User namespaces remap container UID 0 to host UID 100000+ (non-privileged).

**Enable user namespaces**:

**/etc/docker/daemon.json**:
```json
{
  "userns-remap": "default"
}
```

**Restart Docker**:
```bash
sudo systemctl restart docker
```

**Verify**:
```bash
docker run --rm alpine id
# Shows: uid=0(root) gid=0(root) (inside container)

# On host, process runs as:
ps aux | grep alpine
# Shows: 100000 (unprivileged user)
```

**Official Docs**: https://docs.docker.com/engine/security/userns-remap/

---

### Network Segmentation

Isolate containers by security level using custom networks.

**Create security zones**:
```bash
# DMZ network (public-facing services)
docker network create --driver bridge dmz-network

# Internal network (databases, private services)
docker network create --driver bridge --internal internal-network

# Admin network (management tools)
docker network create --driver bridge admin-network
```

**docker-compose.yml with segmentation**:
```yaml
services:
  frontend:
    image: myapp-frontend
    networks:
      - dmz-network

  backend:
    image: myapp-backend
    networks:
      - dmz-network
      - internal-network

  database:
    image: postgres:15
    networks:
      - internal-network  # Not accessible from DMZ

networks:
  dmz-network:
    external: true
  internal-network:
    external: true
    internal: true  # No external access
```

**Official Docs**: https://docs.docker.com/network/drivers/bridge/#use-user-defined-bridge-networks

---

### Runtime Security Tools

#### gVisor (Application Kernel)

**What**: Sandboxes containers with application kernel for enhanced isolation.

**Install**:
```bash
# Install gVisor
wget https://storage.googleapis.com/gvisor/releases/release/latest/x86_64/runsc
chmod +x runsc
sudo mv runsc /usr/local/bin/

# Configure Docker
sudo mkdir -p /etc/docker
cat <<EOF | sudo tee /etc/docker/daemon.json
{
  "runtimes": {
    "runsc": {
      "path": "/usr/local/bin/runsc"
    }
  }
}
EOF

sudo systemctl restart docker
```

**Use with devcontainer**:
```json
{
  "runArgs": ["--runtime=runsc"]
}
```

**Official Docs**: https://gvisor.dev/docs/user_guide/quick_start/docker/

---

#### Falco (Runtime Threat Detection)

**What**: Detects abnormal behavior in running containers.

**Install**:
```bash
# Helm install
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm install falco falcosecurity/falco
```

**Monitor devcontainers**:
Falco alerts on:
- Unexpected network connections
- File access violations
- Privilege escalation attempts
- Suspicious process spawning

**Official Docs**: https://falco.org/docs/

---

### Seccomp and AppArmor Profiles

Restrict syscalls and capabilities.

**Custom seccomp profile** (restrict-syscalls.json):
```json
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "architectures": ["SCMP_ARCH_X86_64"],
  "syscalls": [
    {
      "names": ["read", "write", "open", "close", "stat", "fstat", "lstat"],
      "action": "SCMP_ACT_ALLOW"
    }
  ]
}
```

**Apply to devcontainer**:
```json
{
  "runArgs": [
    "--security-opt=seccomp=./restrict-syscalls.json"
  ]
}
```

**AppArmor profile**:
```bash
# Load custom profile
sudo apparmor_parser -r -W /etc/apparmor.d/docker-devcontainer
```

**Official Docs**:
- Seccomp: https://docs.docker.com/engine/security/seccomp/
- AppArmor: https://docs.docker.com/engine/security/apparmor/

---

### Capability Restrictions

Drop unnecessary Linux capabilities.

**Best practice**: Drop all, add only required.

```json
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_BIND_SERVICE"  // Only if binding to ports <1024
  ]
}
```

**Common capabilities**:
- `NET_BIND_SERVICE`: Bind to privileged ports (<1024)
- `SYS_PTRACE`: Debugging with gdb/strace
- `SYS_ADMIN`: Mount filesystems (usually not needed)

**Check container capabilities**:
```bash
docker inspect <container-id> | jq '.[0].HostConfig.CapAdd'
docker inspect <container-id> | jq '.[0].HostConfig.CapDrop'
```

**Official Docs**: https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities

---

### Security Scanning in CI/CD

Scan devcontainer images before deployment.

**Trivy** (vulnerability scanner):
```yaml
# .github/workflows/security-scan.yml
- name: Build devcontainer
  run: devcontainer build --workspace-folder . --image-name myapp-dev:test

- name: Scan with Trivy
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: 'myapp-dev:test'
    format: 'sarif'
    output: 'trivy-results.sarif'

- name: Upload results to GitHub Security
  uses: github/codeql-action/upload-sarif@v2
  with:
    sarif_file: 'trivy-results.sarif'
```

**Official Docs**: https://github.com/aquasecurity/trivy

---

### Sources
- **Docker Security Overview**: https://docs.docker.com/engine/security/
- **Enhanced Container Isolation**: https://docs.docker.com/security/for-admins/hardened-desktop/enhanced-container-isolation/
- **User Namespaces**: https://docs.docker.com/engine/security/userns-remap/
- **Seccomp Profiles**: https://docs.docker.com/engine/security/seccomp/
- **AppArmor**: https://docs.docker.com/engine/security/apparmor/
- **gVisor**: https://gvisor.dev/docs/
- **Falco**: https://falco.org/docs/
- **Network Security**: https://docs.docker.com/network/network-tutorial-standalone/

---


---


When encountering devcontainer issues, follow this systematic diagnostic process:

### Step 1: Identify Error Category

```
Where did the error occur?
‚îú‚îÄ Building container? ‚Üí Go to Step 2: Build Failures
‚îú‚îÄ Starting container? ‚Üí Go to Step 3: Startup Failures
‚îú‚îÄ Inside container (tool not working)? ‚Üí Go to Step 4: Runtime Issues
‚îî‚îÄ VS Code connection? ‚Üí Go to Step 5: VS Code Integration Issues
```

### Step 2: Build Failures

**Symptoms**: "docker build failed", "command not found during build"

**Debug Process**:

```bash
# 1. Check Docker is running
docker ps  # Should NOT error

# 2. View full build logs
# Command Palette ‚Üí "Dev Containers: Rebuild Container" ‚Üí Watch Output panel

# 3. Test Dockerfile directly (bypass VS Code)
cd .devcontainer
docker build -t test-build .
# This shows exact line where build fails

# 4. Common fixes:
```

**Common build errors**:

| Error Message | Cause | Fix |
|---------------|-------|-----|
| `E: Package 'xyz' has no installation candidate` | Package name wrong or not in repos | Update `apt-get update` or check spelling |
| `npm ERR! code ENOTFOUND` | Network issue | Check internet, try different npm registry |
| `Permission denied` | Running as wrong user | Check `USER node` comes after `RUN npm install` |
| `/bin/sh: 1: xyz: not found` | PATH not set or tool not installed | Verify tool installation in Dockerfile |

### Step 3: Startup Failures

**Symptoms**: Container builds but fails to start, postStartCommand errors

**Debug Process**:

```bash
# 1. View container logs
docker ps -a  # Find container ID (even if stopped)
docker logs <container-id>

# 2. Check postStartCommand (comment it out temporarily)
# In devcontainer.json:
// "postStartCommand": "sudo /usr/local/bin/init-firewall.sh",

# 3. Try starting container manually
docker run -it <image-id> /bin/bash
# Now run postStartCommand manually to see exact error

# 4. Check init scripts have execute permissions
ls -la .devcontainer/*.sh
# Should show: -rwxr-xr-x (x = executable)

# Fix if needed:
chmod +x .devcontainer/*.sh
```

### Step 4: Runtime Issues (Inside Container)

**Symptoms**: Container runs, but "command not found", "permission denied", or tools don't work

**Debug Process**:

```bash
# 1. Verify PATH
echo $PATH
# Should include /usr/local/bin, /home/node/.npm-global/bin, etc.

# 2. Check tool installation
which claude
which node
which python3

# 3. If "command not found":
ls -la /usr/local/bin  # Check if binary exists
npm list -g --depth=0  # List global npm packages

# 4. Test tool directly with full path
/usr/local/bin/claude --version
/home/node/.npm-global/bin/claude --version

# 5. Check environment variables
env | grep -i claude
env | grep -i path

# 6. Fix PATH in devcontainer.json
{
  "containerEnv": {
    "PATH": "/usr/local/bin:/home/node/.npm-global/bin:${containerEnv:PATH}"
  }
}
```

### Step 5: VS Code Integration Issues

**Symptoms**: Extensions don't install, ports don't forward, terminal doesn't open

**Debug Process**:

```bash
# 1. Check VS Code Server installed in container
docker exec <container-id> ls -la /home/node/.vscode-server

# 2. Reinstall VS Code Server
# Command Palette ‚Üí "Dev Containers: Rebuild Container Without Cache"

# 3. Check extension installation
# View ‚Üí Extensions ‚Üí Filter to "Installed"
# Should show extensions from devcontainer.json

# 4. Manually install extension
# Command Palette ‚Üí "Extensions: Install Extension"

# 5. Check port forwarding
# Ports tab in VS Code (bottom panel)
# Manually forward: Right-click port ‚Üí "Forward Port"

# 6. Reset VS Code Remote connection
# Delete ~/.vscode-server in container
docker exec <container-id> rm -rf /home/node/.vscode-server
# Restart VS Code
```

### Step 6: Nuclear Options (When All Else Fails)

```bash
# 1. Rebuild without cache
# Command Palette ‚Üí "Dev Containers: Rebuild Container Without Cache"

# 2. Remove container and volumes
docker ps -a | grep "your-project"
docker rm -f <container-id>
docker volume ls | grep "your-project"
docker volume rm <volume-name>

# 3. Clean Docker entirely
docker system prune -a --volumes  # CAUTION: Removes everything!

# 4. Restart Docker Desktop
# Quit Docker Desktop ‚Üí Wait 30 seconds ‚Üí Restart

# 5. Reset Docker Desktop to factory settings
# Docker Desktop ‚Üí Troublesoot ‚Üí Reset to factory defaults
```

---

## Volume Persistence Patterns

Volumes ensure configuration persists across container rebuilds.

### Named Volumes (Recommended for Configs)

**Pattern**: `source=<name>-${devcontainerId},target=<path>,type=volume`

```json
{
  "mounts": [
    "source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume",
    "source=bashhistory-${devcontainerId},target=/commandhistory,type=volume",
    "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume"
  ]
}
```

**Benefits**:
- ‚úÖ Unique per devcontainer instance (`${devcontainerId}` auto-generated)
- ‚úÖ Survives container deletion (until `docker volume rm`)
- ‚úÖ Fast performance (Docker-managed)
- ‚úÖ Easy to inspect: `docker volume ls`, `docker volume inspect <name>`

**Use cases**: API keys, shell history, package caches

### Bind Mounts (Advanced/Special Cases)

**Pattern**: `source=/host/path,target=/container/path,type=bind`

```json
{
  "mounts": [
    "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly",
    "source=${localWorkspaceFolder}/data,target=/data,type=bind"
  ]
}
```

**Benefits**:
- ‚úÖ Direct access to host filesystem
- ‚úÖ Changes reflect immediately on both sides
- ‚úÖ Useful for debugging, shared data

**Cautions**:
- ‚ö†Ô∏è Exposes host filesystem (security risk if container compromised)
- ‚ö†Ô∏è Platform-specific paths (`/Users/` on Mac, `/home/` on Linux, WSL paths on Windows)
- ‚ö†Ô∏è Performance issues on Mac/Windows (Docker Desktop overhead)

**Use cases**: SSH keys (readonly!), large datasets, debugging

### Common Persisted Paths

```json
{
  "mounts": [
    // AI tool configurations (critical!)
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
    "source=codex-${devcontainerId},target=/home/node/.codex,type=volume",
    "source=gemini-${devcontainerId},target=/home/node/.gemini,type=volume",

    // Shell history (quality of life)
    "source=bashhistory-${devcontainerId},target=/commandhistory,type=volume",

    // Package manager caches (speeds up rebuilds)
    "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume",
    "source=cargo-${devcontainerId},target=/home/node/.cargo,type=volume",
    "source=pip-cache-${devcontainerId},target=/home/node/.cache/pip,type=volume"
  ]
}
```

### Inspecting and Managing Volumes

```bash
# List all volumes
docker volume ls

# Inspect specific volume (shows mount point, size)
docker volume inspect claude-code-config-<devcontainerId>

# Access volume data (advanced - mounts volume to temporary Alpine container)
docker run --rm -v claude-code-config-<devcontainerId>:/data alpine ls -la /data

# Backup volume to tarball
docker run --rm -v claude-code-config-<devcontainerId>:/data -v $(pwd):/backup alpine tar czf /backup/claude-backup.tar.gz /data

# Restore volume from tarball
docker run --rm -v claude-code-config-<devcontainerId>:/data -v $(pwd):/backup alpine tar xzf /backup/claude-backup.tar.gz -C /

# Remove unused volumes
docker volume prune

# Remove specific volume (CAUTION: deletes all data!)
docker volume rm claude-code-config-<devcontainerId>
```

### Volume vs Bind Mount Decision Matrix

| Use Case | Volume | Bind Mount |
|----------|--------|------------|
| API keys, configs | ‚úÖ | ‚ùå |
| Shell history | ‚úÖ | ‚ùå |
| Package caches | ‚úÖ | ‚ùå |
| SSH keys (readonly) | ‚ùå | ‚úÖ |
| Large datasets (shared with host) | ‚ùå | ‚úÖ |
| Source code | ‚ùå (VS Code mounts this) | ‚ùå |
| Debugging container issues | ‚ùå | ‚úÖ |

---

## Platform-Specific Notes

### macOS (Intel and Apple Silicon)

**Docker Desktop Settings**:
- Allocate at least 4GB RAM, 8GB recommended
- Enable VirtioFS for better file sharing performance (Preferences ‚Üí Experimental Features)

**Apple Silicon (M1/M2/M3) Specifics**:
```dockerfile
# Some packages need platform specification
FROM --platform=linux/amd64 node:20  # Force x86 emulation (slower but compatible)
# OR
FROM node:20  # Native ARM64 (faster, but ensure all tools support ARM)
```

**Common Issues**:
- **Slow file sync**: Use VirtioFS instead of osxfs
- **Chromium crashes**: Install `chromium` instead of `google-chrome` in Dockerfile
- **Python package build failures**: Install build tools: `apt-get install -y build-essential`

### Windows (WSL2 Required)

**Prerequisites**:
1. Windows 10/11 version 21H2 or higher
2. WSL2 enabled: `wsl --install` in PowerShell (Admin)
3. Docker Desktop ‚Üí Settings ‚Üí "Use WSL2 based engine" ‚úÖ

**File System Best Practices**:
- ‚úÖ **Store projects in WSL2 filesystem** (`/home/user/projects/`, accessed as `\\wsl$\Ubuntu\home\user\`)
- ‚ùå **Don't store in Windows filesystem** (`C:\Users\...` is slow via Docker)

**Performance**:
```bash
# Clone projects into WSL2 (FAST)
cd ~
git clone https://github.com/your/project.git
code project

# NOT into Windows drive (SLOW)
cd /mnt/c/Users/You/Documents  # Slow Docker access
```

**Common Issues**:
- **"Docker daemon not responding"**: Restart Docker Desktop
- **Slow builds**: Ensure project is in WSL2 filesystem, not `/mnt/c/`
- **Line ending issues**: Configure git in WSL: `git config --global core.autocrlf input`

### Linux (Native Docker)

**Recommended**: Ubuntu 20.04+, Debian 11+, or equivalent

**Installation** (Ubuntu/Debian):
```bash
# Install Docker Engine (not Desktop)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Add user to docker group (no sudo needed)
sudo usermod -aG docker $USER
newgrp docker  # Apply without logout

# Verify
docker run hello-world
```

**File Permissions**:
- Linux containers use **same UID/GID** as files
- If user in container is UID 1000, files will be owned by your host user (UID 1000)
- **Fix permissions issues**:
  ```dockerfile
  ARG USER_UID=1000
  ARG USER_GID=1000
  RUN groupmod --gid $USER_GID node && \
      usermod --uid $USER_UID --gid $USER_GID node
  ```

**Common Issues**:
- **Permission denied**: Add user to `docker` group
- **Docker socket errors**: `sudo systemctl start docker`
- **Out of disk space**: `docker system prune -a` (cleans up old images)

### Sources

- **Docker Desktop for Mac**: https://docs.docker.com/desktop/mac/
- **Docker Desktop for Windows**: https://docs.docker.com/desktop/windows/
- **WSL2 Setup Guide**: https://docs.docker.com/desktop/windows/wsl/
- **Docker Engine for Linux**: https://docs.docker.com/engine/install/
- **Apple Silicon Compatibility**: https://docs.docker.com/desktop/mac/apple-silicon/

---

## Resource and Performance Considerations

### Disk Space Requirements

**Typical Usage**:
- Base Node.js devcontainer: ~1GB
- With build tools + Chromium: ~2-3GB
- Python data science stack: ~4-5GB
- **Recommendation**: Keep 20GB free for comfortable development

**Monitoring**:
```bash
# Check Docker disk usage
docker system df

# Detailed breakdown
docker system df -v
```

**Cleanup Strategies**:
```bash
# Remove old containers (keep images/volumes)
docker container prune

# Remove unused images (rebuilds will redownload)
docker image prune -a

# Remove unused volumes (CAUTION: deletes configs if not careful)
docker volume prune

# Weekly maintenance (safe)
docker container prune && docker image prune
```

### Memory Allocation

**Defaults** (Docker Desktop):
- Mac: 2GB (increase to 4-8GB)
- Windows: 2GB (increase to 4-8GB)
- Linux: No limit (uses host RAM)

**Recommendations by Use Case**:
- Simple Node.js/Python dev: 4GB
- Full-stack with databases: 8GB
- Data science (pandas, ML): 8-16GB

**Configure** (Docker Desktop ‚Üí Preferences ‚Üí Resources ‚Üí Memory)

**Monitor**:
```bash
# Real-time container resource usage
docker stats

# Specific container
docker stats <container-id>
```

### CPU Allocation

**Defaults**: Docker Desktop uses available cores

**Limit CPUs** (if needed):
```json
{
  "runArgs": [
    "--cpus=2"
  ]
}
```

### Build Performance Optimization

**Layer Caching**:
```dockerfile
# GOOD: Dependency changes rarely, cache this layer
COPY package.json package-lock.json ./
RUN npm install
COPY . .  # Source code changes frequently

# BAD: Any source change rebuilds npm install
COPY . .
RUN npm install
```

**Multi-stage Builds** (advanced):
```dockerfile
# Build stage
FROM node:20 AS builder
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Runtime stage (smaller final image)
FROM node:20-slim
COPY --from=builder /app/dist /app
```

**Parallel Package Installation**:
```dockerfile
# npm: Use npm ci (faster than npm install)
RUN npm ci

# Python: Use uv instead of pip
RUN pip install uv && uv pip install -r requirements.txt
```

**Always Upgrade npm to Latest** (October 2025 best practice):

```dockerfile
FROM node:20

# IMPORTANT: Upgrade npm immediately after base image
# Why: node:20 ships with npm 10.8.x, latest is 10.9.x+
# Benefits: Security patches, performance improvements, bug fixes
RUN npm install -g npm@latest

# Then continue with your Dockerfile...
```

**Why this matters**:
- Base images ship with npm version from their build date (often months old)
- npm releases security patches frequently
- Newer npm versions have performance optimizations
- `apt-get update` won't upgrade npm (it's installed via Node.js, not apt)

**Real-world impact**:
```bash
# Without npm upgrade (node:20 default):
npm --version  # 10.8.2

# With npm upgrade:
npm --version  # 10.9.2 (latest at time of build)
```

**Performance benefit**:
- npm 10.9+ has improved lockfile handling
- Faster `npm install` operations
- Better error messages for troubleshooting

**Best practice location in Dockerfile**:
```dockerfile
FROM node:20

ARG TZ
ENV TZ="$TZ"

# DO THIS EARLY (before installing other packages)
RUN npm install -g npm@latest

# Then continue with system packages
RUN apt-get update && apt-get install -y ...
```

**Why early in Dockerfile**:
- Ensures all subsequent npm operations use latest version
- Prevents version inconsistencies
- Better layer caching (npm version rarely changes)

### BuildKit Cache Mounts (5-10x Faster Rebuilds)

**Critical Performance Optimization** (October 2025 best practice):

BuildKit cache mounts dramatically speed up Docker builds by caching package downloads between builds.

**Problem with traditional builds**:
```dockerfile
# BAD: Redownloads packages on EVERY rebuild
RUN apt-get update && apt-get install -y \
    git curl wget chromium
```

**Result**: Even minor Dockerfile changes force re-downloading 500MB+ of packages

**Solution: BuildKit cache mounts**:
```dockerfile
# GOOD: Packages cached, only download new/changed ones
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
    apt-get update && apt-get install -y \
    git curl wget chromium
```

**Performance Impact**:
- **First build**: ~10 minutes (downloads everything)
- **Subsequent builds**: ~2 minutes (reuses cached packages)
- **Speedup**: 5-10x faster rebuilds

**How it works**:
1. `--mount=type=cache` creates a persistent cache directory
2. `target=/var/cache/apt` is where apt stores downloaded .deb files
3. `target=/var/lib/apt/lists` is where apt stores package metadata
4. `sharing=locked` prevents race conditions if multiple builds run concurrently
5. Cache survives Docker layer invalidation

**Complete Example**:

```dockerfile
FROM node:20

# Enable BuildKit (required)
# Set in Docker Desktop or via DOCKER_BUILDKIT=1 docker build

# Upgrade npm to latest with cache
RUN --mount=type=cache,target=/root/.npm \
    npm install -g npm@latest

# Install system packages with cache
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    git \
    curl \
    ripgrep \
    fd-find \
    chromium \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Note: The "apt-get clean && rm -rf /var/lib/apt/lists/*" at the end
# is still useful to keep the final image layer small, even though
# the cache mount keeps the packages cached separately

USER node

# Cache npm packages during global installs
RUN --mount=type=cache,target=/home/node/.npm,uid=1000 \
    npm install -g @anthropic-ai/claude-code@latest
```

**Common Cache Locations**:

| Package Manager | Cache Mount Target |
|----------------|-------------------|
| **apt** (Debian/Ubuntu) | `/var/cache/apt` and `/var/lib/apt/lists` |
| **npm** | `/home/node/.npm` or `/root/.npm` |
| **pip** | `/root/.cache/pip` |
| **cargo** (Rust) | `/usr/local/cargo/registry` |
| **go** | `/go/pkg/mod` |

**Enabling BuildKit** (if not already enabled):

```bash
# Method 1: Environment variable (per-build)
DOCKER_BUILDKIT=1 docker build .devcontainer

# Method 2: Docker Desktop settings
# Docker Desktop ‚Üí Preferences ‚Üí Docker Engine
# Add: { "features": { "buildkit": true } }

# Method 3: Daemon config (persistent)
# /etc/docker/daemon.json
{
  "features": {
    "buildkit": true
  }
}
```

**VS Code devcontainer.json** (uses BuildKit automatically if Docker Desktop has it enabled):
```json
{
  "build": {
    "dockerfile": "Dockerfile"
    // BuildKit enabled by default in recent Docker Desktop versions
  }
}
```

**Debugging Cache Issues**:

```bash
# View BuildKit cache usage
docker system df -v | grep buildkit

# Clear BuildKit cache (if needed)
docker builder prune

# Build with cache disabled (debugging)
DOCKER_BUILDKIT=1 docker build --no-cache .devcontainer
```

**When NOT to use cache mounts**:
- ‚ùå CI/CD systems without persistent Docker layer cache (cache won't help)
- ‚ùå Security-sensitive builds requiring fresh downloads every time
- ‚ùå Docker versions < 18.09 (BuildKit not available)

**When to ALWAYS use cache mounts**:
- ‚úÖ Local development with frequent rebuilds
- ‚úÖ Team devcontainers (everyone benefits from caching)
- ‚úÖ Large base images (Chromium, ML frameworks, databases)
- ‚úÖ Multi-stage builds (cache intermediate stages)

**Combining with .dockerignore**:

Cache mounts work best when combined with `.dockerignore`:

```bash
# .dockerignore - prevents invalidating cache
node_modules/
.git/
.env
*.log
.DS_Store
```

**Real-world impact example**:

```dockerfile
# Before BuildKit cache mounts:
# Rebuild after changing one line: 10 minutes (redownloads Chromium, build tools)

# After BuildKit cache mounts:
# Same rebuild: 2 minutes (uses cached packages)
# Savings: 8 minutes per rebuild
# Over 10 rebuilds per week: 80 minutes saved
```

**Best Practice Checklist**:
- [ ] Use `--mount=type=cache` for apt/yum/apk package managers
- [ ] Use `--mount=type=cache` for language package managers (npm, pip, cargo)
- [ ] Set `sharing=locked` for multi-stage builds or parallel builds
- [ ] Keep `apt-get clean` at end (doesn't affect cache, reduces layer size)
- [ ] Use appropriate UID in cache mount if running as non-root user
- [ ] Document BuildKit requirement in README for team members

### Network Performance

**DNS Issues**:
```json
{
  "runArgs": [
    "--dns=8.8.8.8",
    "--dns=1.1.1.1"
  ]
}
```

### Startup Time Optimization

**Slow postStartCommand?**
```json
{
  // BAD: Runs sequentially
  "postStartCommand": "npm install && pip install -r requirements.txt && rake setup",

  // GOOD: Run in background, non-blocking
  "postStartCommand": "npm install &"
}
```

### Sources

- **Docker Resource Management**: https://docs.docker.com/config/containers/resource_constraints/
- **Docker Desktop Resource Settings**: https://docs.docker.com/desktop/settings/
- **Performance Best Practices**: https://docs.docker.com/develop/dev-best-practices/
- **Build Cache Optimization**: https://docs.docker.com/build/cache/

---

## Step-by-Step Debug Process

## VS Code Tips & Tricks

> **AI Assistant Guidance**: These productivity enhancements make devcontainers more powerful and user-friendly. Recommend these tips when users ask about optimizing their VS Code devcontainer workflow.

**Official Documentation**: https://code.visualstudio.com/docs/devcontainers/tips-and-tricks

### Copilot Instructions in devcontainer.json

Embed AI coding assistant instructions directly in your devcontainer configuration.

**Feature**: `github.copilot.chat.codeGeneration.instructions`

**devcontainer.json**:
```json
{
  "customizations": {
    "vscode": {
      "settings": {
        "github.copilot.chat.codeGeneration.instructions": [
          {
            "text": "Always use TypeScript strict mode"
          },
          {
            "text": "Prefer functional components in React"
          },
          {
            "text": "Use Tailwind CSS for styling, avoid inline styles"
          },
          {
            "text": "Write comprehensive JSDoc comments for all functions"
          }
        ]
      }
    }
  }
}
```

**Benefits**:
- Consistent AI suggestions across team
- Project-specific coding standards
- Onboard new developers automatically
- Version-controlled AI instructions

**Official Docs**: https://code.visualstudio.com/docs/devcontainers/tips-and-tricks#_copilot-instructions

---

### Settings Sync and Dotfiles

Personalize devcontainers while maintaining team standards.

#### Personal Dotfiles Integration

**Configure in VS Code Settings** (applies to all devcontainers):
```json
{
  "dotfiles.repository": "yourusername/dotfiles",
  "dotfiles.targetPath": "~/dotfiles",
  "dotfiles.installCommand": "install.sh"
}
```

**What happens**:
1. Devcontainer starts
2. VS Code clones your dotfiles repository
3. Runs `install.sh` to set up your personalization
4. Your shell configs, aliases, git config applied

**Example dotfiles repo structure**:
```
dotfiles/
‚îú‚îÄ‚îÄ .bashrc
‚îú‚îÄ‚îÄ .zshrc
‚îú‚îÄ‚îÄ .gitconfig
‚îú‚îÄ‚îÄ .vimrc
‚îî‚îÄ‚îÄ install.sh
```

**install.sh**:
```bash
#!/bin/bash
ln -sf ~/dotfiles/.bashrc ~/.bashrc
ln -sf ~/dotfiles/.gitconfig ~/.gitconfig
source ~/.bashrc
```

**Official Docs**: https://code.visualstudio.com/docs/devcontainers/containers#_personalizing-with-dotfile-repositories

---

### Default Extensions vs User Extensions

**Default Extensions** (in devcontainer.json):
- Installed automatically for all users
- Version-controlled, team standard
- Example: ESLint, Prettier, language support

**User Extensions** (from Settings Sync):
- Personal choices (themes, keybindings, etc.)
- Not imposed on team
- Example: Vim emulation, custom themes

**Best practice**:
```json
{
  "customizations": {
    "vscode": {
      "extensions": [
        // Team standards (everyone gets these)
        "dbaeumer.vscode-eslint",
        "esbenp.prettier-vscode",
        "ms-python.python"
        // Don't include personal preferences like themes
      ]
    }
  }
}
```

---

### Workspace Trust

Control security when opening untrusted repositories.

**Trust Levels**:
- **Trusted**: Full extension capabilities, run tasks
- **Restricted**: Limited execution, read-only mode

**Configure trust**:
```json
{
  "security.workspace.trust.enabled": true,
  "security.workspace.trust.untrustedFiles": "open",
  "security.workspace.trust.startupPrompt": "always"
}
```

**For devcontainers** (considered safer since isolated):
```json
{
  "security.workspace.trust.enabled": false
}
```

**Use case**: Open untrusted open-source projects in devcontainers without fear of malicious scripts accessing host.

**Official Docs**: https://code.visualstudio.com/docs/editor/workspace-trust

---

### Debugging Configurations

Pre-configure debuggers for the team.

**.vscode/launch.json** (included in project, not devcontainer):
```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug FastAPI",
      "type": "python",
      "request": "launch",
      "module": "uvicorn",
      "args": ["main:app", "--reload", "--port", "8000"],
      "jinja": true
    },
    {
      "name": "Debug Tests",
      "type": "python",
      "request": "launch",
      "module": "pytest",
      "args": ["-v"]
    }
  ]
}
```

**Combine with devcontainer.json**:
```json
{
  "customizations": {
    "vscode": {
      "extensions": ["ms-python.python"],
      "settings": {
        "python.defaultInterpreterPath": "/usr/local/bin/python"
      }
    }
  }
}
```

Team members open project ‚Üí debugger pre-configured ‚Üí press F5 ‚Üí debug works.

---

### Tasks Integration

Automate common workflows.

**.vscode/tasks.json**:
```json
{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Run Tests",
      "type": "shell",
      "command": "npm test",
      "group": {
        "kind": "test",
        "isDefault": true
      },
      "problemMatcher": []
    },
    {
      "label": "Build Production",
      "type": "shell",
      "command": "npm run build",
      "group": {
        "kind": "build",
        "isDefault": true
      }
    },
    {
      "label": "Start Dev Server",
      "type": "shell",
      "command": "npm run dev",
      "isBackground": true,
      "problemMatcher": {
        "pattern": {
          "regexp": "."
        },
        "background": {
          "activeOnStart": true,
          "beginsPattern": ".",
          "endsPattern": "ready"
        }
      }
    }
  ]
}
```

**Access tasks**: `Cmd+Shift+P` ‚Üí "Tasks: Run Task"

---

### Port Forwarding Management

#### Automatic Port Forwarding

**devcontainer.json**:
```json
{
  "forwardPorts": [3000, 8080],
  "portsAttributes": {
    "3000": {
      "label": "Frontend Dev Server",
      "protocol": "http",
      "onAutoForward": "openBrowser"
    },
    "8080": {
      "label": "Backend API",
      "protocol": "http",
      "onAutoForward": "notify"
    },
    "5432": {
      "label": "PostgreSQL",
      "onAutoForward": "silent",
      "requireLocalPort": true
    }
  }
}
```

**onAutoForward options**:
- `openBrowser`: Opens in browser automatically
- `openPreview`: Opens in VS Code simple browser
- `notify`: Shows notification
- `silent`: Forwards quietly
- `ignore`: Don't forward

---

### Remote Environment Variables

Access devcontainer context in your shell.

**Available variables**:
```bash
# Inside devcontainer
echo $REMOTE_CONTAINERS           # true
echo $REMOTE_CONTAINERS_IPC       # Path to IPC socket
echo $VSCODE_REMOTE_CONTAINERS_SESSION  # Session ID
```

**Use in scripts**:
```bash
if [ -n "$REMOTE_CONTAINERS" ]; then
  echo "Running in devcontainer"
  # Devcontainer-specific setup
else
  echo "Running locally"
  # Local setup
fi
```

---

### Multi-Root Workspaces

Open multiple projects in one devcontainer.

**workspace.code-workspace**:
```json
{
  "folders": [
    {
      "name": "Frontend",
      "path": "./frontend"
    },
    {
      "name": "Backend",
      "path": "./backend"
    },
    {
      "name": "Shared",
      "path": "./shared"
    }
  ],
  "settings": {
    "terminal.integrated.cwd": "${workspaceFolder:Backend}"
  }
}
```

**devcontainer.json**:
```json
{
  "workspaceFolder": "/workspace",
  "workspaceMount": "source=${localWorkspaceFolder},target=/workspace,type=bind"
}
```

Open `workspace.code-workspace` ‚Üí All folders accessible in sidebar.

---

### Performance: Exclude Files from Sync

Improve file watching performance by excluding large directories.

**devcontainer.json**:
```json
{
  "customizations": {
    "vscode": {
      "settings": {
        "files.watcherExclude": {
          "**/node_modules/**": true,
          "**/.git/objects/**": true,
          "**/.git/subtree-cache/**": true,
          "**/dist/**": true,
          "**/build/**": true,
          "**/__pycache__/**": true,
          "**/.venv/**": true
        },
        "search.exclude": {
          "**/node_modules": true,
          "**/bower_components": true,
          "**/.venv": true,
          "**/dist": true
        }
      }
    }
  }
}
```

**Impact**: Faster file searches, reduced CPU usage, better responsiveness.

---

### Development Container Features Quick Add

Add features on-the-fly without editing devcontainer.json manually.

**Command Palette** ‚Üí "Dev Containers: Configure Container Features"
- Browse available features
- Select and configure options
- VS Code updates devcontainer.json automatically
- Rebuild to apply

---

### Sources
- **VS Code Devcontainer Tips**: https://code.visualstudio.com/docs/devcontainers/tips-and-tricks
- **Dotfiles Personalization**: https://code.visualstudio.com/docs/devcontainers/containers#_personalizing-with-dotfile-repositories
- **Workspace Trust**: https://code.visualstudio.com/docs/editor/workspace-trust
- **Tasks**: https://code.visualstudio.com/docs/editor/tasks
- **Debugging**: https://code.visualstudio.com/docs/editor/debugging

---

## Remote Development Platforms

> **AI Assistant Guidance**: Dev containers work with multiple platforms beyond local Docker Desktop. This section covers GitHub Codespaces, Gitpod, and other remote development scenarios.

### GitHub Codespaces

**What is it**: Cloud-based VS Code environment that runs your devcontainer in GitHub's infrastructure.

**Benefits**:
- Zero local setup (no Docker Desktop needed)
- Powerful cloud machines (up to 32 cores, 64GB RAM)
- Billed per-hour usage
- Pre-configured for your repository

**How it works**:
1. GitHub reads `.devcontainer/devcontainer.json` from your repo
2. Builds container in cloud
3. Opens browser-based or local VS Code connected to cloud container

**Configuration** (same as local devcontainer):

```json
{
  "name": "My Project",
  "image": "node:20",
  "customizations": {
    "codespaces": {
      "openFiles": ["README.md", "src/index.ts"]
    }
  }
}
```

**Codespaces-specific settings**:

```json
{
  "hostRequirements": {
    "cpus": 4,
    "memory": "8gb",
    "storage": "32gb"
  },
  "customizations": {
    "codespaces": {
      "openFiles": ["README.md"],
      "repositories": {
        "my-org/my-other-repo": {
          "permissions": "read-all"
        }
      }
    }
  }
}
```

**Using Codespaces**:

```bash
# Create codespace from CLI
gh codespace create --repo myorg/myrepo

# Or from GitHub UI
# Repository ‚Üí Code ‚Üí Codespaces ‚Üí New codespace
```

**Prebuild Configuration** (`.github/workflows/codespaces-prebuild.yml`):

```yaml
name: Codespaces Prebuild
on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: devcontainers/ci@v0.3
        with:
          push: always
          refFilterForPushFilter: refs/heads/main
```

**Pricing** (as of 2024):
- Free tier: 120 core-hours/month
- 2-core machine: ~$0.18/hour
- 4-core machine: ~$0.36/hour
- Storage: $0.07/GB-month

**Sources**:
- **Codespaces Docs**: https://docs.github.com/en/codespaces
- **devcontainer.json for Codespaces**: https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration

---

### Gitpod

**What is it**: Cloud development environment similar to Codespaces, works with GitHub/GitLab/Bitbucket.

**Configuration** (`.gitpod.yml`):

```yaml
image:
  file: .devcontainer/Dockerfile

tasks:
  - init: npm install
    command: npm run dev

ports:
  - port: 3000
    onOpen: open-preview

vscode:
  extensions:
    - anthropic.claude-code
    - dbaeumer.vscode-eslint
```

**Using existing devcontainer** (Gitpod can read devcontainer.json):

```yaml
image:
  file: .devcontainer/devcontainer.json
```

**Pricing**:
- Free tier: 50 hours/month
- Standard: $9/month (100 hours)
- Professional: Custom pricing

**Sources**:
- **Gitpod Docs**: https://www.gitpod.io/docs
- **Using devcontainers in Gitpod**: https://www.gitpod.io/docs/configure/dev-containers

---

### Remote SSH Development

**Scenario**: Connect local VS Code to devcontainer running on remote server.

**Setup**:

1. **Install Remote-SSH extension** in VS Code
2. **SSH into remote server**, clone project
3. **Start devcontainer** on remote server:
   ```bash
   devcontainer up --workspace-folder /path/to/project
   ```
4. **Connect VS Code** to remote devcontainer:
   - VS Code ‚Üí Remote Explorer ‚Üí SSH Targets
   - Connect to server
   - Open project folder
   - Container will auto-start

**Use cases**:
- Development on powerful remote workstation
- Accessing GPU resources for ML
- Building ARM images on ARM server

**Sources**:
- **Remote SSH**: https://code.visualstudio.com/docs/remote/ssh
- **Developing in WSL**: https://code.visualstudio.com/docs/remote/wsl

---

### JetBrains IDEs (IntelliJ, PyCharm, WebStorm)

**Status**: JetBrains has limited devcontainer support via "Dev Containers" plugin.

**Setup**:

1. Install "Dev Containers" plugin
2. Open project with `.devcontainer/`
3. IDE reads devcontainer.json and starts container

**Limitations**:
- Not all devcontainer.json properties supported
- Primarily works with `image` property
- `customizations.vscode` settings ignored

**Alternative**: Use Remote Development plugin for Docker containers:

```xml
<!-- .idea/workspace.xml -->
<component name="DockerSettings">
  <option name="targetName" value="your-container" />
</component>
```

**Sources**:
- **JetBrains Dev Containers**: https://www.jetbrains.com/help/idea/connect-to-devcontainer.html
- **Docker Plugin**: https://www.jetbrains.com/help/idea/docker.html

---

### Platform Comparison

| Feature | Local (Docker Desktop) | GitHub Codespaces | Gitpod | Remote SSH |
|---------|------------------------|-------------------|---------|------------|
| **Setup Time** | 5-10 min first build | Instant (with prebuild) | Instant (with prebuild) | Varies |
| **Cost** | Free (local resources) | ~$0.18/hour | Free tier: 50h/mo | Server cost |
| **Performance** | Depends on laptop | Up to 32 cores | Up to 16 cores | Server specs |
| **Offline Support** | ‚úÖ Yes | ‚ùå No | ‚ùå No | ‚ùå No |
| **GPU Access** | Limited (macOS) | ‚ùå No | ‚ùå No | ‚úÖ Yes (if server has GPU) |
| **Team Collaboration** | Via git only | ‚úÖ Live Share built-in | ‚úÖ Live Share | Via git only |
| **Best For** | Individual dev, offline work | Teams, onboarding, demos | Open source projects | GPU/ML work, powerful servers |

---

### Choosing the Right Platform

**Use Local Docker Desktop if**:
- ‚úÖ You work offline frequently
- ‚úÖ You have a powerful laptop (16GB+ RAM)
- ‚úÖ You need full control over environment
- ‚úÖ You're working solo or small team

**Use GitHub Codespaces if**:
- ‚úÖ Team collaboration is priority
- ‚úÖ You want instant onboarding for new devs
- ‚úÖ You need to demo features to clients
- ‚úÖ You already use GitHub
- ‚úÖ Budget allows ~$50-100/month per developer

**Use Gitpod if**:
- ‚úÖ Open source project with contributors
- ‚úÖ Multi-platform repositories (GitHub + GitLab)
- ‚úÖ Want free tier for occasional use
- ‚úÖ Need quick "Open in Gitpod" button for users

**Use Remote SSH if**:
- ‚úÖ You have dedicated development server
- ‚úÖ Need GPU for ML/AI development
- ‚úÖ Building cross-platform (ARM on x86 server)
- ‚úÖ Corporate environment with remote servers

---

## Devcontainer CLI Reference

> **AI Assistant Guidance**: The Dev Container CLI enables non-VS Code workflows, CI/CD integration, and automation. Recommend CLI for testing, scripting, and GitHub Actions integration.

**Repository**: https://github.com/devcontainers/cli
**Documentation**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md

### What is the Dev Container CLI?

The **Dev Container CLI** (`@devcontainers/cli`) is a reference implementation of the Dev Container specification that enables:

- **CI/CD Integration**: Build and test in devcontainers via GitHub Actions, GitLab CI, etc.
- **Non-VS Code Workflows**: Use devcontainers with other editors or headless
- **Automation**: Script devcontainer operations
- **Testing**: Validate devcontainer configurations
- **Prebuild Creation**: Build and publish devcontainer images

**Not just for VS Code**: While VS Code is the primary consumer, the CLI enables broader adoption.

---

### Installation

#### Global Installation (Recommended)

```bash
npm install -g @devcontainers/cli
```

**Verify**:
```bash
devcontainer --version
```

#### Local Installation (Project-specific)

```bash
npm install --save-dev @devcontainers/cli
```

**Usage**:
```bash
npx devcontainer --help
```

---

### Core Commands

#### `devcontainer build`

Build a development container image.

**Basic usage**:
```bash
devcontainer build --workspace-folder .
```

**Build and tag**:
```bash
devcontainer build \
  --workspace-folder . \
  --image-name myproject-dev:latest
```

**Build and push to registry**:
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-dev:1.0.0
```

**Options**:
- `--workspace-folder <path>`: Project directory (default: `.`)
- `--image-name <name>`: Tag for built image
- `--push`: Push to registry after building
- `--platform <platforms>`: Build for multiple platforms (e.g., `linux/amd64,linux/arm64`)
- `--no-cache`: Build without using cache

**Official Docs**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md#devcontainer-build

---

#### `devcontainer up`

Create and start a development container.

**Basic usage**:
```bash
devcontainer up --workspace-folder .
```

**Output container ID**:
```bash
CONTAINER_ID=$(devcontainer up --workspace-folder . | jq -r .containerId)
echo $CONTAINER_ID
```

**Options**:
- `--workspace-folder <path>`: Project directory
- `--remove-existing-container`: Remove existing container first
- `--skip-post-create`: Skip postCreateCommand
- `--user-data-folder <path>`: VS Code server data location

**Result**: Container created, started, and ready for connections.

**Official Docs**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md#devcontainer-up

---

#### `devcontainer exec`

Execute a command inside a running devcontainer.

**Basic usage**:
```bash
devcontainer exec --workspace-folder . npm test
```

**Run multiple commands**:
```bash
devcontainer exec --workspace-folder . bash -c "npm install && npm test"
```

**Options**:
- `--workspace-folder <path>`: Project directory
- `--remote-env <key=value>`: Set environment variable

**Use case**: CI/CD testing inside devcontainer.

**Official Docs**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md#devcontainer-exec

---

#### `devcontainer run-user-commands`

Run lifecycle commands (onCreateCommand, postCreateCommand, etc.).

**Basic usage**:
```bash
devcontainer run-user-commands --workspace-folder .
```

**Specific hook**:
```bash
devcontainer run-user-commands \
  --workspace-folder . \
  --command postCreateCommand
```

**Use case**: Manually trigger lifecycle hooks for debugging.

---

#### `devcontainer templates`

Manage devcontainer templates.

**Apply template to project**:
```bash
devcontainer templates apply \
  --template-id ghcr.io/devcontainers/templates/python \
  --template-args '{"imageVariant": "3.11"}' \
  --workspace-folder .
```

**Publish templates**:
```bash
devcontainer templates publish \
  -r ghcr.io \
  -n myorg/templates \
  ./src
```

**Official Docs**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md#devcontainer-templates-apply

---

### CI/CD Integration

#### GitHub Actions Example

**.github/workflows/test-in-devcontainer.yml**:
```yaml
name: Test in Dev Container

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Dev Container CLI
        run: npm install -g @devcontainers/cli

      - name: Build and start devcontainer
        run: |
          CONTAINER_ID=$(devcontainer up --workspace-folder . | jq -r .containerId)
          echo "CONTAINER_ID=$CONTAINER_ID" >> $GITHUB_ENV

      - name: Run tests inside devcontainer
        run: |
          devcontainer exec --workspace-folder . npm test

      - name: Run linter
        run: |
          devcontainer exec --workspace-folder . npm run lint

      - name: Build application
        run: |
          devcontainer exec --workspace-folder . npm run build
```

**Benefits**:
- Tests run in exact same environment as development
- No CI/CD-specific setup scripts
- Reproducible across local and CI

---

#### GitLab CI Example

**.gitlab-ci.yml**:
```yaml
test:
  image: node:20
  before_script:
    - npm install -g @devcontainers/cli
  script:
    - devcontainer up --workspace-folder .
    - devcontainer exec --workspace-folder . pytest
    - devcontainer exec --workspace-folder . npm run build
```

---

### Advanced: Pre-building for CI Speed

**Problem**: CI rebuilds devcontainer on every run (slow).

**Solution**: Pre-build devcontainer image, use in CI.

**Step 1: Build prebuild** (in separate workflow/manually):
```bash
devcontainer build \
  --workspace-folder . \
  --push true \
  --image-name ghcr.io/myorg/myproject-ci:latest
```

**Step 2: Update devcontainer.json** (use prebuild):
```json
{
  "image": "ghcr.io/myorg/myproject-ci:latest"
}
```

**Step 3: CI uses prebuild** (fast!):
```yaml
- name: Start devcontainer (instant, uses prebuild)
  run: devcontainer up --workspace-folder .
```

**Result**: CI startup time: 30s (pull image) instead of 10 minutes (build from scratch).

---

### Testing Devcontainer Configurations

Validate devcontainer.json before committing.

**Test script** (test-devcontainer.sh):
```bash
#!/bin/bash
set -e

echo "Testing devcontainer configuration..."

# Build devcontainer
devcontainer build --workspace-folder .

# Start devcontainer
CONTAINER_ID=$(devcontainer up --workspace-folder . | jq -r .containerId)
echo "Container ID: $CONTAINER_ID"

# Verify tools installed
devcontainer exec --workspace-folder . node --version
devcontainer exec --workspace-folder . python3 --version
devcontainer exec --workspace-folder . git --version

# Run postCreateCommand
devcontainer run-user-commands --workspace-folder .

# Run tests
devcontainer exec --workspace-folder . npm test

echo "‚úì Devcontainer configuration valid"
```

**Run in CI**:
```yaml
- name: Test devcontainer
  run: ./test-devcontainer.sh
```

---

### Non-VS Code Workflows

Use devcontainers with other editors.

**Vim/Neovim**:
```bash
# Start devcontainer
devcontainer up --workspace-folder .

# Attach to container with Neovim
docker exec -it $(docker ps -q --filter "label=devcontainer.local_folder=$PWD") nvim .
```

**JetBrains IDEs**:
- Use Docker integration
- Point to devcontainer configuration
- JetBrains reads `.devcontainer/devcontainer.json`

**Official Docs**: https://www.jetbrains.com/help/idea/connect-to-devcontainer.html

---

### Debugging with CLI

**View detailed output**:
```bash
devcontainer build --workspace-folder . --log-level trace
```

**Inspect container**:
```bash
devcontainer up --workspace-folder .
docker inspect $(docker ps -q --filter "label=devcontainer.local_folder=$PWD")
```

**Check lifecycle hooks executed**:
```bash
devcontainer exec --workspace-folder . cat /workspaces/.devcontainer-build.log
```

---

### Sources
- **Dev Container CLI Repository**: https://github.com/devcontainers/cli
- **CLI Reference Documentation**: https://github.com/devcontainers/cli/blob/main/docs/cli-reference.md
- **CI Integration Guide**: https://github.com/devcontainers/ci
- **NPM Package**: https://www.npmjs.com/package/@devcontainers/cli

---


### "Reopen in Container" Button Doesn't Appear

**Cause**: VS Code didn't detect `.devcontainer/devcontainer.json`

**Fix**:
```bash
# 1. Verify file exists
ls .devcontainer/devcontainer.json

# 2. Check JSON syntax
cat .devcontainer/devcontainer.json | jq
# If error, fix JSON syntax

# 3. Manually trigger
# Command Palette ‚Üí "Dev Containers: Reopen in Container"

# 4. Check .devcontainer isn't in .gitignore
cat .gitignore | grep devcontainer
# Remove any exclusion of .devcontainer/
```

### Build Fails with "Permission Denied"

**Cause**: File permissions or sudo configuration issue

**Fix**:
```dockerfile
# Ensure proper ownership BEFORE switching to node user
USER root
RUN mkdir -p /home/node/.claude && \
  chown -R node:node /home/node/.claude
USER node

# Check init scripts are executable
COPY init-firewall.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/init-firewall.sh
```

### Claude Code Command Not Found

**Cause**: PATH not configured or installation failed

**Fix**:
```dockerfile
# Install as non-root user
USER node
RUN npm install -g @anthropic-ai/claude-code@latest

# Verify installation
RUN claude --version
```

**In devcontainer.json**:
```json
{
  "containerEnv": {
    "PATH": "/home/node/.npm-global/bin:${containerEnv:PATH}"
  }
}
```

### Container Runs Out of Memory

**Cause**: Default Docker memory limits too low

**Fix**:
- **Mac/Windows**: Docker Desktop ‚Üí Preferences ‚Üí Resources ‚Üí Memory ‚Üí 8GB
- **Linux**: No limit by default, check host RAM: `free -h`

**Verify**:
```bash
# Inside container
docker stats <container-id>
```

### MCP Servers Not Loading

**Cause**: `mcp.json` not created, permissions issue, or invalid JSON

**Fix**:
```bash
# Inside container, check file exists
ls -la ~/.claude/mcp.json
# Should show: -rw-r--r-- node node

# Validate JSON syntax
cat ~/.claude/mcp.json | jq

# Check init script ran
docker logs <container-id> | grep "MCP"
# Should show: "‚úì MCP servers configured"

# Manually test MCP server
curl https://mcp.context7.com/sse  # SSE servers should respond
npx chrome-devtools-mcp@latest --help  # stdio servers should run
```

### Port Forwarding Not Working

**Cause**: Port not listed in `devcontainer.json` or firewall blocking

**Fix**:
```json
{
  "forwardPorts": [3000, 8080, 8888],
  "portsAttributes": {
    "3000": {
      "label": "Dev Server",
      "onAutoForward": "notify"
    }
  }
}
```

**Check in VS Code**:
- Ports tab (bottom panel) should list forwarded ports
- Manually forward: Right-click port ‚Üí "Forward Port"

### Extensions Not Installing

**Cause**: Network issues, incorrect extension ID, or VS Code Server issue

**Fix**:
```bash
# 1. Verify extension ID correct
# VS Code ‚Üí Extensions ‚Üí Gear icon ‚Üí "Copy Extension ID"

# 2. Test network from container
docker exec <container-id> curl -v https://marketplace.visualstudio.com

# 3. Manually install
# Command Palette ‚Üí "Extensions: Install Extension"

# 4. Rebuild container
# Command Palette ‚Üí "Dev Containers: Rebuild Container"
```

### Git "Dubious Ownership" Error

**Cause**: VS Code mounts workspace with host user UID, but container user has different UID

**Fix**:
```bash
# Inside container
git config --global --add safe.directory /workspaces/your-project

# Or in Dockerfile (applies to all projects)
RUN git config --global --add safe.directory '*'
```

---

## Migration Guides

> **AI Assistant Guidance**: These step-by-step guides help users migrate existing projects to devcontainers. Customize based on their specific stack.

### Guide 1: Migrating Node.js Projects to Devcontainers

**Scenario**: Existing Node.js project with local `node_modules/`, `.env`, and team using different Node versions.

**Step 1: Analyze Current Setup**

```bash
# Check what you have
node --version                    # e.g., v18.x
npm --version
ls -la | grep -E "package.json|.env|.nvmrc"
```

**Step 2: Create devcontainer.json**

```bash
mkdir -p .devcontainer
cd .devcontainer
```

**`.devcontainer/devcontainer.json`**:
```json
{
  "name": "${localWorkspaceFolderBasename}",
  "image": "node:20",
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "dbaeumer.vscode-eslint",
        "esbenp.prettier-vscode"
      ],
      "settings": {
        "editor.formatOnSave": true,
        "editor.defaultFormatter": "esbenp.prettier-vscode"
      }
    }
  },
  "postCreateCommand": "npm install",
  "forwardPorts": [3000, 5000],
  "remoteUser": "node",
  "mounts": [
    "source=node_modules-${devcontainerId},target=${containerWorkspaceFolder}/node_modules,type=volume",
    "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume"
  ]
}
```

**Step 3: Migrate Environment Variables**

If you have `.env` file:

```json
{
  "containerEnv": {
    "NODE_ENV": "development",
    "DATABASE_URL": "postgresql://postgres:postgres@localhost:5432/mydb"
  }
}
```

Or keep `.env` and add to `.gitignore`:
```bash
echo ".env" >> .gitignore
```

**Step 4: Test Migration**

```bash
# Commit changes
git add .devcontainer/
git commit -m "Add devcontainer configuration"

# Open in container
code .
# Click "Reopen in Container" when prompted
```

**Step 5: Verify**

Inside container:
```bash
node --version      # Should match devcontainer.json image
npm --version
ls node_modules/    # Should be populated after postCreateCommand
npm run dev         # Test your dev server
```

**Step 6: Clean Up Local Environment (Optional)**

```bash
# On host machine, remove local node_modules to save space
rm -rf node_modules
```

---

### Guide 2: Migrating Python Projects to Devcontainers

**Scenario**: Python project with `requirements.txt` or `pyproject.toml`, virtual environment, different Python versions on team.

**Step 1: Analyze Current Setup**

```bash
python --version                  # e.g., 3.10.x
ls -la | grep -E "requirements.txt|pyproject.toml|.venv|venv"
```

**Step 2: Create devcontainer.json**

**`.devcontainer/devcontainer.json`**:
```json
{
  "name": "${localWorkspaceFolderBasename}",
  "image": "python:3.11-slim",
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "ms-python.python",
        "ms-python.vscode-pylance",
        "charliermarsh.ruff"
      ],
      "settings": {
        "python.defaultInterpreterPath": "/usr/local/bin/python",
        "python.linting.enabled": true,
        "python.formatting.provider": "black"
      }
    }
  },
  "postCreateCommand": "pip install -r requirements.txt",
  "remoteUser": "vscode",
  "mounts": [
    "source=pip-cache-${devcontainerId},target=/home/vscode/.cache/pip,type=volume"
  ]
}
```

**Step 3: Add Dockerfile (if custom tools needed)**

**`.devcontainer/Dockerfile`**:
```dockerfile
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    build-essential \
    && apt-get clean

# Create non-root user
RUN useradd -m -s /bin/bash vscode
USER vscode

# Install Python tools globally
RUN pip install --user black pylint pytest ipykernel

WORKDIR /workspaces
```

Update devcontainer.json:
```json
{
  "build": {"dockerfile": "Dockerfile"},
  // ... rest of config
}
```

**Step 4: Test Migration**

```bash
git add .devcontainer/
git commit -m "Add Python devcontainer"
code .  # Reopen in Container
```

Inside container:
```bash
python --version
pip list
python -m pytest  # Run tests
```

**Step 5: Clean Up**

```bash
# Remove local virtual environment
rm -rf .venv venv __pycache__
```

---

### Guide 3: Migrating Docker Compose Projects

**Scenario**: Existing `docker-compose.yml` with app + database + Redis.

**Step 1: Review Existing docker-compose.yml**

```yaml
# Existing docker-compose.yml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/app
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/mydb

  db:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: postgres

  redis:
    image: redis:7
```

**Step 2: Create devcontainer.json**

**`.devcontainer/devcontainer.json`**:
```json
{
  "name": "${localWorkspaceFolderBasename}",
  "dockerComposeFile": "../docker-compose.yml",
  "service": "app",
  "workspaceFolder": "/app",
  "customizations": {
    "vscode": {
      "extensions": [
        "anthropic.claude-code",
        "ms-azuretools.vscode-docker"
      ]
    }
  },
  "forwardPorts": [3000, 5432, 6379],
  "postStartCommand": "docker-compose up -d db redis",
  "remoteUser": "node"
}
```

**Step 3: Update docker-compose.yml for devcontainers**

```yaml
version: '3.8'
services:
  app:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile
    volumes:
      - ..:/app:cached
    command: sleep infinity  # Keep container running
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/mydb
      REDIS_URL: redis://redis:6379

  db:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data

  redis:
    image: redis:7
    volumes:
      - redis-data:/data

volumes:
  postgres-data:
  redis-data:
```

**Step 4: Create Dockerfile**

**`.devcontainer/Dockerfile`**:
```dockerfile
FROM node:20

RUN apt-get update && apt-get install -y \
    git \
    postgresql-client \
    && apt-get clean

USER node
RUN npm install -g @anthropic-ai/claude-code

WORKDIR /app
```

**Step 5: Test**

```bash
code .  # Reopen in Container
```

Inside container:
```bash
# Verify services
docker-compose ps

# Test database connection
psql $DATABASE_URL -c "SELECT version();"

# Test Redis
redis-cli -h redis ping
```

---

### Guide 4: Team Adoption Strategy

**Scenario**: Migrating a team of 5-10 developers to devcontainers.

**Phase 1: Pilot (Week 1)**

1. **Select 1-2 volunteers** from team
2. **Create devcontainer** for main project
3. **Document issues** encountered
4. **Iterate** on configuration

**Phase 2: Documentation (Week 2)**

1. **Write team-specific README** in `.devcontainer/README.md`:
   ```markdown
   # Dev Container Setup

   ## Prerequisites
   - Docker Desktop 4.25+
   - VS Code 1.90+
   - Dev Containers extension

   ## First Time Setup
   1. Clone repo
   2. Open in VS Code
   3. Click "Reopen in Container"
   4. Wait 5-10 min for first build

   ## Troubleshooting
   [Link to common issues]
   ```

2. **Record screen demo** (5 min) showing:
   - Opening project in container
   - Running dev server
   - Making code changes
   - Rebuilding container

**Phase 3: Gradual Rollout (Week 3-4)**

1. **Present to team** (15 min demo + Q&A)
2. **Offer 1-on-1 setup help**
3. **Create Slack/Teams channel** for questions
4. **Make it optional initially** (local dev still works)

**Phase 4: Optimization (Month 2)**

1. **Create prebuild images** (speeds up first start from 10min ‚Üí 2min):
   ```bash
   devcontainer build --workspace-folder . \
     --push true \
     --image-name ghcr.io/yourorg/project-dev:latest
   ```

2. **Update devcontainer.json** to use prebuild:
   ```json
   {
     "image": "ghcr.io/yourorg/project-dev:latest"
   }
   ```

**Phase 5: Standardization (Month 3)**

1. **Create org-wide template** repository
2. **Establish best practices** doc
3. **Automate prebuild creation** via GitHub Actions
4. **Make devcontainers required** for new projects

**Success Metrics**:
- ‚úÖ Onboarding time: 2 hours ‚Üí 20 minutes
- ‚úÖ "Works on my machine" incidents: 80% reduction
- ‚úÖ Team satisfaction: survey after 1 month

---

### Sources

- **Migration Best Practices**: https://code.visualstudio.com/docs/devcontainers/containers#_converting-an-existing-project
- **Docker Compose Integration**: https://containers.dev/guide/docker-compose
- **Team Adoption Guide**: https://code.visualstudio.com/docs/devcontainers/devcontainerjson-reference

---

## Common Mistakes and Gotchas

### 1. Installing Tools as Root, Then Switching to Node User

**Mistake**:
```dockerfile
USER node
RUN apt-get install -y git  # ERROR: Permission denied
```

**Fix**: Install system packages as root, then switch to node:
```dockerfile
USER root
RUN apt-get install -y git
USER node
```

### 2. Not Persisting Volumes for AI Configurations

**Mistake**:
```json
{
  "mounts": []  // No volumes!
}
```

**Result**: API keys lost on every rebuild

**Fix**:
```json
{
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume"
  ]
}
```

### 3. Using `npm install` Instead of `npm ci` in Dockerfile

**Mistake**:
```dockerfile
RUN npm install  # Slower, non-deterministic
```

**Fix**:
```dockerfile
# For Dockerfile builds (deterministic, faster)
RUN npm ci

# For postCreateCommand (flexible, after container starts)
"postCreateCommand": "npm install"
```

### 4. Forgetting UTF-8 Locale Configuration

**Mistake**: Omitting locale setup ‚Üí AI tools get encoding errors

**Fix**: Always include:
```dockerfile
RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen && \
  locale-gen
ENV LANG=en_US.UTF-8 \
  LANGUAGE=en_US:en \
  LC_ALL=en_US.UTF-8
```

### 5. Codex CLI Landlock Sandbox Error in Docker Containers

**Problem**: When running `codex` commands, you see:
```
thread 'main' panicked at linux-sandbox/src/linux_run_main.rs:30:9:
error running landlock: Sandbox(LandlockRestrict)
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
```

**Root Cause**:
- Docker Desktop's LinuxKit kernel doesn't include **Landlock** support
- Landlock is a Linux security module (LSM) required by Codex's default sandbox
- LinuxKit uses a minimal kernel configuration for performance
- Known limitation of containerized environments

**Why This Happens**:
```bash
# Check if Landlock is available
cat /proc/sys/kernel/landlock/version
# => No such file or directory (not in LinuxKit kernel)

# Your kernel
uname -r
# => 6.10.14-linuxkit (minimal kernel config)
```

**Solution**: OpenAI's Official Recommendation

Disable Codex sandboxing in containers - Docker provides isolation instead.

**Configuration**: `~/.codex/config.toml`
```toml
sandbox_mode = "danger-full-access"
approval_policy = "never"
```

**Why This Is Safe**:
- ‚úÖ Docker container already provides process isolation
- ‚úÖ Network firewall restricts outbound connections (init-firewall.sh)
- ‚úÖ Container runs as non-root user (node)
- ‚úÖ Limited Linux capabilities (NET_ADMIN, NET_RAW, SETUID, SETGID only)
- ‚úÖ OpenAI officially recommends this for Docker environments

**Verification**:
```bash
# Test Codex works
codex --version
# => codex-cli 0.50.0

# Test command execution
codex exec "echo 'Hello from Codex'"
# => Should execute successfully without sandbox errors

# Verify config
cat ~/.codex/config.toml | grep sandbox_mode
# => sandbox_mode = "danger-full-access"
```

**Devcontainer Auto-Configuration**:

This repository's devcontainer automatically applies this fix:
- **Template**: `config.toml.template` in `.devcontainer/`
- **Init script**: `init-codex-config.sh` copies template on startup
- **Persistence**: Configuration survives rebuilds via volume: `codex-config-${devcontainerId}`

**Manual Fix** (if needed):
```bash
# Create config directory
mkdir -p ~/.codex

# Create config file
cat > ~/.codex/config.toml <<EOF
model = "gpt-5"
model_reasoning_effort = "medium"
sandbox_mode = "danger-full-access"
approval_policy = "never"
EOF
```

**References**:
- [OpenAI Codex Sandbox Documentation](https://github.com/openai/codex/blob/main/docs/sandbox.md)
- [GitHub Issue: Unable to skip sandboxing #973](https://github.com/openai/codex/issues/973)
- [Docker + Codex discussion](https://github.com/Diatonic-AI/codex-cli-docker-mcp)

**Alternative Solutions** (not recommended):
- ‚ùå Adding `SYS_ADMIN` capability doesn't help (kernel doesn't support Landlock)
- ‚ùå Environment variable `CODEX_UNSAFE_ALLOW_NO_SANDBOX` has limited support
- ‚ùå Switching to different Linux kernel (breaks Docker Desktop compatibility)

**Best Practice**: Trust your container's isolation layer, disable Codex's redundant sandboxing.

**‚ö†Ô∏è Known Limitation: VSCode Extension**

**IMPORTANT**: The above configuration **only works for Codex CLI**, not the VSCode extension.

**VSCode Extension Issue**:
- ‚ùå VSCode extension does NOT read `sandbox_mode` or `approval_policy` from config.toml
- ‚ùå Extension only reads `model` and `model_reasoning_effort` settings
- ‚ùå Extension always tries to use Landlock sandboxing (fails in Docker)
- üìã Tracked as [GitHub Issue #5041](https://github.com/openai/codex/issues/5041)

**OpenAI Team Response** (from issue #5041):
> "Currently we actually do not read or write our `network_access` and `sandbox_mode` to config.toml but only the `model` and `model_reasoning_effort` settings. We are currently working on a custom mode which will allow you to use approval and sandbox policy from config.toml."

**Workaround**:
- ‚úÖ Use **Codex CLI** instead of VSCode extension: `codex exec "your prompt"`
- ‚úÖ CLI fully respects config.toml and works perfectly in Docker
- ‚è≥ Wait for OpenAI to implement config.toml support in extension (no ETA)

**Why VSCode Extension Fails**:
```
User runs command in VSCode extension
  ‚Üì
Extension starts: codex app-server (without sandbox flags)
  ‚Üì
app-server tries to use Landlock sandbox (ignores config.toml)
  ‚Üì
Landlock not available in LinuxKit kernel
  ‚Üì
Error: Sandbox(LandlockRestrict)
```

**Why CLI Works**:
```
User runs: codex exec "prompt"
  ‚Üì
CLI reads ~/.codex/config.toml
  ‚Üì
Uses sandbox_mode = "danger-full-access"
  ‚Üì
No Landlock required
  ‚Üì
‚úÖ Command executes successfully
```

**Status**: This is a known limitation with no official workaround. Use the CLI until OpenAI adds config.toml support to the extension.

### 6. Hardcoding Absolute Paths in devcontainer.json

**Mistake**:
```json
{
  "workspaceFolder": "/workspaces/my-project"  // Breaks if project renamed
}
```

**Fix**:
```json
{
  "workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}"  // Dynamic
}
```

### 6. Not Ignoring `.claude/settings.local.json` in Git

**Mistake**: Committing API keys to git

**Fix**: Always configure in Dockerfile:
```dockerfile
RUN git config --global core.excludesfile ~/.gitignore_global && \
  echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

### 7. Using Bind Mounts for Credentials

**Mistake**:
```json
{
  "mounts": [
    "source=${localEnv:HOME}/.claude,target=/home/node/.claude,type=bind"
  ]
}
```

**Problem**: Host credentials leak into container (security risk)

**Fix**: Use named volumes (isolated per container):
```json
{
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume"
  ]
}
```

### 8. Running `docker system prune -a --volumes` Without Thinking

**Mistake**: Deleting ALL volumes (loses all API keys)

**Fix**: Selectively remove:
```bash
docker volume ls | grep "project-name"
docker volume rm <specific-volume>
```

### 9. Not Testing Dockerfile Independently

**Mistake**: Only testing via VS Code (slow iteration)

**Fix**: Test Dockerfile directly:
```bash
cd .devcontainer
docker build -t test .
docker run -it test /bin/bash
```

### 10. Using Windows Paths in WSL2 Devcontainers

**Mistake**:
```bash
# Slow! Project in /mnt/c/Users/...
```

**Fix**: Clone projects into WSL2 filesystem:
```bash
cd ~  # /home/user (fast)
git clone ...
```

### 11. Adding `--security-opt=no-new-privileges` Without Testing sudo

**Mistake** (October 2025 field finding):
```json
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_ADMIN",
    "--security-opt=no-new-privileges"  // Breaks sudo!
  ],
  "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"
}
```

**Error**:
```bash
sudo: The "no new privileges" flag is set, which prevents sudo from running as root.
[215179 ms] postStartCommand from devcontainer.json failed with exit code 1.
```

**Why it breaks**:
- The `--security-opt=no-new-privileges` flag prevents ALL privilege escalation
- This includes `sudo` (which needs to escalate from user to root)
- Any lifecycle hooks using `sudo` will fail silently
- Container appears to start but initialization scripts don't run

**Real-world impact**:
- Firewall configuration fails (no network restrictions applied)
- MCP server setup doesn't complete
- Database initialization skipped
- Devcontainer unusable despite successful build

**Fix**:

**Option 1: Remove the flag** (recommended if you need sudo):
```json
{
  "runArgs": [
    "--cap-drop=ALL",
    "--cap-add=NET_ADMIN",
    "--cap-add=NET_RAW",
    "--cap-add=SETUID",  // Required for sudo
    "--cap-add=SETGID"   // Required for sudo
    // no-new-privileges removed
  ]
}
```

**Option 2: Move root operations to build-time**:
```dockerfile
# Dockerfile - do everything requiring root at build time
RUN /usr/local/bin/init-firewall.sh && \
    iptables-save > /etc/iptables/rules.v4

# devcontainer.json - restore without sudo
{
  "postStartCommand": "iptables-restore < /etc/iptables/rules.v4"
}
```

**Lesson**: Don't blindly apply security hardening flags from generic Docker guides without testing with your specific devcontainer use case.

### 12. Not Upgrading npm in Dockerfile

**Mistake**:
```dockerfile
FROM node:20
# Assumes npm is latest (it's not!)
RUN npm install -g @anthropic-ai/claude-code@latest
```

**Problem**:
- `node:20` ships with npm from its build date (e.g., npm 10.8.2)
- Latest npm might be 10.9.2+ with bug fixes and security patches
- `apt-get update` won't upgrade npm (it's not an apt package)

**Real-world notification**:
```bash
npm notice New patch version of npm available! 10.8.2 -> 10.9.2
npm notice Run `npm install -g npm@10.9.2` to update!
```

**Fix**:
```dockerfile
FROM node:20

ARG CLAUDE_CODE_VERSION=latest

# ALWAYS upgrade npm first
RUN npm install -g npm@latest

# Then install other global packages
RUN npm install -g @anthropic-ai/claude-code@${CLAUDE_CODE_VERSION}
```

**Why it matters**:
- Security vulnerabilities patched in newer npm versions
- Performance improvements (faster installs, better caching)
- Bug fixes for obscure edge cases
- Takes 10 seconds during build, saves hours of debugging later

### 13. Not Using BuildKit Cache Mounts (Slow Rebuilds)

**Mistake**:
```dockerfile
# Redownloads 500MB+ of packages on EVERY rebuild
RUN apt-get update && apt-get install -y \
    chromium \
    build-essential \
    git
```

**Result**:
- First build: 10 minutes
- Rebuild after changing ONE line: 10 minutes (redownloads everything)
- Team members frustrated by slow iteration

**Fix**:
```dockerfile
# Caches packages, only downloads new/changed ones
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
    apt-get update && apt-get install -y \
    chromium \
    build-essential \
    git \
    && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**Performance improvement**:
- First build: 10 minutes (same)
- Subsequent rebuilds: 2 minutes (5x faster!)
- Over 10 rebuilds: Saves 80 minutes

**When you notice this**:
- Frequent Dockerfile changes (debugging, adding tools)
- Team complaining about slow devcontainer builds
- Seeing "Downloading..." repeatedly for same packages

### 14. Missing `"init": true` for Process Management

**Mistake**:
```json
{
  "name": "My Devcontainer",
  "build": {"dockerfile": "Dockerfile"}
  // Missing init process manager
}
```

**Symptoms**:
- Zombie processes accumulate (`<defunct>` in `ps aux`)
- Signals not properly forwarded (Ctrl+C doesn't work as expected)
- Background processes don't clean up
- Container shutdown takes longer than expected

**Fix**:
```json
{
  "name": "My Devcontainer",
  "init": true,  // Enables tini process manager
  "build": {"dockerfile": "Dockerfile"}
}
```

**What `"init": true` does**:
- Adds `tini` or similar init process as PID 1
- Properly reaps zombie processes
- Forwards signals correctly (SIGTERM, SIGINT)
- Ensures clean container shutdown

**Verification**:
```bash
# Inside container with init: true
ps aux | head -2
# Should see: tini or /bin/sh or node as PID 1 (not your app directly)

# Without init: true
ps aux | head -2
# Might see: your app as PID 1 (problematic)
```

**When to ALWAYS use**:
- ‚úÖ Containers running long-lived processes
- ‚úÖ Containers with background jobs
- ‚úÖ Devcontainers where you run tests frequently
- ‚úÖ Production-like development environments

**Modern devcontainer best practice**: Always include `"init": true` unless you have a specific reason not to.

---

## Quick Reference

### Essential Commands

```bash
# Open project in devcontainer
code /path/to/project

# Rebuild container
# Command Palette ‚Üí "Dev Containers: Rebuild Container"

# List running containers
docker ps

# View container logs
docker logs <container-id>

# Execute command in container
docker exec -it <container-id> bash

# Clean up Docker resources
docker system prune  # Safe (removes stopped containers, unused images)
docker system prune -a --volumes  # Nuclear (removes EVERYTHING)
```

### File Checklist

- [ ] `.devcontainer/devcontainer.json` (required)
- [ ] `.devcontainer/Dockerfile` (required)
- [ ] `.devcontainer/init-claude-config.sh` (optional, MCP automation)
- [ ] `.devcontainer/mcp.json.template` (optional, MCP servers)
- [ ] `.devcontainer/settings.json.template` (optional, Claude settings)
- [ ] `.devcontainer/init-firewall.sh` (optional, security)

### Minimal Working Example

**devcontainer.json**:
```json
{
  "name": "Claude Code",
  "build": {"dockerfile": "Dockerfile"},
  "customizations": {
    "vscode": {"extensions": ["anthropic.claude-code"]}
  },
  "remoteUser": "node",
  "mounts": ["source=claude-${devcontainerId},target=/home/node/.claude,type=volume"]
}
```

**Dockerfile**:
```dockerfile
FROM node:20
RUN apt-get update && apt-get install -y git && apt-get clean
USER node
RUN npm install -g @anthropic-ai/claude-code@latest
RUN git config --global core.excludesfile ~/.gitignore_global && \
  echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

### Official Resources

- **Claude Code Devcontainers**: https://docs.claude.com/en/docs/claude-code/devcontainer
- **VS Code Devcontainers**: https://code.visualstudio.com/docs/devcontainers/containers
- **Docker Documentation**: https://docs.docker.com/
- **MCP Protocol**: https://modelcontextprotocol.io
- **Dev Containers Spec**: https://containers.dev/

---

## Multi-Container Patterns (Docker Compose)

For complex setups (app + database + cache), use Docker Compose with devcontainers.

**Official Docker Compose Documentation**: https://docs.docker.com/compose/compose-file/
**Dev Container Compose Spec**: https://containers.dev/implementors/json_reference/#compose-specific

### Example: Next.js + PostgreSQL + Redis

**Create `docker-compose.yml` (in project root)**:

```yaml
version: '3.8'
services:
  app:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    volumes:
      - .:/workspaces/my-app:cached
    command: sleep infinity
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/myapp
      REDIS_URL: redis://redis:6379
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: myapp
    volumes:
      - postgres-data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data

volumes:
  postgres-data:
  redis-data:
```

**Update devcontainer.json**:

```json
{
  "name": "Next.js Full Stack",
  "dockerComposeFile": "../docker-compose.yml",
  "service": "app",
  "workspaceFolder": "/workspaces/my-app",
  "customizations": {
    "vscode": {
      "extensions": ["anthropic.claude-code"]
    }
  },
  "forwardPorts": [3000, 5432, 6379],
  "postStartCommand": "npm install",
  "remoteUser": "node"
}
```

**Key Points**:
- `dockerComposeFile`: Points to docker-compose.yml
- `service`: Which service is the "dev" container (where VS Code connects)
- Services can communicate by service name (`db:5432`, `redis:6379`)
- Separate volumes for databases persist data across restarts

### Testing Multi-Container Setup

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs app
docker-compose logs db

# Connect to database from app container
docker-compose exec app psql $DATABASE_URL

# Stop all services
docker-compose down

# Stop and remove volumes (deletes database data!)
docker-compose down -v
```

---

## DevContainer Features

VS Code devcontainers support a powerful "Features" system for installing common tools without modifying the Dockerfile.

### What Are Features?

**Features** are self-contained, reusable units that install tools and configure the environment. Think of them as "npm packages" for devcontainers.

**Official Feature Registry**: https://containers.dev/features
**Features Specification**: https://containers.dev/implementors/features/
**Features Distribution**: https://containers.dev/implementors/features-distribution/

### Common Features

#### Git

```json
{
  "features": {
    "ghcr.io/devcontainers/features/git:1": {
      "version": "latest",
      "ppa": true
    }
  }
}
```

#### Docker-in-Docker

```json
{
  "features": {
    "ghcr.io/devcontainers/features/docker-in-docker:2": {
      "version": "latest",
      "moby": true
    }
  }
}
```

#### Node.js (Additional Versions)

```json
{
  "features": {
    "ghcr.io/devcontainers/features/node:1": {
      "version": "18"
    }
  }
}
```

#### Python

```json
{
  "features": {
    "ghcr.io/devcontainers/features/python:1": {
      "version": "3.11"
    }
  }
}
```

#### AWS CLI

```json
{
  "features": {
    "ghcr.io/devcontainers/features/aws-cli:1": {
      "version": "latest"
    }
  }
}
```

### Example: Multi-Tool Setup

```json
{
  "name": "Full-Stack Dev",
  "image": "mcr.microsoft.com/devcontainers/base:ubuntu",
  "features": {
    "ghcr.io/devcontainers/features/node:1": {"version": "20"},
    "ghcr.io/devcontainers/features/python:1": {"version": "3.11"},
    "ghcr.io/devcontainers/features/docker-in-docker:2": {},
    "ghcr.io/devcontainers/features/kubectl-helm-minikube:1": {},
    "ghcr.io/devcontainers/features/github-cli:1": {}
  }
}
```

### Features vs. Dockerfile

| Aspect | Features | Dockerfile |
|--------|----------|------------|
| **Ease of use** | Simple JSON | Requires Docker knowledge |
| **Reusability** | Shared across projects | Project-specific |
| **Customization** | Limited to feature options | Full control |
| **Build time** | Often cached | Depends on layer caching |
| **Best for** | Common tools | Custom setups |

### When to Use Features

‚úÖ **Use Features when:**
- Installing common tools (Git, Docker, AWS CLI, kubectl)
- Sharing configuration across multiple projects
- Want simpler devcontainer.json without Dockerfile

‚ùå **Use Dockerfile when:**
- Installing custom/proprietary tools
- Need fine-grained control over installation
- Complex multi-step setup required

### Creating Custom Features

You can create custom features for internal tools:

**Example structure**:
```
my-feature/
‚îú‚îÄ‚îÄ devcontainer-feature.json
‚îî‚îÄ‚îÄ install.sh
```

**devcontainer-feature.json**:
```json
{
  "id": "my-custom-tool",
  "version": "1.0.0",
  "name": "My Custom Tool",
  "description": "Installs my custom tool",
  "options": {
    "version": {
      "type": "string",
      "default": "latest"
    }
  }
}
```

**install.sh**:
```bash
#!/bin/bash
set -e

VERSION=${VERSION:-"latest"}
echo "Installing My Custom Tool ${VERSION}..."
# Installation commands here
```

Host in a git repo and reference:
```json
{
  "features": {
    "https://github.com/myorg/devcontainer-features/my-custom-tool": {
      "version": "1.0.0"
    }
  }
}
```

---

## Frequently Asked Questions

### General Questions

**Q: Do I need to rebuild the container every time I change my code?**

No! Your code lives in a volume mount. Only rebuild when:
- Changing `.devcontainer/devcontainer.json`
- Changing `.devcontainer/Dockerfile`
- Adding VS Code extensions
- Installing new system packages

**Q: Can I run devcontainers without VS Code?**

Technically yes (using Dev Container CLI), but VS Code integration is the primary use case. For non-VS Code workflows, consider:
- Docker Compose directly
- GitHub Codespaces
- Docker-based CI/CD

**Q: How much disk space do devcontainers use?**

Typical usage:
- Base container: 500MB-2GB
- Per-project volumes: 50-200MB
- Total for 10 projects: ~5-10GB

Monitor with: `docker system df`

**Q: Can I use devcontainers with GitHub Codespaces?**

Yes! GitHub Codespaces uses the exact same `.devcontainer/` configuration. Your devcontainer works locally and in Codespaces without modification.

**Q: What happens to my data if I delete the container?**

- **Named volumes** (claude-${devcontainerId}): Persist until manually deleted
- **Bind mounts**: Data remains on host
- **Container filesystem**: Deleted with container

Always use volumes for API keys and configs!

**Q: Can I have multiple devcontainers in one project?**

Yes! Create multiple devcontainer.json files:

```
.devcontainer/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json
‚îî‚îÄ‚îÄ devcontainer.json  # Default
```

Open with: Command Palette ‚Üí "Dev Containers: Open Folder in Container" ‚Üí Select configuration

### Performance Questions

**Q: Why is my devcontainer slow on Mac/Windows?**

File I/O between host and container has overhead on Mac/Windows (not Linux).

**Solutions**:
- Use named volumes instead of bind mounts for dependencies (`node_modules/`, `.venv/`)
- Enable VirtioFS (Mac: Docker Desktop ‚Üí Experimental Features)
- Store projects in WSL2 filesystem (Windows)

**Q: How can I speed up container builds?**

```dockerfile
# 1. Order layers by change frequency (least ‚Üí most)
FROM node:20
RUN apt-get update && apt-get install -y git  # Rarely changes
COPY package*.json ./                         # Changes sometimes
RUN npm install                                # Changes when package*.json changes
COPY . .                                       # Changes often

# 2. Use build cache
# Command Palette ‚Üí "Dev Containers: Rebuild Container" (NOT "Rebuild Without Cache")

# 3. Minimize layers
RUN apt-get update && apt-get install -y \
  git \
  curl \
  && apt-get clean && rm -rf /var/lib/apt/lists/*  # All in one layer
```

**Q: My container uses too much RAM. How do I limit it?**

```json
{
  "runArgs": [
    "--memory=4g",
    "--memory-swap=4g"
  ]
}
```

### Security Questions

**Q: Is it safe to use --dangerously-skip-permissions?**

**Only in trusted environments**:
- ‚úÖ Your own projects in isolated devcontainers with firewall
- ‚úÖ CI/CD pipelines with restricted network
- ‚ùå Open-source projects you didn't audit
- ‚ùå Untrusted codebases

The flag bypasses permission prompts, allowing automated execution. Malicious code could exfiltrate your API keys.

**Q: How do I prevent accidentally committing API keys?**

```dockerfile
# In Dockerfile (automatic protection)
RUN git config --global core.excludesfile ~/.gitignore_global && \
  echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

This ensures `.claude/settings.local.json` (which contains API keys) never gets committed.

**Q: Can containers access my host machine?**

Not by default. Containers are isolated unless you explicitly:
- Bind mount host directories (`type=bind`)
- Forward ports
- Add capabilities (`--cap-add`)

Best practice: Only mount what's needed, preferably read-only.

### Multi-AI Questions

**Q: Can I run Claude Code, Copilot, and Gemini in the same container?**

Yes! Install all tools and configure separate volumes:

```dockerfile
RUN npm install -g \
  @anthropic-ai/claude-code@latest \
  @openai/codex \
  @google/gemini-cli
```

```json
{
  "mounts": [
    "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
    "source=codex-${devcontainerId},target=/home/node/.codex,type=volume",
    "source=gemini-${devcontainerId},target=/home/node/.gemini,type=volume"
  ]
}
```

Each AI gets isolated API keys and settings.

**Q: How do I switch between AI assistants?**

Each has its own CLI command:
```bash
claude     # Anthropic Claude Code
codex      # OpenAI Codex
gemini     # Google Gemini CLI
```

Or use VS Code extensions (switch via sidebar).

### Troubleshooting Questions

**Q: "Reopen in Container" button disappeared after I clicked it once. How do I get back?**

The green icon in bottom-left corner of VS Code. Click it ‚Üí "Reopen in Container"

Or: Command Palette ‚Üí "Dev Containers: Reopen in Container"

**Q: How do I access my container if VS Code won't connect?**

```bash
# Find container ID
docker ps

# Execute bash inside
docker exec -it <container-id> bash

# Now you can debug from inside
claude --version
ls -la ~/.claude
cat ~/.claude/mcp.json | jq
```

**Q: My Dockerfile builds locally but fails in VS Code. Why?**

VS Code builds from the project root, not `.devcontainer/` directory.

**Fix paths in Dockerfile**:
```dockerfile
# If devcontainer.json has "dockerfile": "Dockerfile"
# Then COPY paths are relative to .devcontainer/

# Good
COPY init-firewall.sh /usr/local/bin/

# Bad
COPY .devcontainer/init-firewall.sh /usr/local/bin/
```

**Q: How do I completely reset a devcontainer?**

```bash
# 1. Remove container
docker ps -a | grep "project-name"
docker rm -f <container-id>

# 2. Remove volumes (CAUTION: Deletes API keys!)
docker volume ls | grep "project-name"
docker volume rm <volume-name>

# 3. Rebuild
# Command Palette ‚Üí "Dev Containers: Rebuild Container Without Cache"
```

### MCP Questions

**Q: What's the difference between SSE and stdio MCP servers?**

**SSE (Server-Sent Events)**:
- Remote servers (hosted externally)
- Examples: Context7, Cloudflare Docs
- Requires internet
- No local installation

**stdio (Standard Input/Output)**:
- Local processes (npm packages)
- Examples: Chrome DevTools
- Works offline
- Requires npm installation

**Q: Can I use MCP servers without Claude Code?**

MCP is specific to Claude Code. Other AI assistants have their own extension systems:
- Copilot: GitHub Copilot API
- Cursor: Cursor Rules
- Codex: OpenAI Plugins

**Q: My MCP server shows "not responding". What should I check?**

```bash
# For SSE servers
curl -v https://mcp.context7.com/sse  # Should respond

# For stdio servers
npx chrome-devtools-mcp@latest --help  # Should run

# Check mcp.json syntax
cat ~/.claude/mcp.json | jq  # Should parse without errors

# View Claude logs
claude --verbose
```

---

## Glossary

**API Keys**: Secret tokens for authenticating with AI services (Anthropic, OpenAI, Google).

**Bind Mount**: Direct mapping of host directory to container directory. Changes on either side reflect immediately.

**Container**: Isolated environment running on Docker Engine. Contains OS, tools, and your project.

**Container ID**: Unique identifier for a running container (e.g., `a1b2c3d4e5f6`).

**Dev Container Extension**: VS Code extension (`ms-vscode-remote.remote-containers`) enabling devcontainer support.

**DevContainer Features**: Pre-packaged installations for common tools (Git, Docker, AWS CLI, etc.).

**Docker Compose**: Tool for defining multi-container setups (app + database + cache).

**Docker Desktop**: Docker runtime for Mac/Windows with GUI. Linux uses Docker Engine directly.

**Docker Engine**: The underlying runtime that executes containers.

**Docker Image**: Blueprint for creating containers. Built from Dockerfile.

**Dockerfile**: Text file with instructions for building a Docker image.

**devcontainer.json**: Configuration file telling VS Code how to create and connect to containers.

**Environment Variable**: Key-value pair available to processes in the container (e.g., `CLAUDE_CONFIG_DIR=/home/node/.claude`).

**Extension**: VS Code add-on providing additional functionality (e.g., Claude Code extension).

**Firewall**: Network security rules restricting container's outbound connections.

**Forward Port**: Make container port accessible on host (e.g., container port 3000 ‚Üí localhost:3000).

**Git-Delta**: Enhanced diff viewer with syntax highlighting (optional tool).

**Host**: Your physical/virtual machine (Mac, Windows, Linux) running Docker.

**Image Layer**: Cached build step in Dockerfile. Speeds up rebuilds.

**iptables**: Linux firewall configuration tool.

**MCP (Model Context Protocol)**: Standard for extending Claude Code with external data/tools.

**Mount**: Connection between host and container filesystem (volume or bind mount).

**Named Volume**: Docker-managed storage that persists across container rebuilds.

**npm Global**: npm packages installed system-wide (with `-g` flag).

**Oh My Zsh**: Popular ZSH configuration framework with themes and plugins.

**OTel (OpenTelemetry)**: Observability framework for metrics, logs, and traces (optional, advanced).

**postStartCommand**: Command executed after container starts (in devcontainer.json).

**Remote User**: User account inside container that VS Code uses (typically `node` or `vscode`).

**runArgs**: Docker CLI arguments passed when starting container (in devcontainer.json).

**SSE (Server-Sent Events)**: HTTP-based protocol for server‚Üíclient streaming. Used by remote MCP servers.

**stdio (Standard Input/Output)**: Process communication method. Used by local MCP servers.

**Volume**: Persistent storage managed by Docker. Survives container deletion.

**VS Code Server**: Background service VS Code installs in container for remote connection.

**Workspace Folder**: Directory inside container where your project code appears (`/workspaces/your-project`).

**WSL2 (Windows Subsystem for Linux 2)**: Linux kernel running on Windows. Required for Docker Desktop on Windows.

**ZSH (Z Shell)**: Advanced shell with better autocomplete and themes than Bash.

---

## Anecdotal Notes & Field Reports

> **Community Wisdom**: Real-world issues, gotchas, and solutions discovered by practitioners. This section documents practical knowledge from the field, complete with source citations for verification.

### Claude Code Specific Issues

**MCP stdio Connection Limitations Across Containers**
- When Claude Code runs inside a container, it cannot establish stdio connections to MCP servers running in other containers or on the host - this is a fundamental limitation of how process-to-process stdio communication works across container boundaries
- Use Streamable HTTP transport instead for cross-container MCP server communication
- **Source**: [Building a Secure AI Development Environment - Medium](https://medium.com/@brett_4870/building-a-secure-ai-development-environment-containerized-claude-code-mcp-integration-e2129fe3af5a)

**IDE Diagnostics Availability When Containerized**
- Claude's IDE integration features don't work out of the box when running inside a devcontainer, meaning you lose easy access to IDE diagnostics, the ability to see currently open files, and selected line ranges
- Claude operates purely through the terminal interface in this setup
- **Source**: [Switching to Claude Code + VSCode inside Docker](https://timsh.org/claude-inside-docker/)

**Credential Security with --dangerously-skip-permissions**
- When executed with `--dangerously-skip-permissions`, devcontainers do not prevent malicious projects from exfiltrating anything accessible in the devcontainer including Claude Code credentials
- Only use this flag in trusted environments you control
- **Source**: [From Clicking Yes to Letting Claude Run Wild (Safely)](https://blog.herlein.com/post/claude-code/)

**Volume Mounting Strategies for .claude Folder**
- You can mount your local `.claude` folder into your dev container so Claude can keep and reuse its memory using a bind mount in devcontainer.json
- This preserves Claude's context and configuration across container rebuilds
- **Source**: [Running Claude Code inside dev containers - DEV Community](https://dev.to/sbotto/running-claude-code-inside-your-dev-containers-36e7)

**Network Isolation Recommendations**
- Claude Code is given full control of the host's network stack if you run the container with `--network=host` - never use this flag
- Use Docker's default bridge network instead for proper isolation
- **Source**: [Running Claude Code Safely in Devcontainers](https://www.solberg.is/claude-devcontainer)

**Complete Environment Fidelity**
- Containerized Claude Code ensures complete environment fidelity - Claude experiences the exact same Python interpreter, installed packages, environment variables, and tool versions that your code will use in development and production
- This eliminates "it works on my machine but not in production" issues
- **Source**: [Building a Secure AI Development Environment - Medium](https://medium.com/@brett_4870/building-a-secure-ai-development-environment-containerized-claude-code-mcp-integration-e2129fe3af5a)

**Anthropic's Preconfigured Containerized Option**
- Anthropic provides running Claude Code inside the development container as a preconfigured option for improved security and isolation, recommended for trusted repositories
- This approach ensures Claude experiences the exact same environment as your code, eliminating environment-related issues
- **Source**: [Development containers - Claude Docs](https://docs.claude.com/en/docs/claude-code/devcontainer)

---

### Performance Optimization

**macOS VirtioFS Performance Improvements (2025 Data)**
- VirtioFS performance has improved significantly - bind mounts are now only 3x slower than native operations instead of the 5-6x slowdown from two years ago
- Docker Desktop 4.6 (March 2022) introduced VirtioFS with up to **98% performance improvements**: 90% faster MySQL imports, 87% faster composer install, 80% faster app boot times
- Docker's **file synchronization feature** (paid subscription, 2025) provides an additional 59% performance improvement over standard VirtioFS
- Docker Desktop 4.33 introduced further VirtioFS fine-tuning including increased directory cache timeout and optimized host change notifications
- **Sources**:
  - [Docker on MacOS is still slow? - Paolo Mainardi](https://www.paolomainardi.com/posts/docker-performance-macos-2025/)
  - [Speed boost achievement unlocked on Docker Desktop 4.6 for Mac](https://www.docker.com/blog/speed-boost-achievement-unlocked-on-docker-desktop-4-6-for-mac/)
  - [What Are the Latest Docker Desktop Performance Optimizations](https://www.docker.com/blog/what-are-the-latest-docker-desktop-enterprise-grade-performance-optimizations/)

**WSL2 Filesystem Location is Critical**
- When files are on your Windows drive (`/mnt/c/Users/<yourusername>/repos`), Docker has to rely on less efficient network protocols, slowing things down significantly
- `/mnt/c` is actually a mountpoint exposing Windows files through a Plan9 file share, which creates a major bottleneck
- Moving files from `/mnt/c` to the WSL filesystem can result in dramatic performance improvements for page loads and Docker operations
- **Solution**: Keep project files in the WSL filesystem (e.g., `/home/<yourusername>/repos`)
- **Source**: [Containers and the WSL2 File System - Ken Muse](https://www.kenmuse.com/blog/containers-and-wsl2-filesystem/)

**Docker Layer Caching Strategies**
- When building with Docker, a layer is reused from the build cache if the instruction and the files it depends on haven't changed since it was previously built
- Order instructions strategically: expensive steps near the beginning, frequently changing steps near the end
- Separate dependency installation (package.json, requirements.txt) from source code copying to maximize cache hits
- **Sources**:
  - [Optimize cache usage in builds - Docker Docs](https://docs.docker.com/build/cache/optimize/)
  - [Docker Layer Caching Explained - The Nanjay Blog](https://blog.thenanjay.com/docker-layer-caching-explained-tips-to-improve-build-times)

**.dockerignore Impact on Build Speed**
- When `node_modules` contains hundreds of megabytes, it significantly slows down the build process
- By adding `node_modules` to `.dockerignore`, you reduce the size of the build context drastically, speeding up the build
- Without `node_modules` in `.dockerignore`, the docker build process slows down due to unnecessary copying and the image becomes larger
- **Sources**:
  - [Mastering the .dockerignore File - Medium](https://medium.com/@bounouh.fedi/mastering-the-dockerignore-file-boosting-docker-build-efficiency-398719f4a0e1)
  - [Effective .dockerignore Patterns - Support Tools](https://support.tools/effective-dockerignore-patterns/)

**Named Volumes vs Bind Mounts for Dependencies**
- Mount the `node_modules` sub-folder into a named local volume instead of using bind mounts to significantly improve performance on macOS and Windows
- Use `workspaceMount` property in devcontainer.json to tell VS Code where to bind your source code
- **Sources**:
  - [Improve disk performance - VS Code Docs](https://code.visualstudio.com/remote/advancedcontainers/improve-performance)
  - [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**Multi-Stage Builds for Dependency Caching**
- Multi-stage builds can separate dependency installation into its own stage, which can be cached and reused even when the source code changes
- This prevents re-downloading dependencies on every source code change
- **Source**: [Docker Layer Caching Reference](https://dockerbuild.com/reference/layer-caching)

**BuildKit Parallelization**
- BuildKit supports layer reuse across environments, parallel builds, and external caching ‚Äì all of which make CI/CD pipelines faster and cheaper
- Enable BuildKit with `DOCKER_BUILDKIT=1` environment variable
- **Source**: [Docker Layer Caching: Speed Up CI/CD Builds - Bunnyshell](https://www.bunnyshell.com/blog/docker-layer-caching-speed-up-cicd-builds/)

**Feature Caching Management**
- Manage your own resource cache as part of the Feature to improve performance during container initialization
- Each feature may have an initial build+attach cost per associated Codespace, but subsequent rebuilds will use the cache
- **Source**: [Improving Dev Container Feature Performance - Ken Muse](https://www.kenmuse.com/blog/improving-dev-container-feature-performance/)

**Resource Allocation Optimization**
- Go to Docker Desktop ‚Üí Settings ‚Üí Advanced to increase CPU, Memory, or Swap
- You can use `runArgs` in devcontainer.json with Docker run CLI options to configure container resources
- **Source**: [How Do I Increase the CPU & RAM in a VSCode DevContainer - Stack Overflow](https://stackoverflow.com/questions/71773785/how-do-i-increase-the-cpu-ram-in-a-vscode-devcontainer)

**Clone Repository in Container Volume**
- You can clone your entire source tree inside of a named volume rather than locally, which can significantly improve performance on macOS and Windows
- This avoids cross-OS filesystem penalties
- **Source**: [Improve disk performance - VS Code Docs](https://code.visualstudio.com/remote/advancedcontainers/improve-performance)

---

### Security Best Practices

**Non-Root User Importance and Implementation**
- Docker containers typically run with root privileges by default, which is useful for development but can expose you to high risk in production environments
- Running containers as the root user may provide a path for privilege escalation, allowing attackers to gain control of the underlying host system
- **Solution**: Specify a non-root user in the Dockerfile using `RUN addgroup -S appgroup && adduser -S appuser -G appgroup` followed by `USER appuser`
- **Sources**:
  - [Container Security Best Practices: Avoid Running Containers as Root - Medium](https://medium.com/@amandubey_6607/container-security-best-practices-avoid-running-containers-as-root-ae37fee2846f)
  - [Securing Docker: Non-Root User Best Practices - Medium](https://medium.com/@Kfir-G/securing-docker-non-root-user-best-practices-5784ac25e755)

**Linux Capabilities Management**
- Docker containers should only have the minimum set of capabilities required for their functionality
- Drop unnecessary Linux capabilities using `docker run --cap-drop=ALL --cap-add=NET_ADMIN`
- By default, Docker containers inherit a set of capabilities from the host; to enhance security, drop all default capabilities explicitly and add only required ones
- **Source**: [Docker Security Best Practices - DEV Community](https://dev.to/ajeetraina/docker-security-best-practices-safeguarding-containers-with-privileges-capabilities-and-resource-management-2dk1)

**Workspace Trust Feature Implications**
- The Workspace Trust feature lets you decide whether code in your project folder can be executed by VS Code and extensions without your explicit approval
- Some workflows such as connecting to GitHub Codespace or attaching to a running Docker container are automatically trusted
- **Important**: Workspace Trust can't prevent a malicious extension from executing code and ignoring Restricted Mode
- **Sources**:
  - [Workspace Trust - VS Code Docs](https://code.visualstudio.com/docs/editing/workspaces/workspace-trust)
  - [Dev Containers - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/containers)

**Read-Only Volume Mounts**
- Use read-only mounts for SSH keys and other sensitive files: `source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly`
- This prevents accidental or malicious modification of host files from the container
- **Source**: [Best Practices for Secure Docker Containerization - Medium](https://medium.com/@maheshwar.ramkrushna/best-practices-for-secure-docker-containerization-non-root-user-read-only-volumes-and-resource-d34ed09b1bd3)

**--security-opt=no-new-privileges**
- Use `docker run --security-opt=no-new-privileges` to create a container where processes cannot gain new privileges beyond those they start with
- Prevents privilege escalation attacks
- **Source**: [Docker Security Best Practices - DEV Community](https://dev.to/574n13y/implementing-security-best-practices-in-docker-containers-32oe)

**Capability Dropping Patterns**
- Control things like whether to run as a non-root user, prevent privilege escalation (`allowPrivilegeEscalation: false`), and drop unnecessary kernel capabilities
- Follow best practices from OWASP and the CIS Docker Benchmark
- **Source**: [Docker & Kubernetes Container Security Explained - Aikido](https://www.aikido.dev/blog/docker-kubernetes-container-security)

**Container Escape Risk Mitigation**
- Although dev containers, codespaces, and VMs provide a level of isolation from the host system, they should not be considered a hard security boundary
- For enhanced security, run agent mode operations in isolated environments like dev containers, GitHub Codespaces, or virtual machines to limit potential impact
- **Source**: [Workspace Trust - VS Code Docs](https://code.visualstudio.com/docs/editing/workspaces/workspace-trust)

---

### Platform-Specific Gotchas

**Docker Desktop File Sharing Configuration**
- If you open a dev container from a non-shared location, the container will successfully start but the workspace will be empty
- **Solution**: Go to Docker Desktop ‚Üí Resources ‚Üí File Sharing and check the drive(s) where your source code is located
- **Source**: [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**macOS VirtioFS and Alternative Solutions**
- Docker Desktop 4.6+ with VirtioFS (free) provides up to 98% performance improvements for file operations
- Docker's **file synchronization feature** (paid subscription) offers an additional 59% improvement over standard VirtioFS
- **Alternative solutions**: Lima (open-source, excellent performance), OrbStack (strong performance), or hybrid approach (combining bind mounts with volumes for stable performance)
- **Sources**:
  - [Docker on MacOS is still slow? - Paolo Mainardi](https://www.paolomainardi.com/posts/docker-performance-macos-2025/)
  - [Docker Desktop for Mac is no longer slow - Collabnix](https://collabnix.com/docker-desktop-for-mac-is-no-longer-slow-and-how-docker-team-fixed-it/)

**Windows /mnt/c Performance Penalty**
- When using `/mnt/c` for Docker volumes, significant performance degradation occurs due to the Plan9 file share protocol
- Moving files from Windows filesystem (`/mnt/c`) to WSL filesystem can result in dramatically faster page load times and build performance
- **Best practice**: Keep project files in the WSL filesystem (e.g., `/home/<yourusername>/repos`) for optimal Docker performance
- **Source**: [Containers and the WSL2 File System - Ken Muse](https://www.kenmuse.com/blog/containers-and-wsl2-filesystem/)

**Windows WSL2 Optimal Filesystem Location**
- When your code lives within the WSL filesystem (e.g., `/home/<yourusername>/repos`), Docker can use highly efficient bind mounts
- Open from WSL terminal using `code .` - the command will launch VS Code on your Windows desktop, but it will automatically connect to the WSL environment
- Access WSL files from Windows using `\\wsl$\` or `\\wsl.localhost\` paths when needed
- **Source**: [Containers and the WSL2 File System - Ken Muse](https://www.kenmuse.com/blog/containers-and-wsl2-filesystem/)

**Alpine Linux glibc Compatibility Issues**
- Alpine uses musl libc, while most other linux distributions rely on glibc, making some programs compiled on one incompatible with the other
- When using Alpine Linux containers, some extensions may not work due to glibc dependencies in native code inside the extension
- The Dev Container extension downloads a glibc-based node binary, which will not run on the Alpine vscode tunnel host
- **Solutions**: Install `gcompat` compatibility layer (`apk add --no-cache gcompat libstdc++`), or compile with musl instead
- **Warning**: Installing the glibc compatibility package will get most glibc-compiled binaries to run, but some will still not work - unreliable for production
- **Sources**:
  - [Remote Development with Linux - VS Code Docs](https://code.visualstudio.com/docs/remote/linux)
  - [Running glibc programs - Alpine Linux Wiki](https://wiki.alpinelinux.org/wiki/Running_glibc_programs)
  - [Moving away from Alpine - DEV Community](https://dev.to/asyazwan/moving-away-from-alpine-30n4)

**Extension Native Code Dependencies**
- Some extensions rely on libraries not found in specific Docker images - for example, Visual Studio Live Share requires the installation of system-level dependencies
- Extensions with native code may fail on Alpine or minimal base images
- **Source**: [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**Docker-in-Docker Storage Driver Issues**
- VS Code devcontainers that run Docker inside of host Docker can cause the host Docker to run out of disk space after a few hours of working
- This frequently happens when `/var/lib/docker` is inside the container and not a volume, as the container filesystem will often be overlay
- It's not possible to define an overlay filesystem inside of an overlay filesystem
- **Solutions**: Mount a volume for `/var/lib/docker` and make sure the source for that mount is a supported backing filesystem
- **Source**: [Why is docker-in-docker using so much disk space? - Super User](https://superuser.com/questions/1836377/why-is-docker-in-docker-using-so-much-disk-space)

**VFS Fallback Layer Explosion**
- The fallback when a layered filesystem driver is not available is to use the "native" or "vfs" driver, which is just a copy of the entire filesystem for each layer
- This means a 100MB image with a single 1MB file added results in 201MB of storage
- **Source**: [Why is docker-in-docker using so much disk space? - Super User](https://superuser.com/questions/1836377/why-is-docker-in-docker-using-so-much-disk-space)

**Platform-Specific docker system prune**
- Docker provides ways to control how much memory, or CPU a container can use, setting runtime configuration flags of the docker run command
- `docker system prune --volumes` removes all stopped containers, networks not used by containers, unused volumes, dangling images, and build cache, freeing up disk space
- **Source**: [Docker runs out of disk space - GitHub Issue](https://github.com/moby/moby/issues/18869)

---

### Git & SSH Credential Handling

**SSH Key Passphrase Hang Issues**
- If you clone a Git repository using SSH and your SSH key has a passphrase, VS Code's pull and sync features may hang when running remotely
- **Workarounds**: Either use an SSH key without a passphrase, clone using HTTPS, or run git push from the command line
- **Source**: [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**SSH Agent Forwarding Setup**
- You just need to run `ssh-add` on your host - Docker mounts the SSH socket from your host to the Devcontainer, allowing you to make authentication requests from inside your Devcontainer
- Make sure the ssh agent is up on your host, by running `eval "$(ssh-agent -s)"`
- The Dev Containers extension provides out of the box support for using local Git credentials from inside a container
- **Sources**:
  - [DevContainer with host Git credentials - Marc Andreu](https://marcandreuf.com/blog/2024-07-12-gitdevcont/)
  - [Sharing Git credentials with your container - VS Code Docs](https://code.visualstudio.com/remote/advancedcontainers/sharing-git-credentials)

**Docker Email vs Docker ID Login**
- Docker login issues can occur when using your email instead of Docker ID - the Docker CLI only supports using your Docker ID
- Use your Docker ID, not your email address
- **Source**: [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**.ssh Folder Permission Requirements**
- The error "Bad owner or permissions on /home/vscode/.ssh/config" can be resolved by setting proper permissions
- **Solution**: `chmod 700` for `.ssh` directory and `chmod 600` for files inside
- **Source**: [git push fails in DevContainer - GitHub Issue](https://github.com/csci430-os/vscode-remote-devcontainer/issues/2)

**Git Credential Helper Configuration**
- Only commands that need to push or pull the remote origin (GitHub) will fail in the DevContainer
- Alternative approach: do the clone and push on the local host
- **Source**: [Cannot use SSH credentials inside the dev container - GitHub Issue](https://github.com/loft-sh/devpod/issues/1291)

---

### Docker Resource Management

**Disk Space Consumption Patterns**
- Docker devours disk space through images, containers, volumes, and build cache, and can be quite the disk space hog if left unchecked due to the accumulation of Docker artifacts over time
- One common issue is the "no space left on device" error when pulling images or running containers
- **Source**: [A Guide to Disk Space Management with Docker - Blacksmith](https://www.blacksmith.sh/blog/a-guide-to-disk-space-management-with-docker-how-to-clear-your-cache)

**docker system df Diagnostic Commands**
- Tools like `docker system df` can give you an overview of Docker's disk usage
- `docker system df -v` outputs the actual disk space used by a container
- **Source**: [Do Docker containers take up space? - DevOps Stack Exchange](https://devops.stackexchange.com/questions/12954/do-docker-containers-take-up-space)

**docker system prune Cleanup Strategies**
- Fight back with `docker system prune` and prevent future bloat through `.dockerignore` files, specific image tags, and regular cleanup habits
- `docker system prune --volumes` removes all stopped containers, networks not used by containers, unused volumes, dangling images, and build cache, freeing up disk space
- **Source**: [A Guide to Disk Space Management with Docker - Blacksmith](https://www.blacksmith.sh/blog/a-guide-to-disk-space-management-with-docker-how-to-clear-your-cache)

**Memory Limit Configuration**
- Docker provides ways to control how much memory, or CPU a container can use, setting runtime configuration flags of the docker run command
- Hard limits let the container use no more than a fixed amount of memory, while soft limits let the container use as much memory as it needs unless certain conditions are met
- **Source**: [Resource constraints - Docker Docs](https://docs.docker.com/engine/containers/resource_constraints/)

**Build Cache Management**
- Each prebuild that's created consumes storage space that will either incur a billable charge or use some of your monthly included storage
- Multi-stage builds can help reduce the size of your final image
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

**Volume Mounting for /var/lib/docker**
- The fix for Docker-in-Docker disk issues is to mount a volume for `/var/lib/docker` and make sure the source for that mount is a supported backing filesystem
- **Source**: [Why is docker-in-docker using so much disk space? - Super User](https://superuser.com/questions/1836377/why-is-docker-in-docker-using-so-much-disk-space)

---

### MCP Server Integration

**Container-to-Container stdio Limitations**
- When Claude Code runs inside a container, it cannot establish stdio connections to MCP servers running in other containers or on the host
- This is a fundamental limitation of how process-to-process stdio communication works across container boundaries
- **Workaround**: Use Streamable HTTP transport instead, or run MCP servers in the same container as Claude Code
- **Source**: [Building a Secure AI Development Environment - Medium](https://medium.com/@brett_4870/building-a-secure-ai-development-environment-containerized-claude-code-mcp-integration-e2129fe3af5a)

**Streamable HTTP vs stdio Transport Selection**
- MCP servers can be configured in Dev Containers through the devcontainer.json file
- Streamable HTTP transport works across container boundaries, while stdio requires same-container execution
- **Sources**:
  - [Use MCP servers in VS Code - VS Code Docs](https://code.visualstudio.com/docs/copilot/customization/mcp-servers)
  - [Add MCP Servers to Claude Code - MCPcat](https://mcpcat.io/guides/adding-an-mcp-server-to-claude-code/)

**mcp.json Auto-Population in Codespaces**
- When the Dev Container is created, VS Code automatically writes the MCP server configurations to the remote mcp.json file, making them available in your containerized development environment
- **Source**: [Use MCP servers in VS Code - VS Code Docs](https://code.visualstudio.com/docs/copilot/customization/mcp-servers)

**MCP Proxy Utility Patterns**
- One solution combines VS Code development containers for environment consistency and security isolation, Claude Code running inside the development container, and a self-hosted MCP server for GitHub integration using a general MCP proxy utility
- **Source**: [Building a Secure AI Development Environment - Medium](https://medium.com/@brett_4870/building-a-secure-ai-development-environment-containerized-claude-code-mcp-integration-e2129fe3af5a)

---

### Lifecycle Hook Behavior

**postCreateCommand Background Execution Default**
- By default, postCreateCommand is executed in the background after reporting the successful creation of the development environment
- This means that the container is considered ready and the IDE can connect even while the postCreateCommand is still running
- **Source**: [spec/devcontainer-reference.md - GitHub](https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md)

**waitFor Property Blocking Behavior**
- If the `waitFor` property is defined, then execution should block until all commands in the sequence up to the specified property have executed
- This property defaults to `updateContentCommand`
- **Source**: [spec/devcontainer-reference.md - GitHub](https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md)

**Codespaces vs Local Execution Differences**
- Users expected "all three of onCreateCommand, updateContentCommand, and postCreateCommand will be completed before I am able to connect to the Codespace"
- Instead, users are "connected to the Codespace while onCreateCommand is still running"
- When using VS Code Remote Containers locally, users are "presented with a 'Configuring...' Terminal that displays the progress of these commands before connecting"
- This suggests the `waitFor` property's blocking behavior may work differently between local VS Code Remote Containers and GitHub Codespaces
- **Source**: [waitFor devcontainer.json key not working - GitHub Discussion](https://github.com/orgs/community/discussions/9644)

**Parallel Execution with Object Syntax**
- postCreateCommand, postStartCommand, postAttachCommand, and initializeCommand all support object types to allow for parallel execution
- All lifecycle scripts have been extended to support object types where you can run multiple commands in parallel
- **Source**: [Life Cycle in .devcontainer - Project Asuras](https://blog.projectasuras.com/DevContainers/3)

**onCreateCommand vs postCreateCommand Timing**
- onCreateCommand runs after container creation, before user assignment (no access to user secrets or assets)
- postCreateCommand runs after container assigned to user for first time (has access to user secrets, assets, and permissions)
- Use onCreateCommand for system-level setup, postCreateCommand for user-specific configuration
- **Source**: [Dev Container metadata reference](https://containers.dev/implementors/json_reference/)

---

### Extension Compatibility

**Visual Studio Live Share System Dependencies**
- Some extensions rely on libraries not found in specific Docker images - for example, Visual Studio Live Share requires the installation of system-level dependencies
- **Solution**: Install required system libraries in your Dockerfile
- **Source**: [Dev Containers Tips and Tricks - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/tips-and-tricks)

**Alpine Linux glibc Extension Failures**
- When using Alpine Linux containers, some extensions may not work due to glibc dependencies in native code inside the extension
- Alpine uses musl libc instead of glibc, causing incompatibility
- **Source**: [Remote Development with Linux - VS Code Docs](https://code.visualstudio.com/docs/remote/linux)

**Native Code Library Requirements**
- For Alpine Linux, included native code or runtimes may not work due to fundamental differences between how libc is implemented in Alpine Linux (musl) and other distributions (glibc)
- **Solution**: Use Debian/Ubuntu-based images for maximum extension compatibility, or install gcompat on Alpine
- **Source**: [Remote Development with Linux - VS Code Docs](https://code.visualstudio.com/docs/remote/linux)

**gcompat Compatibility Layer Solution**
- gcompat is a library which provides glibc-compatible APIs for use on musl libc systems like Alpine Linux
- Install with `apk add --no-cache gcompat libstdc++`
- **Warning**: This is unreliable and not suited for production environments - some glibc binaries will still not work
- **Sources**:
  - [Running glibc programs - Alpine Linux Wiki](https://wiki.alpinelinux.org/wiki/Running_glibc_programs)
  - [Is there a best practice on setting up glibc on Alpine - Stack Overflow](https://stackoverflow.com/questions/37818831/is-there-a-best-practice-on-setting-up-glibc-on-docker-alpine-linux-base-image)

---

### GitHub Codespaces Specific

**Prebuild Trigger Strategy Optimization**
- You can choose between "On configuration change" trigger which will update prebuilds only when devcontainer files change - this option uses fewer GitHub Actions minutes but won't guarantee codespaces always include recently added or updated dependencies
- Versus the default "Every push" setting
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

**onCreateCommand vs updateContentCommand Usage**
- Use `onCreateCommand` and `updateContentCommand` commands in your devcontainer.json to include time-consuming processes as part of prebuild creation
- `onCreateCommand` runs only once when the prebuild is created, whereas `updateContentCommand` runs at creation and at subsequent updates
- Incremental builds should be included in `updateContentCommand` since they represent the source of your project
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

**Prebuild Optimization Setting Importance**
- Keep prebuild optimization enabled, because it helps ensure that codespaces can still be created quickly if an up-to-date prebuild is not available
- With this optimization, as long as there is an active prebuild for a given repository, branch, and devcontainer combination, you will be able to spin up prebuilt codespaces for it, even if the latest prebuild workflow for that branch might be failing
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

**Storage Cost Management**
- Each prebuild that's created consumes storage space that will either incur a billable charge or, for repositories owned by your personal GitHub account, will use some of your monthly included storage
- Monitor your prebuild usage to avoid unexpected costs
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

**Multi-Stage Builds for Size Reduction**
- Use multi-stage builds to reduce the size of your final image
- Multi-stage builds allow you to create intermediate images that perform specific tasks, and then copy only the necessary files to the final image
- Also, exclude files and directories that are not needed for building or running your application with a `.dockerignore` file
- **Source**: [Configuring prebuilds - GitHub Docs](https://docs.github.com/en/codespaces/prebuilding-your-codespaces/configuring-prebuilds)

---

### Features vs Dockerfile Best Practices

**When to Use Features**
- Features allow you to install tools like Ruby and Node in a single line in devcontainer.json, versus potentially several steps in a typical Dockerfile
- You can reuse the Dockerfile that defines your production infrastructure and then layer some Features over that, allowing it to be used for both local development and production deployments, without the risk of developer tooling leaking out
- **Source**: [Simplifying devcontainers With Features - LINQ to Fail](https://www.aaron-powell.com/posts/2023-01-11-simplifying-devcontainers-with-features/)

**When to Use Dockerfiles**
- A Dockerfile is most suitable for installing packages and tools independent of your workspace files
- A custom Dockerfile will benefit from Docker's build cache and result in faster rebuilds than postCreateCommand
- This can result in a faster build process and an easy way to centralize an image
- **Source**: [Devfile & devcontainer vs. Dockerfile & Docker-Compose - Cloudomation](https://cloudomation.com/cloudomation-blog/devfile-devcontainer-vs-dockerfile-docker-compose/)

**Best Practice Recommendation**
- Features tend to be the right solution when the Dockerfile is intended to represent the base of a dev container and a production image
- The approach allows you to maintain a production-ready Dockerfile while layering development-specific tools through Features
- **Source**: [Intro to Dev Container Features - Ken Muse](https://www.kenmuse.com/blog/intro-to-dev-container-features/)

**Key Limitation of Dockerfiles in Devcontainers**
- The Dockerfile runs before the dev container is created and the workspace folder is mounted and therefore does not have access to the files in the workspace folder
- For workspace-specific setup, use lifecycle hooks instead
- **Source**: [Create a Dev Container - VS Code Docs](https://code.visualstudio.com/docs/devcontainers/create-dev-container)

---

## AI Assistant Guidelines

> **For AI Assistants**: When helping users create or debug devcontainers:

### Decision-Making Framework

1. **Assess User Experience**:
   - Beginner? ‚Üí Start with minimal example, explain each line
   - Intermediate? ‚Üí Provide working example with customization options
   - Advanced? ‚Üí Discuss trade-offs, security implications

2. **Understand Requirements**:
   - What's the primary language? ‚Üí Choose base image
   - Need databases? ‚Üí Suggest Docker Compose pattern
   - Security concerns? ‚Üí Recommend firewall, volume isolation
   - Team environment? ‚Üí Emphasize reproducibility

3. **Provide Progressive Solutions**:
   - **First**: Minimal working setup (get them running)
   - **Then**: Add features (MCP servers, multi-AI, security)
   - **Finally**: Optimize (caching, performance, cleanup)

4. **Always Include**:
   - ‚úÖ UTF-8 locale configuration
   - ‚úÖ Volume mounts for `.claude/` (and other AI configs)
   - ‚úÖ Git exclusion of `.claude/settings.local.json`
   - ‚úÖ Explanation of "why" not just "how"

5. **Test Incrementally**:
   - Suggest testing Dockerfile with `docker build -t test .`
   - Recommend building ‚Üí testing ‚Üí adding features ‚Üí rebuilding
   - Don't give 500-line config without incremental validation

6. **Reference Official Docs**:
   - Link to https://docs.claude.com/en/docs/claude-code/devcontainer
   - Cite VS Code devcontainers docs for advanced features
   - Point to official MCP docs for server configuration

7. **Explain Trade-offs**:
   - Security vs. convenience (firewall vs. open network)
   - Performance vs. disk space (slim images vs. feature-rich)
   - Simplicity vs. robustness (minimal config vs. production-ready)

### Common User Questions (Suggested Responses)

**"How do I add Python to my Node devcontainer?"**
```dockerfile
# In Dockerfile after base image
RUN apt-get update && apt-get install -y \
  python3 \
  python3-pip \
  python3-venv \
  && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**"Can I use my existing Dockerfile?"**
Yes, but recommend separation:
- Production: `Dockerfile` (optimized for size, security)
- Development: `.devcontainer/Dockerfile` (includes dev tools, AI assistants)

**"How do I share my devcontainer with my team?"**
Commit `.devcontainer/` to git. Team members:
1. Pull repo
2. Open in VS Code
3. Click "Reopen in Container"

**"Will this work on Windows?"**
Yes, if using WSL2:
- Docker Desktop ‚Üí Settings ‚Üí "Use WSL2 based engine" ‚úÖ
- Clone projects into WSL2 filesystem (not `/mnt/c/`), for performance

**"How do I debug build failures?"**
1. Test Dockerfile directly: `docker build -t test .devcontainer/`
2. View full error output (not truncated VS Code log)
3. Use `RUN echo "Checkpoint 1"` to isolate failing line
4. Check [Step-by-Step Debug Process](#step-by-step-debug-process)

**"Should I use devcontainers for [X]?"**
- ‚úÖ Multi-developer teams
- ‚úÖ Projects with complex dependencies
- ‚úÖ Security-sensitive work (client projects)
- ‚úÖ Cross-platform development
- ‚ùå Simple scripts (overkill)
- ‚ùå GPU-intensive ML (complex setup)
- ‚ùå GUI desktop apps

---

**Document Version**: 2.0
**Last Updated**: 2025-10
**Maintained By**: Community
**License**: MIT
**Feedback**: https://github.com/anthropics/claude-code/discussions

---

> **For AI Assistants**: You've reached the end of this comprehensive guide. Remember:
> - **Understand before implementing** - Ask clarifying questions
> - **Start simple, iterate** - Don't overwhelm with 500-line configs
> - **Explain trade-offs** - Security, performance, complexity
> - **Test incrementally** - Build ‚Üí Test ‚Üí Add feature ‚Üí Rebuild
> - **Reference official docs** - https://docs.claude.com/en/docs/claude-code/devcontainer
> - **Prioritize user success** - Working devcontainer > perfect devcontainer

**Your goal**: Help users achieve a **working devcontainer** that solves their problem, not to showcase every advanced feature.
