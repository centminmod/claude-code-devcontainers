# VS Code Development Containers for Claude Code and Multi-AI Environments

> **AI Assistant Guidance**: This document provides comprehensive instructions for creating, configuring, and managing VS Code development containers optimized for Claude Code and other AI coding assistants. Use this as a complete reference when helping users set up devcontainer environments.

> **Version Context**: Version numbers, software references, and technical specifications current as of October 2025.

> **Official Documentation**: https://docs.claude.com/en/docs/claude-code/devcontainer
> **Specification**: https://containers.dev/implementors/spec/
> **JSON Reference**: https://containers.dev/implementors/json_reference/


---

## 5-Minute Quick Start (Impatient Users Start Here!)

**Already have Docker + VS Code + Dev Containers extension?** Jump straight in:

```bash
# Method 1: Clone Anthropic's reference implementation
git clone https://github.com/anthropics/claude-code.git
cd claude-code
code .
# Click "Reopen in Container" when prompted (5-10 min first time)

# Method 2: Create minimal devcontainer (2 files)
mkdir -p .devcontainer
cat > .devcontainer/devcontainer.json << 'EOF'
{
 "name": "Claude Code",
 "image": "node:22",
 "customizations": {"vscode": {"extensions": ["anthropic.claude-code"]}},
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest && npm install -g @openai/codex && npm install -g @google/gemini-cli",
 "remoteUser": "node",
 "mounts": [
  "source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume",
  "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
  "source=codex-config-${devcontainerId},target=/home/node/.codex,type=volume",
  "source=gemini-config-${devcontainerId},target=/home/node/.gemini,type=volume",
  "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
  "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume"
  // Add cloud tools: "source=aws-config-${devcontainerId},target=/home/node/.aws,type=volume"
  // Add cloud tools: "source=local-bin-${devcontainerId},target=/home/node/.local,type=volume"
  // Add cloud tools: "source=wrangler-config-${devcontainerId},target=/home/node/.wrangler,type=volume"
  // Add Vercel: "source=vercel-config-${devcontainerId},target=/home/node/.vercel,type=volume"
 ]
}
EOF
code .
# Click "Reopen in Container"
```

**Don't have prerequisites?** [Jump to Prerequisites](#prerequisites)

**Want to understand before doing?** [Read "What Are Development Containers?"](#what-are-development-containers)

---

## Table of Contents

### Getting Started
1. [What Are Development Containers?](#what-are-development-containers)
2. [Why Use Development Containers?](#why-use-development-containers)
3. [When NOT to Use Devcontainers](#when-not-to-use-devcontainers)
4. [Prerequisites](#prerequisites)
5. [Quick Start Checklist](#quick-start-checklist)

### Core Concepts
6. [Architecture Overview](#architecture-overview)
7. [Official devcontainer.json Property Reference](#official-devcontainerjson-property-reference)
8. [AI Decision Trees](#ai-decision-trees) ⭐ **For AI Assistants**
9. [AI Assistant Quick Commands](#ai-assistant-quick-commands)
 - [AI Assistant Discovery Protocol](#ai-assistant-discovery-protocol)
10. [Common Stack Examples](#common-stack-examples)
11. [Prebuild Images & CI/CD Automation](#prebuild-images--cicd-automation)
12. [Creating & Distributing Templates](#creating--distributing-templates)

### Implementation
13. [Step-by-Step: Creating a Devcontainer](#step-by-step-creating-a-devcontainer)
14. [Lifecycle Hooks Explained](#lifecycle-hooks-explained)
15. [Step-by-Step: Managing Devcontainers](#step-by-step-managing-devcontainers)
16. [Multi-AI Configuration](#multi-ai-configuration)
17. [MCP Server Setup](#mcp-server-setup)

### Advanced Topics
18. [Security Best Practices](#security-best-practices)
19. [Volume Persistence Patterns](#volume-persistence-patterns)
20. [Platform-Specific Notes](#platform-specific-notes)
21. [Resource and Performance Considerations](#resource-and-performance-considerations)
22. [VS Code Tips & Tricks](#vs-code-tips--tricks)
23. [Remote Development Platforms](#remote-development-platforms)
24. [Devcontainer CLI Reference](#devcontainer-cli-reference)
25. [Migration Guides](#migration-guides)

### Troubleshooting
26. [Step-by-Step Debug Process](#step-by-step-debug-process)
27. [Common Troubleshooting](#common-troubleshooting)
28. [Common Mistakes and Gotchas](#common-mistakes-and-gotchas)

### Reference
29. [Quick Reference](#quick-reference)
30. [Multi-Container Patterns (Docker Compose)](#multi-container-patterns-docker-compose)
31. [DevContainer Features](#devcontainer-features)
32. [Frequently Asked Questions](#frequently-asked-questions)
33. [Glossary](#glossary)
34. [Anecdotal Notes & Field Reports](#anecdotal-notes--field-reports)

---

## What Are Development Containers?

Development containers (devcontainers) are Docker containers specifically configured for development work. They provide:

- **Isolated Environment**: A self-contained workspace separate from your host machine
- **Reproducible Setup**: Same environment for all team members
- **VS Code Integration**: Seamless connection between VS Code and the container
- **Full Toolchain**: Pre-installed languages, tools, and dependencies

**Analogy**: Think of a devcontainer as a "development workspace in a box" - everything you need to code is pre-installed and ready to go.

### How They Work (Visual Flow)

```
┌─────────────┐
│ Your Mac/ │
│ Windows/ │ 1. Open project
│ Linux │────────────────────┐
└─────────────┘ │
 ▼
 ┌─────────────────┐
 │ VS Code │
 │ (detects │
 │ .devcontainer/) │
 └─────────────────┘
 │
 2. Builds/starts │
 Docker container │
 ▼
 ┌─────────────────┐
 │ Docker Container│
 │ • Node.js │
 │ • Claude Code │
 │ • Your tools │
 └─────────────────┘
 │
 3. VS Code connects
 │
 ▼
 You code as if local
 (but it's in container)
```

---

## Why Use Development Containers?

### Benefits for Individual Developers

- **Zero Setup**: No manual installation of Node.js, Python, build tools, etc.
- **Clean Host System**: Tools run in containers, keeping your computer clean
- **Disposable**: Delete and rebuild anytime without losing configurations
- **Multiple Environments**: Different projects with conflicting dependencies work side-by-side
- **Consistency**: Same setup on Mac, Windows, and Linux
- **Security**: Network isolation prevents credential leakage between projects

### Benefits for Teams

- **Onboarding**: New developers productive in minutes, not days
- **Standardization**: Everyone uses the same tools and versions
- **CI/CD Alignment**: Dev environment mirrors production/CI environment
- **Documentation as Code**: Environment setup is version-controlled
- **Troubleshooting**: "Works on my machine" becomes obsolete

### Benefits for AI Coding Assistants

- **Pre-configured Tools**: Claude Code, MCP servers, and CLIs ready immediately
- **Security Isolation**: Each project gets isolated credentials and network access
- **Persistent State**: Configuration persists across container rebuilds
- **Reproducibility**: Same environment for testing AI-generated code
- **Automation-Ready**: Can run with `--dangerously-skip-permissions` in trusted environments

---

## When NOT to Use Devcontainers

Devcontainers aren't always the best solution. **Avoid devcontainers when:**

 **Simple Scripts** - For single-file Python/Node scripts, local execution is faster
 **GUI Applications** - Desktop apps requiring native UI don't work well in containers
 **Hardware Access** - USB devices, GPUs, specialized hardware need complex setup
 **Legacy Windows Apps** - .NET Framework, Visual Studio projects better on Windows directly
 **Resource-Constrained Machines** - Docker overhead (1-2GB RAM) may be too much
 **Quick Experiments** - Testing a new tool for 5 minutes doesn't warrant container setup
 **Learning Docker** - Ironically, learning Docker itself is easier on host

**Better Alternatives:**
- **Simple projects**: `nvm`, `pyenv`, `rbenv` for version management
- **Cloud development**: GitHub Codespaces, Gitpod for browser-based environments
- **Virtual machines**: VirtualBox, VMware for full OS isolation

---

## Prerequisites

### Required Software

1. **VS Code**: Download from https://code.visualstudio.com/
2. **Docker Desktop**: Download from https://www.docker.com/products/docker-desktop
 - **Mac**: Intel or Apple Silicon (M1/M2/M3) supported, Docker Desktop 4.0+
 - **Windows**: WSL2 required, Docker Desktop 4.0+ (see [Platform-Specific Notes](#platform-specific-notes))
 - **Linux**: Docker Engine 20.10+ (community edition fine)
3. **Dev Containers Extension**: Install from VS Code marketplace
 - Extension ID: `ms-vscode-remote.remote-containers`
 - Install via: `Cmd+Shift+X` (Mac) / `Ctrl+Shift+X` (Windows/Linux) → Search "Dev Containers" → Install

### Verify Installation

```bash
# Check Docker (should show version and "Server: Docker Engine")
docker --version
docker info

# Check VS Code (should show version)
code --version

# Test Docker works
docker run hello-world
```

**Troubleshooting Verification**:
- If `docker info` shows "Cannot connect to Docker daemon", start Docker Desktop
- If `code` command not found, VS Code → View → Command Palette → "Shell Command: Install 'code' command in PATH"

### Minimum System Requirements

- **RAM**: 8GB minimum, 16GB recommended (Docker + VS Code + containers)
- **Disk**: 20GB free space (Docker images accumulate quickly)
- **CPU**: 2 cores minimum, 4+ cores for comfortable experience
- **OS**: macOS 10.15+, Windows 10/11 with WSL2, Ubuntu 20.04+

---

## Quick Start Checklist

Before creating your first devcontainer, verify:

- [ ] Docker Desktop installed and **running** (check menu bar/system tray)
- [ ] VS Code installed with Dev Containers extension
- [ ] At least 10GB free disk space
- [ ] Familiarity with basic terminal commands (`cd`, `ls`, `cat`)
- [ ] Understanding of what problem devcontainers solve for your project

**Ready?** Proceed to [Creating a Devcontainer](#step-by-step-creating-a-devcontainer)

---

## Architecture Overview

A devcontainer consists of three core components:

### File Structure

```
your-project/
├── .devcontainer/
│ ├── devcontainer.json # Container configuration (required)
│ ├── Dockerfile # Container image definition (required)
│ ├── init-claude-config.sh # Claude Code initialization (optional)
│ ├── init-firewall.sh # Network security (optional)
│ ├── mcp.json.template # MCP servers template (optional)
│ └── settings.json.template # Claude settings template (optional)
├── .gitignore # Git exclusions
├── README.md # Project docs
└── [your project files]
```

### Component Purposes

**devcontainer.json** (VS Code ↔ Docker bridge)
- Controls VS Code integration
- Defines mounts, environment variables, and extensions
- Configures port forwarding
- Sets post-creation commands
- **Role**: "How VS Code interacts with the container"

**Dockerfile** (Container blueprint)
- Defines base image (e.g., `node:22`, `python:3.11`)
- Installs system packages and tools
- Sets up users and permissions
- Configures shell environment
- **Role**: "What's installed inside the container"

**Init Scripts** (Automation)
- Run after container starts
- Initialize tool configurations (e.g., MCP servers)
- Set up security policies (e.g., firewall rules)
- Prepare development environment
- **Role**: "Automated setup tasks on first start"

### Configuration Flow

```
1. VS Code reads devcontainer.json
 ↓
2. Docker builds image from Dockerfile
 ↓
3. Docker starts container with mounts/env vars
 ↓
4. postStartCommand runs init scripts
 ↓
5. VS Code connects and installs extensions
 ↓
6. You start coding!
```

---

## AI Decision Trees

## Official devcontainer.json Property Reference

> **AI Assistant Guidance**: Use this complete property reference when helping users configure their devcontainer.json files. All properties link to official schema documentation.

**Official Schema**: https://containers.dev/implementors/json_reference/

### Container Configuration

#### name
- **Type**: `string`
- **Description**: Display identifier for the development container shown in UI interfaces
- **Example**: `"My Dev Container"` or `"${localWorkspaceFolderBasename}"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### image
- **Type**: `string`
- **Description**: Name of an image in a container registry (DockerHub, GHCR, ACR) that devcontainer.json supporting services should use to create the dev container
- **Example**: `"node:22"`, `"mcr.microsoft.com/devcontainers/typescript-node:22"`
- **Schema**: https://containers.dev/implementors/json_reference/#image-specific
- **Use when**: You want to use a pre-built image instead of building from Dockerfile

#### build
- **Type**: `object`
- **Description**: Configuration for building a custom container from a Dockerfile
- **Properties**:
 - `dockerfile` (string): Path to Dockerfile relative to devcontainer.json
 - `context` (string): Docker build context directory (default: `.`)
 - `args` (object): Build arguments passed to Docker build, supports variable interpolation
 - `target` (string): Target stage in multi-stage Dockerfile
- **Example**:
 ```json
 {
 "build": {
 "dockerfile": "Dockerfile",
 "context": "..",
 "args": {
 "NODE_VERSION": "20",
 "TZ": "${localEnv:TZ:UTC}"
 },
 "target": "development"
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#image-specific

### Environment & Users

#### containerEnv
- **Type**: `object`
- **Description**: Set or override environment variables for the container. Variables apply to all processes spawned within the container and remain static across the container's lifetime
- **Example**:
 ```json
 {
 "containerEnv": {
 "NODE_ENV": "development",
 "API_URL": "http://localhost:3000"
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Note**: Use for container-level config. For tool-specific env vars, use `remoteEnv`

#### remoteEnv
- **Type**: `object`
- **Description**: Environment variables scoped to development tools and sub-processes rather than the container itself, allowing dynamic updates without rebuilding
- **Example**:
 ```json
 {
 "remoteEnv": {
 "PATH": "${containerEnv:PATH}:/custom/bin",
 "WORKSPACE_FOLDER": "${containerWorkspaceFolder}"
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Variables**: Supports `${localEnv:VAR}`, `${containerEnv:VAR}`, `${localWorkspaceFolder}`, etc.

#### remoteUser
- **Type**: `string`
- **Description**: User that runs connected tools and processes within the container
- **Example**: `"node"`, `"vscode"`, `"root"`
- **Default**: Container's default user (often root)
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Best Practice**: Use non-root user for security

#### containerUser
- **Type**: `string`
- **Description**: Specifies the operational user for all container processes
- **Example**: `"node"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Difference from remoteUser**: containerUser affects container processes, remoteUser affects tool connections

### Lifecycle Hooks

#### initializeCommand
- **Type**: `string | array | object`
- **Description**: Command to run on local/host machine before container creation
- **When**: Before any container operations
- **Access**: Local machine only, no container access
- **Example**: `"npm install"` (runs on host to populate node_modules before mounting)
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### onCreateCommand
- **Type**: `string | array | object`
- **Description**: Command to run after container creation (first start only)
- **When**: After container created, before user assignment
- **Access**: No user secrets or assets
- **Example**: `"apt-get update && apt-get install -y git"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### updateContentCommand
- **Type**: `string | array | object`
- **Description**: Command to run when new content is available in the workspace
- **When**: When workspace content updates
- **Access**: Limited, similar to onCreateCommand
- **Example**: `"npm install"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postCreateCommand
- **Type**: `string | array | object`
- **Description**: Command to run after container assigned to user for first time
- **When**: After user assignment (first start)
- **Access**: Has access to user secrets, assets, and permissions
- **Example**: `"npm install -g @anthropic-ai/claude-code@latest && npm install -g @openai/codex"`
- **Use For**: Global package installations that need volume persistence (runs AFTER volumes mount)
- **Execution**: Background by default (non-blocking)
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postStartCommand
- **Type**: `string | array | object`
- **Description**: Command to run each time the container successfully starts
- **When**: Every container start
- **Access**: Full container access
- **Example**: `"docker-compose up -d database"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### postAttachCommand
- **Type**: `string | array | object`
- **Description**: Command to run each time a tool attaches to the container
- **When**: Every tool attachment (e.g., opening in VS Code)
- **Example**: `"echo 'Welcome to the dev container!'"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

#### waitFor
- **Type**: `enum`
- **Options**: `"initializeCommand" | "onCreateCommand" | "updateContentCommand" | "postCreateCommand" | "postStartCommand" | "postAttachCommand"`
- **Default**: `"updateContentCommand"`
- **Description**: Specifies which lifecycle command tools should wait for before connecting
- **Example**: `"waitFor": "postCreateCommand"`
- **Schema**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

### Ports & Networking

#### forwardPorts
- **Type**: `array`
- **Items**: `number` or `string` (format: `"host:container"`)
- **Description**: Ports that should always be forwarded from inside the primary container to the local machine (including on the web)
- **Example**: `[3000, 8080, "5000:5000"]`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### portsAttributes
- **Type**: `object`
- **Description**: Maps specific ports to configuration options including labels, protocols, and auto-forward behaviors
- **Properties per port**:
 - `label` (string): Display name
 - `protocol` (string): `"http"` or `"https"`
 - `onAutoForward` (string): `"notify"`, `"openBrowser"`, `"openPreview"`, `"silent"`, `"ignore"`
 - `requireLocalPort` (boolean): Require specific local port
 - `elevateIfNeeded` (boolean): Elevate privileges if port <1024
- **Example**:
 ```json
 {
 "portsAttributes": {
 "3000": {
 "label": "Dev Server",
 "protocol": "http",
 "onAutoForward": "openBrowser"
 },
 "5432": {
 "label": "PostgreSQL",
 "onAutoForward": "silent"
 }
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

### VS Code Customizations

#### customizations.vscode.extensions
- **Type**: `array`
- **Items**: `string` (extension IDs)
- **Description**: VS Code extensions to install in the container
- **Example**: `["anthropic.claude-code", "dbaeumer.vscode-eslint"]`
- **Schema**: https://containers.dev/implementors/json_reference/#vs-code-specific-properties
- **Extension ID Format**: `publisher.extension-name`

#### customizations.vscode.settings
- **Type**: `object`
- **Description**: VS Code settings to apply in the container
- **Example**:
 ```json
 {
 "customizations": {
 "vscode": {
 "settings": {
 "terminal.integrated.defaultProfile.linux": "zsh",
 "editor.formatOnSave": true,
 "python.defaultInterpreterPath": "/usr/local/bin/python"
 }
 }
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#vs-code-specific-properties

### Features

#### features
- **Type**: `object`
- **Description**: Dev Container Features to install (modular tooling like Git, Docker, AWS CLI)
- **Format**: `{ "feature-id": options }`
- **Example**:
 ```json
 {
 "features": {
 "ghcr.io/devcontainers/features/node:1": {
 "version": "20"
 },
 "ghcr.io/devcontainers/features/python:1": {
 "version": "3.11"
 },
 "ghcr.io/devcontainers/features/docker-in-docker:2": {}
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Registry**: https://containers.dev/features
- **Docs**: https://containers.dev/implementors/features/

### Resource Requirements

#### hostRequirements
- **Type**: `object`
- **Description**: Minimum hardware specifications for cloud services to use when creating compute
- **Properties**:
 - `cpus` (integer): Minimum CPU cores
 - `memory` (string): Minimum RAM (e.g., `"8gb"`)
 - `storage` (string): Minimum disk (e.g., `"32gb"`)
- **Example**:
 ```json
 {
 "hostRequirements": {
 "cpus": 4,
 "memory": "8gb",
 "storage": "32gb"
 }
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Used by**: GitHub Codespaces, cloud-based devcontainer services

### Mounts & Volumes

#### mounts
- **Type**: `array`
- **Items**: `string` (mount specification)
- **Description**: Additional mounts for the container
- **Format**: `"source=<source>,target=<target>,type=<type>[,options]"`
- **Types**: `volume`, `bind`, `tmpfs`
- **Example**:
 ```json
 {
 "mounts": [
 "source=claude-config-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
 "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
 ]
 }
 ```
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Variables**: `${devcontainerId}` creates unique volume per container instance

### Advanced Configuration

#### runArgs
- **Type**: `array`
- **Items**: `string` (Docker CLI arguments)
- **Description**: Docker run arguments to use when creating the container
- **Example**: `["--cap-add=SYS_PTRACE", "--security-opt=seccomp=unconfined"]`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Docs**: https://docs.docker.com/engine/reference/run/

#### workspaceFolder
- **Type**: `string`
- **Description**: Path where workspace should be mounted inside container
- **Example**: `"/workspaces/${localWorkspaceFolderBasename}"`
- **Default**: `/workspaces/<folder-name>`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties

#### workspaceMount
- **Type**: `string`
- **Description**: Custom mount specification for the workspace folder
- **Example**: `"source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=cached"`
- **Schema**: https://containers.dev/implementors/json_reference/#general-properties
- **Note**: Only needed for custom workspace mounting; default usually sufficient

### Docker Compose Support

#### dockerComposeFile
- **Type**: `string | array`
- **Description**: Path(s) to Docker Compose file(s) relative to devcontainer.json
- **Example**: `"../docker-compose.yml"` or `["../docker-compose.yml", "docker-compose.devcontainer.yml"]`
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

#### service
- **Type**: `string`
- **Description**: Name of the service in docker-compose.yml that VS Code should connect to
- **Example**: `"app"`
- **Required**: When using Docker Compose
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

#### runServices
- **Type**: `array`
- **Items**: `string` (service names)
- **Description**: Services to start when creating the container
- **Example**: `["app", "database", "cache"]`
- **Default**: All services
- **Schema**: https://containers.dev/implementors/json_reference/#docker-compose-specific

### Property Quick Reference Table

| Category | Key Properties | Schema Link |
|----------|---------------|-------------|
| **Container** | `name`, `image`, `build` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Environment** | `containerEnv`, `remoteEnv`, `remoteUser` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Lifecycle** | `onCreateCommand`, `postCreateCommand`, `postStartCommand` | [Link](https://containers.dev/implementors/json_reference/#lifecycle-scripts) |
| **Ports** | `forwardPorts`, `portsAttributes` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **VS Code** | `customizations.vscode.extensions`, `customizations.vscode.settings` | [Link](https://containers.dev/implementors/json_reference/#vs-code-specific-properties) |
| **Features** | `features` | [Link](https://containers.dev/implementors/features/) |
| **Resources** | `hostRequirements` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Volumes** | `mounts`, `workspaceMount` | [Link](https://containers.dev/implementors/json_reference/#general-properties) |
| **Docker** | `runArgs`, `dockerComposeFile`, `service` | [Link](https://containers.dev/implementors/json_reference/) |

### Sources
- **Complete Schema Reference**: https://containers.dev/implementors/json_reference/
- **JSON Schema File**: https://github.com/devcontainers/spec/blob/main/schemas/devContainer.base.schema.json
- **Specification**: https://containers.dev/implementors/spec/
- **VS Code Documentation**: https://code.visualstudio.com/docs/devcontainers/create-dev-container

---


---


> **For AI Assistants**: Use these decision trees to quickly determine the right approach for user requests.

### Decision Tree 1: Which Base Image?

```
User's primary language?
├─ JavaScript/TypeScript → node:22
├─ Python → python:3.11-slim
├─ Go → golang:1.21
├─ Rust → rust:1.75
├─ Java → eclipse-temurin:17
├─ Multi-language → node:22 + install others
└─ Universal → mcr.microsoft.com/devcontainers/base:ubuntu
```

### Decision Tree 2: MCP Transport Type

**How to determine transport**: See "Testing MCP Server Transport Support" section below for testing methodology.

```
MCP server needs what?
├─ External API (Context7, Cloudflare Docs)
│ ├─ Context7
│ │ └─ Use: transport.type = "sse" (only option as of Oct 27, 2025)
│ │ URL: https://mcp.context7.com/sse
│ │
│ └─ Cloudflare Docs (two options)
│ ├─ SSE (public, simple): transport.type = "sse"
│ │ URL: https://docs.mcp.cloudflare.com/sse
│ │
│ └─ mcp-remote (OAuth, recommended): transport.type = "stdio"
│ Command: npx mcp-remote https://docs.mcp.cloudflare.com/mcp
│
├─ Local npm package (Chrome DevTools)
│ └─ Use: transport.type = "stdio"
│ Command: npx package-name
│
└─ Custom server
 └─ Test to determine: Use curl or try both transports
 See "Testing MCP Server Transport Support" section
```

### Decision Tree 3: Volume or Bind Mount?

```
What are you persisting?
├─ API keys, configs (.claude/, .codex/, .aws/)
│ → Named volume (survives container deletion)
│ → source=name-${devcontainerId},target=/path,type=volume
│
├─ CLI binaries and tools (AWS CLI, wrangler, vercel)
│ → Named volume (persists across rebuilds)
│ → source=local-bin-${devcontainerId},target=/home/node/.local,type=volume
│ → source=wrangler-config-${devcontainerId},target=/home/node/.wrangler,type=volume
│ → source=vercel-config-${devcontainerId},target=/home/node/.vercel,type=volume
│
├─ SSH keys (read-only access)
│ → Bind mount (readonly)
│ → source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly
│
├─ Temporary build cache
│ → Named volume (disposable)
│ → source=cache-${devcontainerId},target=/cache,type=volume
│
└─ Shared data with host
 → Bind mount (read-write, caution!)
 → source=/host/path,target=/container/path,type=bind
```

### Decision Tree 4: Troubleshooting Entry Point

```
User reports error, what type?
├─ "Container won't build"
│ → Go to: Step-by-Step Debug Process → Build Failures
│
├─ "Claude/tool command not found"
│ → Go to: Common Troubleshooting → PATH issues
│
├─ "Permission denied"
│ → Go to: Common Troubleshooting → File permissions
│
├─ "Out of memory/disk space"
│ → Go to: Resource Considerations
│
└─ "MCP servers not loading"
 → Go to: MCP Server Setup → Debugging
```

### Decision Tree 5: Security Level

```
Who owns the codebase?
├─ You/Your team (trusted)
│ ├─ Sensitive data? (client project, API keys)
│ │ → Enable firewall, isolate volumes, use --dangerously-skip-permissions
│ └─ No sensitive data
│ → Basic setup, optional firewall
│
├─ Open source (trusted maintainers)
│ → Standard setup, review .devcontainer/ before opening
│
└─ Unknown/Untrusted
 → DON'T use devcontainer OR
 → Use heavily restricted firewall
 → Don't use --dangerously-skip-permissions
 → Review Dockerfile line-by-line
```

### Decision Tree 6: Image vs Build vs Compose?

```
How complex is the project setup?
├─ Single service, standard language (Node, Python, Go)
│ ├─ No custom tools needed?
│ │ → Use "image": "node:22" (fastest, simplest)
│ │ → Add tools via Features
│ │
│ └─ Custom tools or specific versions needed?
│ → Use "build": {"dockerfile": "Dockerfile"}
│ → Customize base image with RUN commands
│
├─ Multiple services (app + database + cache)
│ → Use Docker Compose
│ → Create docker-compose.yml with all services
│ → Reference in devcontainer.json: "dockerComposeFile": "docker-compose.yml"
│
└─ Need both custom build AND multiple services?
 → Use Docker Compose + custom Dockerfile
 → docker-compose.yml defines services
 → app service uses "build: {dockerfile: .devcontainer/Dockerfile}"
```

**Quick Decision Guide**:
- **Just coding** (no database) → `"image": "language:version"`
- **Custom tools** (Chromium, ffmpeg) → `"build": {"dockerfile": "Dockerfile"}`
- **Database required** → Docker Compose
- **Complex stack** (app+db+redis+mq) → Docker Compose with custom Dockerfile

---

## AI Assistant Quick Commands

> **AI Assistant Guidance**: These are common user requests and suggested prompts for efficiently handling devcontainer tasks. Use these as templates when users ask for help.

---

## AI Assistant Discovery Protocol

> **Critical Guidance for AI Assistants**: Before creating any devcontainer, follow this adaptive discovery protocol. It optimizes for user expertise level, minimizes questions through auto-detection, and provides appropriate explanations based on experience.

### Core Principles

1. **Scan First, Ask Smart**: Auto-detect project details before asking questions
2. **Adapt to Expertise**: One question determines verbosity for all subsequent interactions
3. **Minimize Questions**: Maximum 4 questions for beginners, 3 for intermediate, 2 for experts
4. **Provide Defaults**: Every question has a sensible default (press Enter)
5. **Show, Don't Interrogate**: Present proposed configuration for approval

---

### Step 1: Silent Auto-Detection (Always Run First)

**Before asking ANY questions, scan the project directory to detect:**

| File/Pattern | Indicates | Action |
|--------------|-----------|--------|
| `package.json` | Node.js project | Extract version, detect framework (React, Next.js, Express) |
| `package-lock.json` | npm used | Use npm for postCreateCommand |
| `yarn.lock` | Yarn used | Use yarn for postCreateCommand |
| `requirements.txt` | Python project | Detect dependencies (Flask, Django, FastAPI) |
| `pyproject.toml` | Modern Python | Use poetry/pip as appropriate |
| `go.mod` | Go project | Extract Go version |
| `Cargo.toml` | Rust project | Rust application |
| `docker-compose.yml` | Already using Compose | Offer to integrate with existing config |
| `Dockerfile` | Already using Docker | Offer migration path |
| `.env`, `.env.example` | Environment variables | Auto-configure .gitignore rules |
| `README.md` | Documentation | Scan for tech stack keywords |
| `.git/` | Version control | Git already initialized |

**What auto-detection achieves:**
- Reduces questions by 50-70%
- Shows intelligence ("I already understand your project")
- Only asks about gaps in knowledge
- Builds user confidence

**Example auto-detection output:**
```
Detected from project files:
 Node.js 22.x (from package.json: "engines")
 TypeScript (tsconfig.json present)
 React 18 (package.json dependency)
 Environment variables (.env.example found)
 Git initialized

Still need to know:
- Database requirements
- Team size (for prebuild recommendation)
```

---

#### When Auto-Detection Finds Nothing

**Scenario**: Empty directory, brand new project, only `.git/` or `README.md` present

**What this means**:
- No language-specific files detected (no package.json, requirements.txt, etc.)
- No existing configuration (docker-compose.yml, Dockerfile)
- User is starting from scratch

**AI Assistant Response Strategy**:

Do NOT say:
- "I couldn't find anything in your project"
- "Your project appears empty"
- "No files detected"

Instead, frame positively:
- "Starting a brand new project - perfect! I'll help you set up the ideal devcontainer."
- "Creating a fresh devcontainer from scratch."
- "Let's build your development environment together."

**Adjusted Discovery Flow for Empty Projects**:

1. **Skip auto-detection summary** (nothing to show - don't announce "found nothing")
2. **Ask expertise level** (still required - same as always)
3. **ALWAYS ask project type** (Priority 1 - cannot be inferred)
 - This is now a REQUIRED question (even for experts)
 - No way to detect without files
4. **Ask database/services** (as normal)
5. **Skip team size question** (assume solo for new projects)
6. **Present config summary** (as normal)

**Example - Empty Project Discovery**:

```
AI: [Scans directory - finds only .git/ directory]

AI: "I'm setting up a devcontainer for your project.

Before I create your devcontainer, what's your experience level?

1) New to devcontainers (I'll explain everything step-by-step)
2) Some experience (brief explanations, focus on decisions)
3) Expert (minimal questions, just show me the config)

[Press Enter for option 1 - New to devcontainers]"

User: 1

AI: "Great! Since you're starting fresh, I'll guide you through this.

**Question 1 of 3:**
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) API or backend service (Node.js, Python, Go)
4) Mobile app backend
5) Other: _____

Why it matters: This determines what programming language tools I'll install
in your container (like installing Microsoft Word for writing documents).

[Press Enter for option 1 - Website/web app]"

User: [Enter]

AI: "Perfect! Node.js is great for websites.

**Question 2 of 3:**
Does your project need a database to store data permanently?

What a database does: Stores info like user accounts, posts, etc.

1) No database needed
2) Yes - PostgreSQL (recommended for beginners)

[Press Enter for: No database]"

[Continue with standard flow...]
```

**Key Differences from Existing Project Flow**:

| Aspect | Existing Project | Empty/New Project |
|--------|-----------------|-------------------|
| **Auto-detection summary** | Show detected stack | Skip (don't show "nothing found") |
| **Project type question** | Optional (if detected) | **REQUIRED** (cannot detect) |
| **Tone** | "Detected X, confirm?" | "What are you building?" |
| **Team size question** | Ask if professional indicators | Skip (assume solo) |
| **Confidence level** | Confirm existing setup | Guide from ground zero |
| **Question count** | 2-3 (many skipped) | 3-4 (must ask basics) |

---

#### Auto-Detection Decision Matrix

**Use this decision tree after scanning:**

```
Step 1: Scan project directory
 ↓
Found package.json/requirements.txt/go.mod/Cargo.toml?
 ↓
 ┌────┴────┐
 ↓ ↓
 YES NO
 │ │
 ↓ ↓
Show Skip
detection detection
summary summary
 │ │
 ↓ ↓
Ask Ask
expertise expertise
 │ │
 ↓ ↓
Confirm MUST ASK
detection? project
(may skip type
 if certain) (required)
 │ │
 ↓ ↓
Ask Ask
database database
 │ │
 ↓ ↓
Ask team Skip team
(if prof (assume
 signals) solo)
 │ │
 └────┬────┘
 ↓
 Show config
 summary
```

**Smart Defaults for Empty Projects**:

When user presses Enter or says "not sure" on empty projects:

| Question | Default | Rationale |
|----------|---------|-----------|
| **Project type** | Node.js (Website/web app) | Most popular for web development, beginner-friendly |
| **Database** | None | Keeps initial setup simple, can add later |
| **Services** | None | Start simple, add complexity as needed |
| **Team size** | Solo | Safe assumption for brand new projects |
| **Security** | Basic (.gitignore rules) | Always protect secrets, even solo |
| **Optimization** | Standard | No performance issues yet |

**Why "None" for database on empty projects**:
- Easier to learn one thing at a time
- Can add database later (migration guide available)
- Reduces initial complexity
- Faster first build (no Compose setup)

---

### Step 2: Expertise Gating (Single Required Question)

**This one question determines ALL subsequent interaction verbosity:**

**Always ask this first:**
```
Before I create your devcontainer, what's your experience level?

1) New to devcontainers (I'll explain everything step-by-step)
2) Some experience (brief explanations, focus on decisions)
3) Expert (minimal questions, just show me the config)

[Press Enter for option 1 - New to devcontainers]
```

**How expertise level affects responses:**

| Expertise | Question Format | Explanations | Default Behavior |
|-----------|----------------|--------------|------------------|
| **Beginner** | Full sentences, examples | "What it is", "Why it matters" | Show defaults, explain impact |
| **Intermediate** | Concise, numbered options | Brief context only | Show defaults, skip basics |
| **Expert** | Shorthand, Y/n prompts | None (assume knowledge) | Immediate config preview |

**Example - Same question, three expertise levels:**

**Beginner:**
```
Does your project need a database to store data permanently?

What a database does: Stores information (like user accounts, blog posts,
product listings) even when your app restarts. Think of it as a filing
cabinet for your app's data.

Common options:
1) No database needed (simple app, just displays info)
2) PostgreSQL (recommended for beginners - powerful and beginner-friendly)
3) MySQL (also popular, similar to PostgreSQL)
4) MongoDB (for flexible data that doesn't fit neat tables)
5) Other: _____

[Press Enter for option 1 - No database]
```

**Intermediate:**
```
Database requirements?

1) None
2) PostgreSQL (recommended for relational data)
3) MySQL
4) MongoDB (NoSQL)
5) Other: _____

[Default: None]
```

**Expert:**
```
DB: postgres/mysql/mongo/redis/none? [none]
```

---

### Step 3: Smart Context Questions (2-3 Questions Maximum)

**Only ask what auto-detection didn't find. Prioritize by importance:**

#### Priority 1: Project Type (if not detected)

**When to ask**: No package.json, requirements.txt, go.mod, or Cargo.toml found

**Beginner format:**
```
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) API or backend service (Node.js, Python, Go)
4) Mobile app backend
5) Other: _____

Why it matters: This determines what programming language tools I'll install
in your container (like installing Microsoft Word for writing documents).

[Press Enter for option 1 - Website/web app]
```

**Expert format:**
```
Stack: 1) Node 2) Python 3) Go 4) Rust 5) Other [1]
```

---

#### Priority 2: Services/Database (if not in docker-compose.yml)

**When to ask**: Always ask unless docker-compose.yml already defines services

**Beginner format:**
```
Does your project need a database or other services?

What this means: Services are helper programs that run alongside your app:
- Database: Stores data permanently (PostgreSQL, MySQL)
- Cache: Speeds up your app (Redis)
- Message Queue: Handles background tasks (RabbitMQ)

Options:
1) No services needed (app works standalone)
2) Database only - PostgreSQL (recommended)
3) Database only - MySQL
4) Database + Redis cache
5) Custom setup (I'll ask more details)

[Press Enter for option 1 - No services]
```

**Intermediate format:**
```
Services needed?
1) None
2) PostgreSQL
3) MySQL
4) PostgreSQL + Redis
5) Custom

Note: Selecting services creates Docker Compose configuration.
[Default: None]
```

**Expert format:**
```
Services: [none]
(postgres, mysql, mongo, redis, rabbitmq, or comma-separated)
```

**Smart follow-up (only if database selected):**
```
[Beginner only]
I'll set up Docker Compose to run your app + database together.
This means:
 Database starts automatically with your container
 Data persists even when you stop the container
 Pre-configured connection (just use: postgresql://localhost:5432)

Sound good? [Y/n]
```

---

#### Priority 3: Team Context (conditional)

**When to ask**: Only if project appears to be professional (has tests, CI files, multiple contributors in git log)

**Skip for**: Learning projects, simple apps, solo experiments

**Beginner format:**
```
Who will be using this devcontainer?

1) Just me (solo project, personal learning)
2) Small team (2-5 people working together)
3) Large team (6+ people)

Why it matters:
- Solo: Simple, fast setup
- Small team: I'll configure it so everyone gets the exact same environment
 (no more "works on my machine" problems!)
- Large team: I'll recommend "prebuilds" - a way to make the container start
 in 2 minutes instead of 15 minutes for your teammates

[Press Enter for option 1 - Just me]
```

**Intermediate format:**
```
Team size?
1) Solo
2) Small team (2-5) - shared config
3) Large team (6+) - recommend prebuilds

[Default: Solo]
```

**Expert format:**
```
Team size for prebuild recommendation? [1]
```

---

### Step 4: Adaptive Follow-ups (Only When Needed)

**These questions ONLY appear in specific contexts:**

#### If Large Team (Size > 5)

**Intermediate/Expert only:**
```
Large team detected. Recommend prebuild strategy?

Benefits:
- Developers start coding in ~2 minutes (vs 15+ minutes)
- Requires CI/CD (GitHub Actions, Azure DevOps)
- Builds image automatically on .devcontainer/ changes

Include prebuild configuration? [Y/n]
```

---

#### If .env File Detected

**All levels, but verbosity varies:**

**Beginner:**
```
I found a .env file - this might contain secrets like API keys or passwords.

I'll help protect these by:
1. Creating .env.example (template without real secrets)
2. Adding .env to .gitignore (prevents committing secrets to Git)
3. Adding instructions for your team to copy .env.example → .env

This keeps your secrets safe and off the internet. Sound good? [Y/n]
```

**Expert:**
```
.env detected. Add .env.example + .gitignore rules? [Y]
```

---

#### If Low System Resources Detected

**Beginner only:**
```
I noticed your system has [8GB RAM / 12GB free disk space].

I'll optimize the container to use fewer resources:
 Smaller base image (node:22-slim instead of node:22)
 Better .dockerignore (excludes unnecessary files)
 Volume caching for dependencies

Trade-off: First build may take 2-3 minutes longer, but the container will
run faster and use less RAM/disk.

Optimize for your system? [Y/n]
```

---

### Step 5: Present Configuration for Approval

**Always show a summary before creating files:**

#### Beginner Format (Detailed)

```
 Devcontainer Configuration Summary

Based on your answers, I'll create:

**Container Setup:**
 Node.js 22 (latest stable version)
 TypeScript support (tsconfig detected)
 PostgreSQL 15 database (runs in separate container)

**Developer Tools:**
 Claude Code extension (AI coding assistant)
 ESLint (finds bugs in your code)
 Prettier (auto-formats code)
 Git (version control)

**Features:**
 Hot reload (changes appear instantly)
 Port forwarding (access app at localhost:3000)
 Volume persistence (settings saved between restarts)

**Files I'll create:**
- .devcontainer/devcontainer.json (container config)
- .devcontainer/docker-compose.yml (app + database setup)
- .dockerignore (speeds up builds)
- Updated .gitignore (protects secrets)

**Build Times:**
- First time: ~10-12 minutes (downloads and installs everything)
- Subsequent times: ~2 minutes (uses cached layers)

Ready to create your devcontainer? [Y/n/show-config]
(Type 'show-config' to see the actual JSON files first)
```

---

#### Intermediate Format (Concise)

```
Configuration:
- Node.js 22 + TypeScript
- PostgreSQL 15 (Docker Compose)
- Extensions: Claude Code, ESLint, Prettier
- Volume: claude-config persisted
- Ports: 3000 (app), 5432 (postgres)

Files: devcontainer.json, docker-compose.yml, .dockerignore
Build time: ~10 min (first), ~2 min (cached)

Create? [Y/n/show]
```

---

#### Expert Format (Minimal)

```
Config:
- node:22, postgres:15 (compose)
- Ports: 3000, 5432
- Extensions: anthropic.claude-code, dbaeumer.vscode-eslint

Create? [Y]
```

---

### Smart Defaults Reference

**Use these defaults when user presses Enter or says "not sure":**

| Question | Default | Rationale |
|----------|---------|-----------|
| **Expertise level** | Beginner | Safe to over-explain |
| **Project type** (if unknown) | Node.js | Most popular for web development |
| **Database** | None | Can add later, keeps setup simple |
| **Team size** | Solo | Most common for new devcontainers |
| **System optimization** | No | Standard images more reliable |
| **Prebuild** | No (unless team > 5) | Adds complexity for small teams |
| **Secret handling** | Yes (if .env exists) | Always protect secrets |

---

### Question Limits by Expertise

**Never exceed these question counts:**

- **Beginner**: Max 4 questions (expertise + 3 context)
- **Intermediate**: Max 3 questions (expertise + 2 context)
- **Expert**: Max 2 questions (expertise + 1 confirm)

**If you need more questions, you're doing it wrong.** Use better auto-detection or provide sensible defaults.

---

### Examples of GOOD vs BAD Questions

#### BAD Examples

**Asks detectable information:**
```
"What programming language is your project using?"
[When package.json exists in project directory]
```

**Too many options:**
```
"Which database: PostgreSQL, MySQL, MongoDB, MariaDB, SQLite,
CouchDB, Redis, Cassandra, Oracle, SQL Server, or other?"
```

**Asks before scanning:**
```
"Tell me about your project"
[Before running any auto-detection]
```

**No default provided:**
```
"What base image do you want?"
[Expects user to know Docker image names]
```

**Jargon without explanation (to beginners):**
```
"Configure OCI-compliant orchestration layer? [Y/n]"
```

---

#### GOOD Examples

**Confirms detection:**
```
"Detected Node.js 22 from package.json. Correct? [Y/n]"
```

**Limited options with default:**
```
"Database?
1) None 2) PostgreSQL 3) MySQL 4) Other: _____
[Press Enter for: None]"
```

**Shows what you know first:**
```
"I found package.json with Express and React dependencies.
Building a full-stack web app? [Y/n]"
```

**Beginner-appropriate:**
```
"Need a database to store data (like user accounts)?
1) No 2) Yes - PostgreSQL (recommended)
[Press Enter for: No]"
```

**Explains impact:**
```
"Team of 6+ developers.
Should I set up prebuilds? (Saves 10-15 min per person)
[Y/n]"
```

---

### Full Example Flows

#### Flow 1: Complete Beginner, New Project

```
AI: [Scans directory - finds nothing except .git]

AI: "Before I create your devcontainer, what's your experience level?

1) New to devcontainers (I'll explain everything)
2) Some experience
3) Expert

[Press Enter for option 1]"

User: [Enter]

AI: "Great! I'll guide you through this step-by-step.

**Question 1 of 3:**
What type of project are you building?

1) Website or web app (JavaScript/Node.js)
2) Data project or scripts (Python)
3) Other: _____

This tells me what programming tools to install.
[Press Enter for: Website/web app]"

User: [Enter]

AI: "Perfect! Node.js is great for websites.

**Question 2 of 3:**
Does your project need a database to store data permanently?

What a database does: Stores info like user accounts, posts, etc.

1) No database needed
2) Yes - PostgreSQL (recommended for beginners)

[Press Enter for: No database]"

User: 2

AI: "Excellent choice! PostgreSQL works great for most projects.

**Question 3 of 3:**
Who will use this devcontainer?

1) Just me
2) Small team (2-5 people)

[Press Enter for: Just me]"

User: [Enter]

AI: "Got it! Here's what I'll create:

 **Configuration Summary:**

**Container:**
 Node.js 22
 PostgreSQL 15 database

**Tools:**
 Claude Code (AI assistant)
 ESLint (finds bugs)
 Git

**What this means:**
- Your app and database run in isolated containers
- Everything's pre-installed - just start coding
- Settings persist between restarts

**Build time:** ~10 minutes first time, ~2 minutes later

Create this devcontainer? [Y/n]"

User: Y

AI: [Creates files, shows progress]

AI: " Done! Your devcontainer is ready.

**Next steps:**
1. VS Code will prompt to 'Reopen in Container' - click it
2. Wait ~10 minutes for first build (grab coffee )
3. Once ready, your terminal will open inside the container
4. Test: Type 'node --version' to verify Node.js is installed

**Database connection:**
- Host: localhost
- Port: 5432
- User: postgres
- Password: postgres
- Database: devdb

Need help getting started? Just ask!"
```

**Total questions: 3 (expertise + project type + database)**

---

#### Flow 2: Intermediate User, Existing Project

```
AI: [Scans directory]
Found:
- package.json (Node.js 18.x, Express 4.x)
- tsconfig.json (TypeScript)
- .env.example

AI: "Experience level?
1) Beginner 2) Intermediate 3) Expert
[1]"

User: 2

AI: "Detected: Node.js 18 + TypeScript + Express
Correct? [Y/n]"

User: Y

AI: "Database needed?
1) None 2) PostgreSQL 3) MySQL
[None]"

User: 1

AI: "Config:
- Node.js 18 + TypeScript + Express
- No database
- Extensions: Claude Code, ESLint, Prettier
- .env.example detected - will add .gitignore rules

Create? [Y/n]"

User: Y

AI: [Creates files]

" Complete. Run: Cmd+Shift+P → 'Reopen in Container'"
```

**Total questions: 3 (expertise + confirm + database)**

---

#### Flow 3: Expert, Existing Docker Compose

```
AI: [Scans directory]
Found:
- package.json (Node 22, Next.js 14)
- docker-compose.yml (app, postgres, redis services)

AI: "Expertise: [1/2/3]"

User: 3

AI: "Detected stack:
- Next.js 14
- PostgreSQL 15 (compose)
- Redis 7 (compose)

Use existing docker-compose.yml? [Y]"

User: Y

AI: "Generated devcontainer.json:

\`\`\`json
{
 "name": "Next.js App",
 "dockerComposeFile": "docker-compose.yml",
 "service": "app",
 "workspaceFolder": "/workspace",
 "customizations": {
 "vscode": {
 "extensions": ["anthropic.claude-code", "bradlc.vscode-tailwindcss"]
 }
 }
}
\`\`\`

Write? [Y]"

User: Y

AI: "Done."
```

**Total questions: 2 (expertise + confirm)**

---

### Implementation Checklist for AI Assistants

Before responding to "Create a devcontainer", verify:

- [ ] Scanned project directory (auto-detection complete)
- [ ] Asked expertise level (gates verbosity)
- [ ] Limited to max questions (4 beginner / 3 intermediate / 2 expert)
- [ ] Provided defaults for every question
- [ ] Showed configuration summary before creating
- [ ] Adapted language to expertise level
- [ ] Only asked what auto-detection couldn't find
- [ ] Included "why it matters" for beginners
- [ ] Gave examples for unclear options
- [ ] Used numbered options (easy to select)

---

### When to Skip the Protocol

**Skip discovery questions and create immediately if:**

1. User provides explicit, complete requirements:
 ```
 "Create a devcontainer with Node 22, PostgreSQL 15, Redis,
 and configure for a team of 10"
 ```

2. User references existing configuration:
 ```
 "Convert my Dockerfile to a devcontainer"
 ```

3. User is migrating from a tutorial/template:
 ```
 "Use the official Python devcontainer template"
 ```

**In these cases:**
- Acknowledge the requirements
- Show what you'll create (summary)
- Create immediately (no questions)

---

### Summary: The Adaptive Discovery Flow

```
┌─────────────────────────────────┐
│ Step 1: Auto-Detect Project │
│ (Silent - scans files) │
└───────────┬─────────────────────┘
 │
 ▼
┌─────────────────────────────────┐
│ Step 2: Expertise Gating │
│ (1 question - determines tone) │
└───────────┬─────────────────────┘
 │
 ├──────────┬──────────────┐
 ▼ ▼ ▼
 Beginner Intermediate Expert
 (explain all) (brief context) (minimal)
 │ │ │
 └──────────┴──────────────┘
 │
 ▼
┌─────────────────────────────────┐
│ Step 3: Fill Knowledge Gaps │
│ (2-3 questions max) │
│ - Project type (if unknown) │
│ - Services (database, etc.) │
│ - Team size (conditional) │
└───────────┬─────────────────────┘
 │
 ▼
┌─────────────────────────────────┐
│ Step 4: Adaptive Follow-ups │
│ (Only if needed) │
│ - Prebuilds (large team) │
│ - Security (.env handling) │
│ - Optimization (low resources) │
└───────────┬─────────────────────┘
 │
 ▼
┌─────────────────────────────────┐
│ Step 5: Present & Confirm │
│ (Show config summary) │
│ - Beginner: Detailed │
│ - Intermediate: Concise │
│ - Expert: Minimal │
└───────────┬─────────────────────┘
 │
 ▼
 Create!
```

---

### Creating Devcontainers

**User Request**: "Create a devcontainer for [technology/stack]"

**IMPORTANT**: Follow the [AI Assistant Discovery Protocol](#ai-assistant-discovery-protocol) before creating. DO NOT immediately create files - ask context-gathering questions first unless user provides explicit complete requirements.

**AI Prompt Template (After Discovery Protocol)**:
```
Based on our conversation, I'll create a devcontainer with:

[Show configuration summary - adapt detail level to expertise]

**For Beginners:**
 Configuration Summary:
- [Language/framework + version]
- [Services if any]
- [Extensions: Claude Code + relevant tools]
- Build time: ~X minutes first time, ~2 minutes later

**For Intermediate:**
Config:
- [Stack]
- [Services]
- Extensions: [list]

**For Experts:**
[Stack], [services if any]
Proceed? [Y]

[After approval, create files]
```

**Discovery Protocol Checklist** (Use before creating):
1. Auto-detect project files (package.json, requirements.txt, etc.)
2. Ask expertise level (beginner/intermediate/expert)
3. Confirm detected stack or ask project type
4. Ask about services/database (if not in docker-compose.yml)
5. Ask team size (conditional - if appears professional)
6. Show configuration summary
7. Get approval before creating files

**Common Stacks** (Reference for Recommended Configs):
- **Node.js/TypeScript**: `node:22` + eslint, prettier, Claude Code
- **Python**: `python:3.11-slim` + pylint, black, ipykernel
- **Full-stack**: Docker Compose with app + database + cache
- **Go**: `golang:1.21` + delve debugger
- **Rust**: `rust:1.75` + rust-analyzer

**When to Skip Protocol** (Create Immediately):
- User provides complete requirements: "Create devcontainer with Node 22, PostgreSQL, Redis for team of 10"
- User references template: "Use official Python devcontainer template"
- Migration scenario: "Convert my Dockerfile to devcontainer"

---

### Debugging Devcontainers

**User Request**: "My devcontainer won't start/build"

**AI Prompt Template**:
```
Let me help debug this. I'll check:
1. Build logs for errors
2. devcontainer.json syntax
3. Dockerfile issues
4. Docker daemon status
5. Resource constraints

First, let me see your devcontainer.json...
```

**Quick Diagnostic Commands**:
```bash
# Check Docker daemon
docker ps

# View build logs
docker build .devcontainer -f .devcontainer/Dockerfile

# Check disk space
docker system df

# Rebuild container
Cmd+Shift+P → "Dev Containers: Rebuild Container"
```

---

### Optimizing Performance

**User Request**: "My devcontainer is slow"

**AI Prompt Template**:
```
I'll optimize your devcontainer performance by:
1. Enabling build cache layers
2. Using volume mounts instead of bind mounts
3. Optimizing lifecycle hooks
4. Configuring platform-specific settings

Let me analyze your current setup...
```

**Optimization Checklist**:
- [ ] Use `.dockerignore` to exclude `node_modules/`, `.git/`
- [ ] Multi-stage Dockerfile with cached layers
- [ ] Named volumes for `node_modules/`, `.npm/`
- [ ] VirtioFS on macOS (Docker Desktop → Experimental)
- [ ] WSL2 filesystem on Windows (not `/mnt/c/`)
- [ ] `postCreateCommand` runs in background (`&`)

---

### Adding MCP Servers

**User Request**: "Add [MCP server name] to my devcontainer"

**AI Prompt Template**:
```
I'll add the [MCP server] to your devcontainer. This involves:
1. Installing dependencies (if stdio transport)
2. Configuring mcp.json
3. Setting up volume persistence
4. Verifying connectivity

Let me update your configuration...
```

**Common MCP Servers**:
```json
{
 "mcpServers": {
 "context7": {
 "transport": {"type": "sse", "url": "https://mcp.context7.com/sse"}
 },
 "cf-docs": {
 "transport": {"type": "sse", "url": "https://docs.mcp.cloudflare.com/sse"}
 },
 "chrome-devtools": {
 "command": "npx",
 "args": [
   "-y",
   "chrome-devtools-mcp@latest",
   "--executablePath=/usr/bin/chromium",
   "--headless",
   "--chromeArg=--no-sandbox",
   "--chromeArg=--disable-setuid-sandbox",
   "--chromeArg=--disable-dev-shm-usage"
 ],
 "transport": {"type": "stdio"}
 }
 }
}
```

---

### Security Configuration

**User Request**: "Make my devcontainer more secure"

**AI Prompt Template**:
```
I'll enhance your devcontainer security by:
1. Running as non-root user
2. Dropping unnecessary capabilities
3. Configuring firewall rules
4. Isolating volumes
5. Using read-only mounts where possible

Let me update your configuration...
```

**Security Hardening**:
```json
{
 "remoteUser": "node",
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_BIND_SERVICE",
 "--security-opt=no-new-privileges"
 ],
 "mounts": [
 "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
 ]
}
```

---

### Migration to Devcontainers

**User Request**: "Convert my existing project to use devcontainers"

**AI Prompt Template**:
```
I'll migrate your project to devcontainers. This involves:
1. Analyzing your current setup (package.json, requirements.txt, etc.)
2. Choosing appropriate base image
3. Creating .devcontainer/ directory
4. Migrating environment variables
5. Testing the migration

Let me start by examining your project files...
```

**Migration Steps**:
1. Identify language/framework → choose base image
2. List tools installed globally → add to Dockerfile
3. Find env vars (`.env`) → add to `containerEnv`
4. Identify VS Code extensions → add to `customizations.vscode.extensions`
5. Create lifecycle hooks for `npm install`, `pip install`, etc.

---

### Validation and Troubleshooting

**User Request**: "Verify my devcontainer configuration is correct"

**AI Prompt Template**:
```
I'll validate your devcontainer configuration by checking:
1. JSON syntax in devcontainer.json
2. Required properties (image/build, name)
3. Dockerfile best practices
4. Port conflicts
5. Volume mount paths

Let me review your files...
```

**Validation Checklist**:
```bash
# Validate JSON syntax
jq . .devcontainer/devcontainer.json

# Test Dockerfile builds
docker build .devcontainer -f .devcontainer/Dockerfile

# Check for port conflicts
docker ps --format "table {{.Names}}\t{{.Ports}}"

# Verify VS Code extensions exist
code --list-extensions | grep "anthropic.claude-code"
```

---

### Quick Fixes for Common Errors

**Error**: `"Cannot connect to Docker daemon"`
**AI Response**:
```
This means Docker Desktop isn't running. Please:
1. Start Docker Desktop
2. Wait for it to fully start (green whale icon)
3. Retry: Cmd+Shift+P → "Dev Containers: Rebuild Container"
```

**Error**: `"No such file or directory: .devcontainer/devcontainer.json"`
**AI Response**:
```
The .devcontainer/ directory doesn't exist. I'll create it for you:
mkdir -p .devcontainer && cd .devcontainer
Then I'll create a basic devcontainer.json...
```

**Error**: `"ERROR: failed to solve: python:3.11-slim: not found"`
**AI Response**:
```
The base image tag is incorrect. Let me check Docker Hub for valid tags:
- python:3.11-slim
- python:3.11-alpine
- python:3.11

I'll update your Dockerfile with the correct tag...
```

**Error**: `"EACCES: permission denied, open '/workspaces/...'" `
**AI Response**:
```
This is a file permission issue. I'll fix it by:
1. Setting correct UID/GID in Dockerfile
2. Using remoteUser: "node" (not root)
3. Ensuring volume mounts have correct permissions

Let me update your configuration...
```

---

### Sources

- **VS Code Dev Containers CLI**: https://code.visualstudio.com/docs/devcontainers/devcontainer-cli
- **Common Errors**: https://code.visualstudio.com/docs/devcontainers/troubleshooting
- **Best Practices**: https://code.visualstudio.com/docs/devcontainers/dev best-practices

---

## Common Stack Examples

> Copy-paste these as starting points for common development stacks.

### Example 1: React + Next.js + TypeScript

**devcontainer.json**:
```json
{
 "name": "Next.js Dev",
 "build": {"dockerfile": "Dockerfile"},
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code",
 "dbaeumer.vscode-eslint",
 "esbenp.prettier-vscode",
 "bradlc.vscode-tailwindcss"
 ]
 }
 },
 "forwardPorts": [3000],
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest && npm install",
 "remoteUser": "node",
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
 "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume",
 "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume"
 ]
}
```

**Dockerfile**:
```dockerfile
FROM node:22
RUN apt-get update && apt-get install -y git && apt-get clean
USER node
# Claude Code installed via postCreateCommand (after npm-global volume mounts)
WORKDIR /workspaces
```

### Example 2: Python Data Science (Jupyter, pandas, numpy)

**devcontainer.json**:
```json
{
 "name": "Python Data Science",
 "build": {"dockerfile": "Dockerfile"},
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code",
 "ms-python.python",
 "ms-python.vscode-pylance",
 "ms-python.debugpy",
 "ms-toolsai.jupyter"
 ]
 }
 },
 "forwardPorts": [8888],
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest && pip install -r requirements.txt",
 "remoteUser": "vscode",
 "mounts": [
 "source=claude-${devcontainerId},target=/home/vscode/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/vscode/.config/gh,type=volume",
 "source=npm-global-${devcontainerId},target=/home/vscode/.npm-global,type=volume"
 ]
}
```

**Dockerfile**:
```dockerfile
FROM python:3.11-slim
RUN apt-get update && apt-get install -y git curl && apt-get clean
RUN useradd -m -s /bin/bash vscode
USER vscode
RUN pip install --user jupyterlab pandas numpy matplotlib
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
 apt-get install -y nodejs
# Claude Code installed via postCreateCommand (after npm-global volume mounts)
ENV NPM_CONFIG_PREFIX=/home/vscode/.npm-global
ENV PATH=$PATH:/home/vscode/.npm-global/bin
WORKDIR /workspaces
```

### Example 3: Full-Stack (Node.js + PostgreSQL)

See [Multi-Container Patterns](#multi-container-patterns-docker-compose) for Docker Compose setup.

### Example 4: Go + Protobuf

**devcontainer.json**:
```json
{
 "name": "Go Development",
 "build": {"dockerfile": "Dockerfile"},
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code",
 "golang.go"
 ],
 "settings": {
 "go.useLanguageServer": true
 }
 }
 },
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest",
 "remoteUser": "vscode",
 "mounts": [
 "source=claude-${devcontainerId},target=/home/vscode/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/vscode/.config/gh,type=volume",
 "source=npm-global-${devcontainerId},target=/home/vscode/.npm-global,type=volume",
 "source=go-pkg-${devcontainerId},target=/go/pkg,type=volume"
 ]
}
```

**Dockerfile**:
```dockerfile
FROM golang:1.21
RUN apt-get update && apt-get install -y git curl nodejs npm && apt-get clean
RUN useradd -m -s /bin/bash vscode && \
 mkdir -p /go && chown vscode:vscode /go
USER vscode
# Claude Code installed via postCreateCommand (after npm-global volume mounts)
ENV NPM_CONFIG_PREFIX=/home/vscode/.npm-global
ENV PATH=$PATH:/home/vscode/.npm-global/bin
ENV GOPATH=/go
WORKDIR /workspaces
```

---

## Step-by-Step: Creating a Devcontainer

> **AI Assistant Guidance**: When helping users create devcontainers, follow this comprehensive guide including essential configuration files that are often overlooked but critical for performance and security.

This section walks through creating a devcontainer from scratch, with emphasis on proper configuration files that optimize build performance and prevent common pitfalls.

### Quick Overview

**Typical workflow**:
1. Create `.devcontainer/` directory
2. Add essential configuration files (`.dockerignore`, `.gitignore` updates)
3. Create `devcontainer.json`
4. Create `Dockerfile` (or use base image)
5. Test and iterate

**Time to complete**: 10-30 minutes depending on complexity

---

### Essential Configuration Files

Before creating your devcontainer configuration, set up these critical files that dramatically improve build performance, reduce image size, and prevent security issues.

#### .dockerignore - Build Performance & Security

**Purpose**: Excludes files from Docker build context, improving:
- **Build Speed**: Smaller context = faster uploads to Docker daemon
- **Image Size**: Prevents accidental inclusion of large files
- **Security**: Blocks secrets/credentials from entering images
- **Cache Efficiency**: Reduces layer invalidation

**Location**: Project root (same directory as `docker-compose.yml` or where you run `docker build`)

**How it works**: Similar to `.gitignore`, uses glob patterns to exclude files when building Docker images.

---

##### .dockerignore - Node.js/TypeScript Projects

**.dockerignore**:
```
# Dependencies (will be installed in container)
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*
.npm/
.yarn/
.pnp.*

# Testing
coverage/
.nyc_output/
*.lcov

# Build outputs
dist/
build/
out/
.next/
.nuxt/
.cache/

# Environment variables (secrets!)
.env
.env.local
.env.*.local
*.env

# Version control
.git/
.gitignore
.gitattributes

# IDE & Editor
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# CI/CD
.github/
.gitlab-ci.yml
.travis.yml
Jenkinsfile

# Documentation
README.md
CHANGELOG.md
docs/
*.md

# Logs
logs/
*.log
npm-debug.log*

# OS files
.DS_Store
Thumbs.db
Desktop.ini
```

**Key patterns explained**:
- `node_modules/`: Heaviest directory, always rebuilt in container
- `.env*`: Prevents secrets leaking into images
- `.git/`: Large directory, not needed in container
- `dist/`, `build/`: Build outputs, regenerated in container
- `.vscode/`, `.idea/`: IDE configs, vary per developer

---

##### .dockerignore - Python Projects

**.dockerignore**:
```
# Virtual environments (recreated in container)
venv/
env/
ENV/
.venv/
.env/
*.virtualenv

# Python compiled files
__pycache__/
*.py[cod]
*$py.class
*.so
.Python

# Distribution / packaging
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Testing
.pytest_cache/
.tox/
.coverage
.coverage.*
.cache
htmlcov/
*.cover
.hypothesis/

# Jupyter Notebook
.ipynb_checkpoints/
*.ipynb_checkpoints

# Environment variables
.env
.env.*
*.env

# Version control
.git/
.gitignore

# IDE
.vscode/
.idea/
.spyderproject/
.spyproject/
.ropeproject/
*.swp

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Databases (use volumes instead)
*.db
*.sqlite
*.sqlite3

# Logs
*.log
pip-log.txt

# OS files
.DS_Store
Thumbs.db
```

**Key patterns explained**:
- `venv/`, `.venv/`: Virtual environments are container-specific
- `__pycache__/`, `*.pyc`: Compiled Python files, regenerated
- `.pytest_cache/`: Test cache, rebuilt in container
- `*.egg-info/`: Package metadata, recreated during install
- `.ipynb_checkpoints/`: Jupyter temp files, not needed

---

##### .dockerignore - Go Projects

**.dockerignore**:
```
# Binaries
*.exe
*.exe~
*.dll
*.so
*.dylib
bin/
dist/

# Build artifacts
*.test
*.out
/vendor/

# Go workspace
go.work
go.work.sum

# Coverage
*.coverprofile
coverage.txt
coverage.html
*.coverage

# IDE
.vscode/
.idea/
*.swp

# Environment
.env
.env.*

# Version control
.git/
.gitignore

# OS
.DS_Store
Thumbs.db

# Documentation
README.md
docs/
*.md

# CI/CD
.github/
.gitlab-ci.yml
```

**Key patterns explained**:
- `bin/`, `*.exe`: Compiled binaries, built for host OS (not container)
- `/vendor/`: Go dependencies, use `go mod download` in container
- `*.test`, `*.out`: Test binaries, regenerated
- `go.work`: Go workspace file, may conflict with container setup

---

##### .dockerignore - Universal/Multi-Language Projects

**.dockerignore** (comprehensive template for any project):
```
# ===========================
# Version Control
# ===========================
.git/
.gitignore
.gitattributes
.gitmodules
.hg/
.svn/

# ===========================
# CI/CD
# ===========================
.github/
.gitlab-ci.yml
.travis.yml
.circleci/
Jenkinsfile
azure-pipelines.yml
.drone.yml

# ===========================
# IDEs & Editors
# ===========================
.vscode/
.idea/
*.iml
.project
.classpath
.settings/
*.swp
*.swo
*~
.vs/
.vimrc.local

# ===========================
# OS Files
# ===========================
.DS_Store
Thumbs.db
Desktop.ini
$RECYCLE.BIN/
.Trash-*/

# ===========================
# Security (CRITICAL)
# ===========================
.env
.env.*
*.env
.env.local
.env.*.local
secrets/
secret.*
*.key
*.pem
*.crt
*.cer
*.p12
*.pfx
id_rsa*
*.asc
.aws/
.ssh/
credentials

# ===========================
# Dependencies (Language-specific)
# ===========================
# Node.js
node_modules/
.npm/
.yarn/
# Python
venv/
.venv/
__pycache__/
*.pyc
# Go
vendor/
# Ruby
.bundle/
# PHP
vendor/
# Rust
target/
# Java
.gradle/
.m2/

# ===========================
# Build Artifacts
# ===========================
dist/
build/
out/
bin/
*.exe
*.dll
*.so
*.dylib
*.jar
*.war
*.ear

# ===========================
# Logs & Temporary Files
# ===========================
logs/
*.log
*.log.*
tmp/
temp/
cache/
.cache/

# ===========================
# Testing & Coverage
# ===========================
coverage/
.coverage
htmlcov/
.nyc_output/
.pytest_cache/
.tox/

# ===========================
# Documentation
# ===========================
README.md
CHANGELOG.md
CONTRIBUTING.md
LICENSE
docs/
*.md

# ===========================
# Devcontainer-Specific
# ===========================
# Include these - needed for build!
!.devcontainer/
!.devcontainer/**

# ===========================
# Docker-in-Docker
# ===========================
.docker/
docker-compose.override.yml
```

**Critical security patterns**:
- `.env*`: Environment files may contain API keys, passwords
- `*.key`, `*.pem`: Private keys and certificates
- `.ssh/`: SSH keys
- `.aws/`: AWS credentials
- `secrets/`: Any secrets directory

**Performance patterns**:
- `node_modules/`: Can be 500MB+, slowest part of context copy
- `.git/`: Often 100MB+, not needed in image
- `dist/`, `build/`: Large build outputs, regenerated
- Documentation: `*.md`, `docs/` not needed at runtime

---

##### .dockerignore Best Practices

1. **Start Specific, Then Add Wildcards**
 ```
 # Good (specific)
 .env.local
 .env.development.local

 # Better (catches all)
 .env*
 ```

2. **Use Negative Patterns to Include Exceptions**
 ```
 # Exclude all markdown
 *.md

 # But include README in Docker image
 !README.md
 ```

3. **Order Matters** (first match wins)
 ```
 # Exclude all, then include specific
 secrets/*
 !secrets/public-cert.pem
 ```

4. **Test Your .dockerignore**
 ```bash
 # See what Docker will copy
 docker build --no-cache --progress=plain . 2>&1 | grep "COPY"

 # Or check context size
 docker build --no-cache . 2>&1 | grep "sending build context"
 ```

5. **Measure Impact**
 ```bash
 # Before adding .dockerignore
 time docker build .
 # => Sending build context: 2.3GB (60 seconds)

 # After optimized .dockerignore
 time docker build .
 # => Sending build context: 45MB (3 seconds)
 ```

---

#### .gitignore - Version Control for Devcontainers

**Purpose**: Controls what gets committed to version control. For devcontainers, this has special considerations.

**Location**: Project root

---

##### .gitignore - Devcontainer-Specific Patterns

**.gitignore** (additions for devcontainer projects):
```
# ===========================
# DO COMMIT (Important!)
# ===========================
# These should be committed for team collaboration
# .devcontainer/ ← NEVER ignore this!
# .devcontainer/*.json ← NEVER ignore configs!
# .devcontainer/Dockerfile ← NEVER ignore this!

# ===========================
# DO IGNORE (Personal Settings)
# ===========================
# Local overrides (personal preferences)
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
.devcontainer/docker-compose.override.yml

# User-specific VS Code settings
.vscode/settings.local.json

# Personal Claude Code settings (contains API keys!)
.claude/settings.local.json
.claude/cache/
.claude/logs/

# Personal MCP server configs (may contain tokens)
.claude/mcp.local.json

# ===========================
# Docker Build Artifacts
# ===========================
# Docker layer cache (if using local cache)
.devcontainer/.docker-cache/

# ===========================
# Volume Data (DO NOT COMMIT)
# ===========================
# Named volume contents (if accidentally created locally)
.docker-volumes/
volumes/

# Database data (use volumes instead)
postgres-data/
mysql-data/
redis-data/

# ===========================
# Standard Patterns
# ===========================
# Environment variables
.env
.env.local
.env.*.local

# Secrets
secrets/
*.key
*.pem

# OS
.DS_Store
Thumbs.db

# IDE
.vscode/*
!.vscode/extensions.json
!.vscode/settings.json
!.vscode/tasks.json
.idea/
```

---

##### .gitignore - Common Mistakes

** MISTAKE #1: Ignoring .devcontainer/ Entirely**
```
# WRONG - breaks team collaboration!
.devcontainer/
```

**Why it's wrong**: Team members won't get your devcontainer setup. The whole point is to share the environment.

** Correct approach**:
```
# Commit the configs
# (no ignore rule)

# Only ignore personal overrides
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
```

---

** MISTAKE #2: Committing Personal Settings**
```
# Missing from .gitignore
.claude/settings.local.json
```

**Why it's wrong**: Contains API keys, personal preferences, and credentials.

** Correct approach**:
```
# In .gitignore
.claude/settings.local.json
.claude/cache/
.claude/logs/

# In .devcontainer/
.claude/settings.json.template ← Commit this (template without secrets)
```

---

** MISTAKE #3: Ignoring Lock Files**
```
# WRONG
package-lock.json
yarn.lock
poetry.lock
Gemfile.lock
```

**Why it's wrong**: Lock files ensure reproducible builds. Without them, `npm install` might install different versions for different developers.

** Correct approach**:
```
# Commit lock files for reproducibility
# (no ignore rule needed)
```

---

##### .gitignore - Language-Specific Additions

**Node.js projects** (add to standard .gitignore):
```
# Dependencies
node_modules/

# Build outputs
dist/
build/

# Logs
npm-debug.log*
yarn-debug.log*
```

**Python projects** (add to standard .gitignore):
```
# Virtual environments
venv/
.venv/
env/

# Compiled Python
__pycache__/
*.pyc
*.pyo

# Distribution
dist/
*.egg-info/
```

**Go projects** (add to standard .gitignore):
```
# Binaries
bin/
*.exe

# Vendor (if using modules, don't commit vendor/)
vendor/

# Build artifacts
*.test
```

---

##### .gitignore Decision Tree

```
Is it a devcontainer config file?
├─ devcontainer.json, Dockerfile, docker-compose.yml
│ → COMMIT (team needs it)
│
├─ devcontainer.local.json, .env.local
│ → IGNORE (personal overrides)
│
└─ init scripts, setup.sh
 → COMMIT (part of automated setup)

Is it a personal setting or credential?
├─ .claude/settings.local.json, API keys, tokens
│ → IGNORE (sensitive data)
│
├─ .vscode/settings.json
│ → COMMIT (team workspace settings)
│
└─ .vscode/settings.local.json
 → IGNORE (personal preferences)

Is it generated by tools?
├─ node_modules/, venv/, __pycache__
│ → IGNORE (regenerated from lock files)
│
├─ package-lock.json, poetry.lock
│ → COMMIT (ensures reproducibility)
│
└─ dist/, build/, *.pyc
 → IGNORE (build artifacts)
```

---

### Step-by-Step Creation Process

Now that you understand essential configuration files, follow these steps to create a complete devcontainer.

#### Step 1: Create Directory Structure

```bash
# From project root
mkdir -p .devcontainer
cd .devcontainer
```

**Result**:
```
your-project/
├── .devcontainer/ ← New directory
└── [your existing files]
```

---

#### Step 2: Create .dockerignore (Project Root)

```bash
# Return to project root
cd ..

# Create .dockerignore based on your language
# (Use examples from "Essential Configuration Files" above)
```

**For Node.js**:
```bash
cat > .dockerignore << 'EOF'
node_modules/
.npm/
dist/
.env*
.git/
.vscode/
README.md
*.log
EOF
```

**For Python**:
```bash
cat > .dockerignore << 'EOF'
venv/
.venv/
__pycache__/
*.pyc
.env*
.git/
.vscode/
*.log
EOF
```

---

#### Step 3: Update .gitignore

```bash
# Add devcontainer-specific patterns
cat >> .gitignore << 'EOF'

# Devcontainer personal settings
.devcontainer/devcontainer.local.json
.devcontainer/.env.local
.claude/settings.local.json
.claude/cache/
.claude/logs/
EOF
```

**Verify .devcontainer/ is NOT ignored**:
```bash
# This should return nothing
grep "^\.devcontainer/$" .gitignore

# If it returns a match, remove that line!
```

---

#### Step 4: Create devcontainer.json

Choose your approach:

**Option A: Use Base Image (Fastest)**
```bash
cat > .devcontainer/devcontainer.json << 'EOF'
{
 "name": "My Dev Container",
 "image": "node:22",
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code"
 ]
 }
 },
 "postCreateCommand": "npm install",
 "remoteUser": "node",
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
EOF
```

**Option B: Use Dockerfile (Custom)**
```bash
cat > .devcontainer/devcontainer.json << 'EOF'
{
 "name": "My Dev Container",
 "build": {
 "dockerfile": "Dockerfile"
 },
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code"
 ]
 }
 },
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest && npm install",
 "remoteUser": "node",
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
 "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume"
 ]
}
EOF
```

---

#### Step 5: Create Dockerfile (If Using Option B)

```bash
cat > .devcontainer/Dockerfile << 'EOF'
FROM node:22

# Install system packages
RUN apt-get update && \
 apt-get install -y git curl && \
 apt-get clean && \
 rm -rf /var/lib/apt/lists/*

# Switch to non-root user
USER node

# Claude Code installed via postCreateCommand (after npm-global volume mounts)
ENV NPM_CONFIG_PREFIX=/home/node/.npm-global
ENV PATH=$PATH:/home/node/.npm-global/bin

WORKDIR /workspaces
EOF
```

---

#### Step 6: Validate Configuration

```bash
# Check JSON syntax
jq . .devcontainer/devcontainer.json

# Verify .dockerignore exists
ls -la .dockerignore

# Verify .devcontainer/ will be committed
git status .devcontainer/
# Should show: new file: .devcontainer/devcontainer.json
```

---

#### Step 7: Test the Devcontainer

**In VS Code**:
1. Open Command Palette: `Cmd+Shift+P` (Mac) / `Ctrl+Shift+P` (Windows/Linux)
2. Select: `Dev Containers: Reopen in Container`
3. Wait for build to complete (5-15 minutes first time)
4. Verify terminal opens inside container:
 ```bash
 # Check you're inside container
 hostname
 # => Should show container ID (e.g., a1b2c3d4e5f6)

 # Check Node version
 node --version
 # => Should show v20.x.x

 # Check Claude Code installed
 claude --version
 ```

---

#### Step 8: Commit Your Configuration

```bash
# Stage devcontainer files
git add .devcontainer/
git add .dockerignore
git add .gitignore

# Commit
git commit -m "Add devcontainer configuration

- Node.js 22 base image
- Claude Code pre-installed
- Optimized .dockerignore for build performance
- Updated .gitignore for devcontainer personal settings"

# Push to remote
git push
```

**Team members can now**:
```bash
git pull
code .
# Click "Reopen in Container"
# Start coding immediately!
```

---

### Validation Checklist

Before sharing with your team, verify:

- [ ] `.dockerignore` exists and excludes `node_modules/`, `.git/`, `dist/`
- [ ] `.gitignore` does NOT ignore `.devcontainer/` directory
- [ ] `.gitignore` DOES ignore `.claude/settings.local.json`
- [ ] `devcontainer.json` has valid JSON syntax
- [ ] `devcontainer.json` includes necessary VS Code extensions
- [ ] Container builds successfully (`docker build .devcontainer`)
- [ ] Container starts and you can open a terminal inside it
- [ ] Tools are accessible (e.g., `node --version`, `python --version`)
- [ ] Volumes persist data across rebuilds (test: create file, rebuild, check file exists)
- [ ] Port forwarding works (test: run dev server, access from host browser)

---

### Quick Troubleshooting

**Build is slow (>10 minutes)**:
- Check `.dockerignore` excludes `node_modules/`, `.git/`
- Verify Docker Desktop has sufficient resources (Settings → Resources)
- Use multi-stage Dockerfile to cache dependencies

**"Permission denied" errors**:
- Ensure `remoteUser` matches Dockerfile user (e.g., `"remoteUser": "node"`)
- Verify volume mounts target user's home directory (`/home/node`)

**.devcontainer/ changes not reflected**:
- Rebuild container: `Cmd+Shift+P` → `Dev Containers: Rebuild Container`
- Don't just "Reopen in Container" (uses cached image)

**API keys not working**:
- Check `.env` is NOT in `.dockerignore` (if needed during build)
- Use `containerEnv` or `remoteEnv` in `devcontainer.json` for runtime vars
- Ensure `.env.local` is in `.gitignore` (don't commit secrets!)

---

### Next Steps

Once your devcontainer is working:

1. **Add MCP servers**: See [MCP Server Setup](#mcp-server-setup)
2. **Optimize performance**: See [Resource and Performance Considerations](#resource-and-performance-considerations)
3. **Set up CI/CD**: See [Prebuild Images & CI/CD Automation](#prebuild-images--cicd-automation)
4. **Enhance security**: See [Security Best Practices](#security-best-practices)
5. **Create team template**: See [Creating & Distributing Templates](#creating--distributing-templates)

---

## Step-by-Step: Managing Devcontainers

## Lifecycle Hooks Explained

> **AI Assistant Guidance**: Understanding lifecycle hooks is critical for proper devcontainer configuration. Use this execution order diagram when helping users debug initialization issues.

**Official Documentation**: https://containers.dev/implementors/json_reference/#lifecycle-scripts

Development containers execute commands at specific lifecycle stages. Each hook serves a distinct purpose with different access levels and execution contexts.

### Execution Order Diagram

```
┌─────────────────────────────────────────────────────┐
│ LOCAL MACHINE │
│ ┌───────────────────────────────────────────────┐ │
│ │ 1. initializeCommand │ │
│ │ • Runs on host/local machine │ │
│ │ • Before container exists │ │
│ │ • Use: Prepare local files, download deps │ │
│ └───────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────┘
 ↓
┌─────────────────────────────────────────────────────┐
│ CONTAINER (First Start Only) │
│ ┌───────────────────────────────────────────────┐ │
│ │ 2. onCreateCommand │ │
│ │ • Runs after container creation │ │
│ │ • No access to user secrets │ │
│ │ • Use: Install system packages │ │
│ └───────────────────────────────────────────────┘ │
│ ↓ │
│ ┌───────────────────────────────────────────────┐ │
│ │ 3. updateContentCommand │ │
│ │ • Runs when workspace content updates │ │
│ │ • No access to user secrets │ │
│ │ • Use: Update dependencies (npm install) │ │
│ └───────────────────────────────────────────────┘ │
│ ↓ │
│ ┌───────────────────────────────────────────────┐ │
│ │ 4. postCreateCommand (waitFor default) │ │
│ │ • Runs after user assignment │ │
│ │ • HAS access to user secrets/assets │ │
│ │ • Runs in BACKGROUND by default │ │
│ │ • Use: Setup that needs credentials │ │
│ └───────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────┘
 ↓
┌─────────────────────────────────────────────────────┐
│ CONTAINER (Every Start) │
│ ┌───────────────────────────────────────────────┐ │
│ │ 5. postStartCommand │ │
│ │ • Runs EVERY time container starts │ │
│ │ • Use: Start services (docker-compose up) │ │
│ └───────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────┘
 ↓
┌─────────────────────────────────────────────────────┐
│ CONTAINER (Every Attach) │
│ ┌───────────────────────────────────────────────┐ │
│ │ 6. postAttachCommand │ │
│ │ • Runs every time tool attaches │ │
│ │ • Use: Display welcome message │ │
│ └───────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────┘
```

### Hook Details

#### 1. initializeCommand
**Location**: Local/host machine
**When**: Before container creation
**Access**: No container access
**Frequency**: Once per devcontainer configuration

**Use cases**:
- Pre-populate `node_modules/` on host before mounting
- Download large files to avoid container bloat
- Generate configuration files
- Validate prerequisites

**Example**:
```json
{
 "initializeCommand": "echo 'Preparing local workspace...' && npm install"
}
```

**Official Docs**: https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md#initializecommand

---

#### 2. onCreateCommand
**Location**: Inside container
**When**: After container creation (first start only)
**Access**: No user secrets or assets
**Frequency**: Once per container

**Use cases**:
- Install system packages (`apt-get install`)
- Clone git repositories
- Set up file permissions
- Initialize database schemas

**Example**:
```json
{
 "onCreateCommand": "apt-get update && apt-get install -y postgresql-client"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 3. updateContentCommand
**Location**: Inside container
**When**: When workspace content updates
**Access**: No user secrets
**Frequency**: On content changes

**Use cases**:
- Update dependencies (`npm install`, `pip install -r requirements.txt`)
- Rebuild assets
- Run database migrations

**Example**:
```json
{
 "updateContentCommand": "npm install && npm run build"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 4. postCreateCommand
**Location**: Inside container
**When**: After container assigned to user (first start)
**Access**: **Has access to user secrets, assets, and permissions**
**Execution**: Background by default (non-blocking)
**Frequency**: Once per container (after user assignment)

**Use cases**:
- Configure git with user credentials
- Set up SSH keys
- Initialize user-specific tools
- Run setup scripts requiring authentication

**Example**:
```json
{
 "postCreateCommand": "git config --global user.name 'Your Name' && ./setup.sh"
}
```

**Important**: This is the **default waitFor target**. VS Code waits for this to complete before showing "ready" status.

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 5. postStartCommand
**Location**: Inside container
**When**: **Every time** container starts
**Access**: Full container access
**Frequency**: Every start

**Use cases**:
- Start background services (`docker-compose up -d`)
- Mount network drives
- Refresh certificates
- Display startup messages

**Example**:
```json
{
 "postStartCommand": "docker-compose up -d database redis && echo 'Services started'"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

#### 6. postAttachCommand
**Location**: Inside container
**When**: Every time a tool attaches to container
**Access**: Full container access
**Frequency**: Every attach (e.g., opening VS Code)

**Use cases**:
- Display welcome message
- Check service health
- Log user sessions
- Trigger monitoring

**Example**:
```json
{
 "postAttachCommand": "echo 'Welcome! Container ready at http://localhost:3000'"
}
```

**Official Docs**: https://containers.dev/implementors/json_reference/#image-specific

---

### Command Syntax Options

All lifecycle hooks support three formats:

#### String (Shell Command)
Executed through a shell, supports pipes, redirection, etc.

```json
{
 "postStartCommand": "npm install && npm run build"
}
```

#### Array (Direct Command)
Passed directly to OS without shell interpretation (more secure, no globbing)

```json
{
 "postStartCommand": ["npm", "install"]
}
```

#### Object (Parallel Execution)
Multiple commands executed in parallel

```json
{
 "postStartCommand": {
 "install-deps": "npm install",
 "start-db": "docker-compose up -d database",
 "log-start": "echo 'Container started'"
 }
}
```

**Parallel execution** is useful for independent tasks (database start + npm install).

### Error Handling

**Cascading Failures**: If a lifecycle hook fails, subsequent hooks **will not execute**.

**Example**:
```
onCreateCommand fails
 ↓
updateContentCommand skipped ⏭️
 ↓
postCreateCommand skipped ⏭️
 ↓
postStartCommand skipped ⏭️
```

**Best practices**:
- Test hooks individually
- Use `set -e` in shell scripts to fail fast
- Log output for debugging
- Keep hooks idempotent (safe to run multiple times)

### Access to User Secrets Timeline

```
Hook | Has User Secrets?
─────────────────────────────────────────────
initializeCommand | (runs on host)
onCreateCommand |
updateContentCommand |
postCreateCommand | YES
postStartCommand | YES
postAttachCommand | YES
```

**Why this matters**: Only use `postCreateCommand` and later hooks for operations requiring:
- Git credentials
- SSH keys
- API tokens
- User-specific configuration

### waitFor Property

The `waitFor` property controls which lifecycle command VS Code waits for before considering the container "ready".

```json
{
 "waitFor": "postCreateCommand" // Default
}
```

**Options**:
- `"initializeCommand"`: Wait before container creation
- `"onCreateCommand"`: Wait after container creation
- `"updateContentCommand"`: Wait after content sync
- `"postCreateCommand"`: **Default** - wait after user assignment
- `"postStartCommand"`: Wait after container start
- `"postAttachCommand"`: Wait after tool attachment

**Use case**: If your `postCreateCommand` is slow (large npm install), users see "ready" status only after it completes.

### Common Patterns

#### Pattern 1: System Setup + Dependency Install
```json
{
 "onCreateCommand": "apt-get update && apt-get install -y build-essential",
 "updateContentCommand": "npm install",
 "postCreateCommand": "npm run setup-user-config"
}
```

#### Pattern 2: Background Services
```json
{
 "postStartCommand": {
 "start-postgres": "docker-compose up -d postgres",
 "start-redis": "docker-compose up -d redis",
 "wait-for-services": "wait-for-it.sh postgres:5432 redis:6379"
 }
}
```

#### Pattern 3: Multi-Language Project
```json
{
 "postCreateCommand": {
 "install-npm": "npm install",
 "install-python": "pip install -r requirements.txt",
 "install-go": "go mod download"
 }
}
```

### Debugging Lifecycle Hooks

**View execution logs**:
```bash
# Inside container
docker logs <container-id>

# Or from VS Code
# View → Output → Select "Dev Containers"
```

**Test individual hook**:
```bash
# Run command manually inside container
docker exec -it <container-id> bash
# Then run the command to test
```

**Common issues**:
- **Hook hangs**: Check for interactive prompts (use `-y` flags, `DEBIAN_FRONTEND=noninteractive`)
- **Hook fails silently**: Add logging (`echo "Step 1..."`)
- **Commands not found**: Check PATH in containerEnv
- **Permission denied**: Verify remoteUser has necessary permissions

### Sources
- **Lifecycle Scripts Reference**: https://containers.dev/implementors/json_reference/#lifecycle-scripts
- **Devcontainer Reference**: https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-reference.md#lifecycle-scripts
- **VS Code Lifecycle Docs**: https://code.visualstudio.com/docs/devcontainers/create-dev-container#_lifecycle-scripts
- **Issue Discussion**: https://github.com/devcontainers/spec/issues/477

---


---


### Opening an Existing Devcontainer

**Method 1: Automatic Prompt**
1. Open project in VS Code: `code /path/to/project`
2. Click **"Reopen in Container"** when prompted

**Method 2: Manual Command**
1. Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)
2. Type: **"Dev Containers: Reopen in Container"**

**Method 3: From Remote Window**
1. Click the green icon in bottom-left corner of VS Code
2. Select **"Reopen in Container"**

### Rebuilding After Configuration Changes

When you modify `.devcontainer/devcontainer.json` or `Dockerfile`:

1. Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)
2. Select: **"Dev Containers: Rebuild Container"**
3. Choose:
 - **"Rebuild"**: Preserves volumes (keeps API keys, configs)
 - **"Rebuild Without Cache"**: Fresh build (slower, but resolves caching issues)

**Best Practice**:
- Use **"Rebuild"** for config changes (faster, preserves state)
- Use **"Rebuild Without Cache"** if experiencing mysterious errors

### Accessing the Container Terminal

VS Code automatically opens terminals inside the container. You can also:

**From Host Machine**:
```bash
# Find container ID
docker ps

# Execute command in container
docker exec -it <container-id> bash

# Or by name
docker exec -it <container-name> bash
```

### Viewing Container Logs

```bash
# See build and startup logs
docker logs <container-id>

# Follow logs in real-time
docker logs -f <container-id>
```

### Stopping the Container

**Method 1**: Close VS Code window
**Method 2**: Command Palette → **"Dev Containers: Close Remote Connection"**
**Method 3**: Docker Desktop → Containers → Stop

Container stops automatically when VS Code disconnects.

### Removing the Container

```bash
# List all containers (including stopped)
docker ps -a

# Remove specific container
docker rm <container-id>

# Remove container and volumes (CAUTION: deletes API keys!)
docker rm -v <container-id>

# Or via Docker Desktop: Containers → Delete
```

### Managing Disk Space

Devcontainers accumulate over time:

```bash
# See disk usage breakdown
docker system df

# Remove stopped containers
docker container prune

# Remove unused images
docker image prune -a

# Remove unused volumes (CAUTION: may delete configs)
docker volume prune

# Nuclear option: remove ALL unused Docker resources
docker system prune -a --volumes
```

**️ Warning**: `docker system prune -a --volumes` removes **all** unused Docker resources. If you have other Docker projects, this affects them too.

**Safer Approach**:
```bash
# Remove only resources for this project
docker ps -a | grep "your-project-name" # Find container ID
docker rm <container-id>
docker volume ls | grep "your-project" # Find volumes
docker volume rm <volume-name>
```

---

## Multi-AI Configuration

Configure multiple AI assistants (Claude Code, OpenAI Codex, Google Gemini) in one container.

### Installing Multiple CLIs

**Dockerfile additions**:

```dockerfile
# Install Claude Code, Codex, Gemini
USER node
RUN npm install -g \
 @anthropic-ai/claude-code@latest \
 @openai/codex \
 @google/gemini-cli
```

### VS Code Extensions

**devcontainer.json additions**:

```json
{
 "customizations": {
 "vscode": {
 "extensions": [
 "anthropic.claude-code",
 "openai.chatgpt",
 "google.gemini-cli-vscode-ide-companion",
 "google.geminicodeassist",
 "github.copilot",
 "github.copilot-chat",
 "kilocode.kilo-code",
 "tamasfe.even-better-toml",
 "ms-toolsai.jupyter-keymap",
 "ms-vscode.sublime-keybindings",
 "grapecity.gc-excelviewer",
 "imgildev.vscode-json-flow",
 "redhat.vscode-yaml"
 ]
 }
 }
}
```

### Persistent Configurations (Critical!)

**Separate volumes for each AI** to prevent credential conflicts:

```json
{
 "mounts": [
 "source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=codex-config-${devcontainerId},target=/home/node/.codex,type=volume",
 "source=gemini-config-${devcontainerId},target=/home/node/.gemini,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

**Why separate volumes?**
- Each AI stores API keys in its config directory
- Rebuilding container doesn't lose credentials
- Different projects can have different API keys
- Credential isolation improves security

### API Key Configuration

**Method 1: .env File (Recommended)** ⭐

Create `.env` in project root:

```bash
cp .env.example .env
# Edit and add: GEMINI_API_KEY=your_key_here
```

Benefits:
- Per-project credentials (different keys for different containers)
- Git-ignored by default (secure)
- Standard devcontainer practice
- Loaded automatically on container start via `--env-file` in devcontainer.json

**Method 2: Settings File**

```bash
mkdir -p ~/.gemini
echo '{"apiKey": "YOUR_KEY"}' > ~/.gemini/settings.json
```

**Method 3: Environment Variable**

```bash
export GEMINI_API_KEY=YOUR_KEY  # Add to .bashrc/.zshrc for persistence
```

⚠️ **Security**: Always ensure .env is in .gitignore before adding real API keys.

Get your API key: https://makersuite.google.com/app/apikey

### Verifying Multi-AI Setup

```bash
# Inside container
claude --version
codex --version
gemini --version

# Check config directories exist
ls -la ~/.claude ~/.codex ~/.gemini ~/.config/gh
```

### Claude Code Performance Optimization for Devcontainers

> **AI Assistant Guidance**: For devcontainer environments (trusted, isolated), recommend enabling these performance flags to dramatically improve Claude Code's development speed.

**Why optimize for devcontainers?**
- Devcontainers are **isolated** from host system (limited damage potential)
- Network firewall restricts outbound connections with IPv6 disabled (controlled security boundary)
- All tool executions are **auditable** via logs and telemetry
- Environment is **disposable** (can rebuild anytime if issues occur)
- Running as non-root user limits impact
- **Result**: Safe to skip permission prompts for faster development

#### Recommended Settings for Devcontainers

Add to `~/.claude/settings.json` or `.devcontainer/settings.json.template`:

```json
{
 "$schema": "https://json.schemastore.org/claude-code-settings.json",
 "dangerously_skip_permissions": true,
 "verbose": true,
 "env": {
 "MAX_MCP_OUTPUT_TOKENS": "60000",
 "BASH_DEFAULT_TIMEOUT_MS": "300000",
 "BASH_MAX_TIMEOUT_MS": "600000",
 "MAX_THINKING_TOKENS": "8192"
 }
}
```

#### Flag Explanations

**`dangerously_skip_permissions: true`**
- **What**: Skips user confirmation prompts before executing tools (Bash, Read, Write, etc.)
- **Why**: Eliminates delays waiting for permission confirmation
- **Effect**: Claude Code executes tools immediately without prompts
- **Speed Improvement**: 50-80% faster responses (no prompt delays)
- **Safe when**: Running in isolated devcontainer with network restrictions
- ️ **WARNING**: **NEVER** use this flag on host system or with untrusted code!

**`verbose: true`**
- **What**: Enables detailed logging for all operations
- **Why**: Easier debugging of MCP servers, tool failures, and network issues
- **Effect**: More informative error messages and execution traces
- **Performance Impact**: None (logging is async)
- **Safe**: Always safe to enable

**Extended timeouts**:
- `BASH_DEFAULT_TIMEOUT_MS: "300000"` - 5 minutes for Bash commands (default)
- `BASH_MAX_TIMEOUT_MS: "600000"` - 10 minutes maximum timeout
- **Why**: Long-running builds, npm installs, database migrations won't timeout
- **Safe**: No security implications, just prevents premature timeouts

**High token limits**:
- `MAX_MCP_OUTPUT_TOKENS: "60000"` - MCP servers can return more data
- `MAX_THINKING_TOKENS: "8192"` - Claude can think through complex problems longer
- **Why**: Better quality responses, fewer "output truncated" errors
- **Cost**: Slightly higher API usage, but better results

#### Implementation in Devcontainer Templates

**.devcontainer/settings.json.template**:
```json
{
 "$schema": "https://json.schemastore.org/claude-code-settings.json",
 "dangerously_skip_permissions": true,
 "verbose": true,
 "env": {
 "MAX_MCP_OUTPUT_TOKENS": "60000",
 "BASH_DEFAULT_TIMEOUT_MS": "300000",
 "BASH_MAX_TIMEOUT_MS": "600000",
 "MAX_THINKING_TOKENS": "8192"
 },
 "mcpServers": {
 "context7": {
 "transport": {"type": "sse", "url": "https://mcp.context7.com/sse"}
 }
 }
}
```

**Init script to apply settings** (`.devcontainer/init-claude-config.sh`):
```bash
#!/bin/bash
set -euo pipefail

# Create .claude directory if doesn't exist
mkdir -p ~/.claude ~/.config/gh

# Copy template to settings.json if not exists
if [ ! -f ~/.claude/settings.json ]; then
 cp /usr/local/share/claude-defaults/settings.json ~/.claude/settings.json
 echo "Initialized Claude Code settings with performance flags"
else
 echo "Claude Code settings already exist, skipping..."
fi
```

**devcontainer.json** (run init script on container start):
```json
{
 "postStartCommand": "sudo /usr/local/bin/init-claude-config.sh"
}
```

#### Security Considerations

**Why this is SAFE in devcontainers**:
1. **Isolated environment** - Container can't access host files directly
2. **Network firewall** - Outbound connections restricted to whitelisted domains (IPv4 + IPv6 disabled)
3. **Non-root user** - Limited privilege (e.g., `node` user UID 1000)
4. **Auditable** - All tool executions logged via OpenTelemetry/Prometheus
5. **Disposable** - Can rebuild container if compromised
6. **Volume isolation** - Each project gets separate credential volumes
7. **IPv6 bypass prevented** - IPv6 disabled at kernel level before firewall rules applied

**When NOT to use these flags**:
- Running on host system (not in container)
- Untrusted codebases or repositories
- Production environments
- Shared machines or CI/CD runners
- When required to audit every tool execution before running

**Alternative**: If security policies prohibit `dangerously_skip_permissions`, keep `verbose: true` and extended timeouts for improved debugging without skipping prompts.

#### Verification

```bash
# Check settings are applied
cat ~/.claude/settings.json | jq '{dangerously_skip_permissions, verbose}'

# Expected output:
# {
# "dangerously_skip_permissions": true,
# "verbose": true
# }

# Test Claude Code responds faster
claude chat
# Try a command that uses tools - notice no permission prompts!
```

#### Performance Impact Summary

| Setting | Speed Improvement | Safety Trade-off | Recommended |
|---------|------------------|------------------|-------------|
| `dangerously_skip_permissions` | 50-80% faster | Low in devcontainer | Yes (devcontainer only) |
| `verbose` | None (better debugging) | None | Always |
| Extended timeouts | Prevents failures | None | Always |
| High token limits | Better responses | Slightly higher cost | Yes |

**Bottom line**: For devcontainer development, enabling these flags provides **significantly faster** coding experience with **minimal security risk** due to container isolation.

### Sources

- **Claude Code**: https://www.npmjs.com/package/@anthropic-ai/claude-code
- **Claude Code Settings Schema**: https://json.schemastore.org/claude-code-settings.json
- **Devcontainer Security**: https://code.visualstudio.com/docs/devcontainers/containers#_security-and-container-isolation
- **OpenAI Codex**: https://www.npmjs.com/package/@openai/codex
- **Google Gemini CLI**: https://www.npmjs.com/package/@google/gemini-cli
- **GitHub Copilot**: https://github.com/features/copilot
- **VS Code Extension Marketplace**: https://marketplace.visualstudio.com/vscode

---

## MCP Server Setup

Model Context Protocol (MCP) servers extend Claude Code with specialized capabilities.

### What Are MCP Servers?

MCP servers provide Claude Code with access to:
- **External Documentation**: Library docs (Next.js, MongoDB, Cloudflare), API references
- **Tools**: Browser automation (Chromium DevTools), database queries
- **Custom Data**: Company wikis, internal APIs, documentation systems

**Official MCP Documentation**: https://modelcontextprotocol.io

### Transport Types Explained

MCP servers use two transport mechanisms:

**Streamable HTTP** - For remote/cloud services
```json
{
 "transport": {
 "type": "sse",
 "url": "https://api.example.com/sse"
 }
}
```
- **Use when**: Server is hosted externally (Context7, Cloudflare Docs)
- **Pros**: No local installation, always up-to-date
- **Cons**: Requires internet, potential rate limits
- **Note**: Previously called "SSE (Server-Sent Events)" before March 2025 MCP specification update

**stdio (Standard Input/Output)** - For local processes
```json
{
 "command": "npx",
 "args": [
   "-y",
   "chrome-devtools-mcp@latest",
   "--executablePath=/usr/bin/chromium",
   "--headless",
   "--chromeArg=--no-sandbox",
   "--chromeArg=--disable-setuid-sandbox",
   "--chromeArg=--disable-dev-shm-usage"
 ],
 "transport": {
 "type": "stdio"
 }
}
```
- **Use when**: Server runs as local npm package (Chrome DevTools, mcp-remote)
- **Pros**: Works offline, full control
- **Cons**: Needs installation, manual updates
- **Note**: Chrome DevTools MCP requires `--executablePath=/usr/bin/chromium` in containers (Chromium is installed instead of Google Chrome)

### Testing MCP Server Transport Support

Before configuring an MCP server, test which transport methods it supports:

#### Method 1: Check Official Documentation

Always check the server's documentation first. Examples:
- **Context7**: https://context7.com/mcp (documents SSE endpoint)
- **Cloudflare**: https://developers.cloudflare.com/agents/model-context-protocol/

#### Method 2: Test with curl

```bash
# Test SSE endpoint (Server-Sent Events)
curl -v https://mcp.context7.com/sse
# Expected: HTTP/1.1 200 OK or 204 No Content

# Test HTTP endpoint
curl -v -X POST https://api.example.com/mcp \
 -H "Content-Type: application/json" \
 -d '{"jsonrpc":"2.0","method":"initialize","params":{},"id":1}'
# Expected: JSON-RPC response if supported
```

#### Method 3: Try Both Transports

```bash
# Test SSE transport
claude mcp add --transport sse testserver https://server.com/sse
claude mcp list # Check if status shows "connected"

# If SSE fails, test HTTP (if advertised)
claude mcp remove testserver
claude mcp add --transport http testserver https://server.com
claude mcp list
```

#### Method 4: Check Claude Code Logs

View MCP connection logs:
```bash
# In VS Code terminal or Claude CLI
# Errors like "connection refused" or "404" indicate unsupported transport
# Success: Server appears in `claude mcp list` with "connected" status
```

#### Transport Status as of October 27, 2025

| Server | SSE | HTTP | stdio (mcp-remote) | Notes |
|--------|-----|------|-------------------|-------|
| **Context7** | Yes | No | Yes | SSE: `/sse` endpoint, stdio: use `mcp-remote` |
| **Cloudflare Docs** | Yes | No | Yes | SSE: `/sse` endpoint, stdio: use `mcp-remote` |
| **Chrome DevTools** | No | No | Yes | Local stdio only: `npx chrome-devtools-mcp@latest`. **In containers**: Add `--executablePath=/usr/bin/chromium` |

**Note**: While the MCP specification calls the transport "Streamable HTTP", the JSON configuration still uses `"type": "sse"`. Do not confuse this with `"type": "http"` which is a different (future) transport method.

### Common MCP Servers

#### Context7 - Library Documentation

> **Transport Status (Oct 27, 2025)**: Context7 supports two methods:
> 1. **SSE transport** (public, no auth): `https://mcp.context7.com/sse`
> 2. **stdio with mcp-remote** (OAuth secured): `https://mcp.context7.com/mcp`

**Method 1: SSE Transport (Simple)**

```bash
# Add via CLI
claude mcp add --transport sse context7 https://mcp.context7.com/sse

# Or in mcp.json
{
 "mcpServers": {
 "context7": {
 "transport": {
 "type": "sse",
 "url": "https://mcp.context7.com/sse"
 }
 }
 }
}
```

**Method 2: mcp-remote (OAuth Secured, Recommended)**

Provides access to 1000+ library documentation sources with OAuth authentication.

```bash
# Add via CLI
claude mcp add --transport stdio context7 -- npx mcp-remote https://mcp.context7.com/mcp

# Or in mcp.json
{
 "mcpServers": {
 "context7": {
 "command": "npx",
 "args": ["mcp-remote", "https://mcp.context7.com/mcp"],
 "transport": {
 "type": "stdio"
 }
 }
 }
}
```

**First use**: Opens browser for OAuth authentication. Subsequent uses are automatic.

**Testing both methods**: Use `.devcontainer/switch-mcp.sh` script to compare SSE vs mcp-remote.

**Supported libraries**: Next.js, React, MongoDB, Supabase, Vercel, and more.

#### Cloudflare Docs - Cloudflare Product Documentation

> **Transport Status (Oct 27, 2025)**: Cloudflare Docs supports two methods:
> 1. **SSE transport** (public, no auth): `https://docs.mcp.cloudflare.com/sse`
> 2. **stdio with mcp-remote** (OAuth secured): `https://docs.mcp.cloudflare.com/mcp`

**Method 1: SSE Transport (Simple)**

```bash
# Add via CLI
claude mcp add --transport sse cf-docs https://docs.mcp.cloudflare.com/sse

# Or in mcp.json
{
 "mcpServers": {
 "cf-docs": {
 "transport": {
 "type": "sse",
 "url": "https://docs.mcp.cloudflare.com/sse"
 }
 }
 }
}
```

**Method 2: mcp-remote (OAuth Secured, Recommended)**

Provides `search_cloudflare_documentation` tool with OAuth authentication.

```bash
# Install mcp-remote wrapper
npm install -g mcp-remote

# Add to mcp.json (cannot use CLI for this syntax)
{
 "mcpServers": {
 "cf-docs": {
 "command": "npx",
 "args": ["mcp-remote", "https://docs.mcp.cloudflare.com/mcp"],
 "transport": {
 "type": "stdio"
 }
 }
 }
}
```

**First use**: Opens browser for OAuth authentication. Subsequent uses are automatic.

**Testing both methods**: Use `.devcontainer/switch-mcp.sh` script to compare SSE vs mcp-remote.

**Covers**: Workers, Pages, R2, D1, KV, Durable Objects, Queues, etc.

**See**: https://developers.cloudflare.com/agents/model-context-protocol/mcp-servers-for-cloudflare/

#### Chrome DevTools (stdio) - Browser Automation

Requires Chromium installed in Dockerfile.

**Dockerfile additions**:
```dockerfile
RUN apt-get update && apt-get install -y \
 chromium \
 fonts-liberation \
 && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**Add MCP server**:
```bash
claude mcp add --transport stdio chrome-devtools npx chrome-devtools-mcp@latest -- \
 --executablePath=/usr/bin/chromium \
 --headless \
 --chromeArg='--no-sandbox' \
 --chromeArg='--disable-setuid-sandbox' \
 --chromeArg='--disable-dev-shm-usage'
```

**Why these Chrome args?**
- `--no-sandbox`: Required in Docker (containers already sandboxed)
- `--disable-setuid-sandbox`: Docker compatibility
- `--disable-dev-shm-usage`: Prevents /dev/shm memory issues

### Automating MCP Setup

Create `.devcontainer/mcp.json.template`:

```json
{
 "mcpServers": {
 "context7": {
 "transport": {
 "type": "sse",
 "url": "https://mcp.context7.com/sse"
 }
 },
 "cf-docs": {
 "transport": {
 "type": "sse",
 "url": "https://docs.mcp.cloudflare.com/sse"
 }
 }
 }
}
```

Create `.devcontainer/init-claude-config.sh`:

```bash
#!/bin/bash
set -euo pipefail

CLAUDE_HOME="/home/node/.claude"
MCP_FILE="$CLAUDE_HOME/mcp.json"
MCP_TEMPLATE="/usr/local/share/claude-defaults/mcp.json"

echo "Initializing Claude Code configuration..."

# Create .claude directory if it doesn't exist
if [ ! -d "$CLAUDE_HOME" ]; then
 mkdir -p "$CLAUDE_HOME"
 chown node:node "$CLAUDE_HOME"
fi

# Create .config/gh directory if it doesn't exist
GH_CONFIG="/home/node/.config/gh"
if [ ! -d "$GH_CONFIG" ]; then
 mkdir -p "$GH_CONFIG"
 chown node:node "$GH_CONFIG"
fi

# Copy MCP configuration if it doesn't exist
if [ ! -f "$MCP_FILE" ]; then
 if [ -f "$MCP_TEMPLATE" ]; then
 cp "$MCP_TEMPLATE" "$MCP_FILE"
 chown node:node "$MCP_FILE"
 echo " MCP servers configured"
 fi
else
 echo "MCP configuration already exists, preserving user settings"
fi
```

**Dockerfile additions**:

```dockerfile
# Copy MCP template to shared location
RUN mkdir -p /usr/local/share/claude-defaults
COPY --chown=node:node mcp.json.template /usr/local/share/claude-defaults/mcp.json

# Copy and configure init script
COPY init-claude-config.sh /usr/local/bin/
USER root
RUN chmod +x /usr/local/bin/init-claude-config.sh && \
 echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-claude-config.sh" > /etc/sudoers.d/node-claude && \
 chmod 0440 /etc/sudoers.d/node-claude
USER node
```

**devcontainer.json additions**:

```json
{
 "postStartCommand": "sudo /usr/local/bin/init-claude-config.sh"
}
```

This ensures MCP servers are automatically configured on first container start, but **preserves user customizations** on subsequent starts.

### Verifying MCP Setup

```bash
# List configured MCP servers
claude mcp list

# Test MCP server (inside Claude Code session)
# Ask Claude: "What's new in Next.js 14?" (uses Context7)
```

### Debugging MCP Issues

```bash
# Check mcp.json exists and is valid JSON
cat ~/.claude/mcp.json | jq

# Test SSE endpoint manually
curl -v https://mcp.context7.com/sse

# Check stdio MCP can run
npx chrome-devtools-mcp@latest --help

# View Claude Code logs
claude --verbose
```

---

### Docker MCP Toolkit Integration


### Docker MCP Toolkit

**What is it**: Docker Desktop integration that simplifies MCP server management with 200+ pre-built, containerized MCP servers.

**Official Announcement**: https://www.docker.com/blog/add-mcp-servers-to-claude-code-with-mcp-toolkit/

#### Features

1. **One-Click Deployment**: Install MCP servers from Docker Desktop UI
2. **200+ Pre-built Servers**: Curated catalog of containerized MCP servers
3. **No Dependency Issues**: Each server runs in isolated container
4. **Automatic Configuration**: Docker Desktop writes to `~/.claude/mcp.json`

#### Using Docker MCP Toolkit

**Step 1: Enable in Docker Desktop**

Docker Desktop → Extensions → Claude Code → Enable

**Step 2: Browse MCP Servers**

Docker Desktop → Claude Code → Browse Servers

**Available categories**:
- Development tools (GitHub, GitLab, Jira)
- Cloud services (AWS, Azure, Google Cloud)
- Databases (PostgreSQL, MongoDB, Redis)
- AI services (OpenAI, Anthropic)
- Custom organization servers

**Step 3: One-Click Install**

Click server → Install → Docker Desktop:
1. Pulls containerized MCP server
2. Starts container
3. Configures `~/.claude/mcp.json` automatically

**Result**: MCP server immediately available in Claude Code.

---

### MCP Proxy for Inter-Container Communication

**Problem**: Claude Code in devcontainer can't use stdio to communicate with MCP servers in other containers.

**Solution**: MCP proxy that bridges stdio and network communication.

**Architecture**:
```
┌─────────────────────────┐
│ Devcontainer │
│ ┌─────────────────────┐│
│ │ Claude Code ││
│ │ (OTLP gRPC) ││
│ └──────────┬──────────┘│
│ │ │
│ stdio → HTTP │
│ │ │
│ ┌──────────▼──────────┐│
│ │ MCP Proxy ││
│ └──────────┬──────────┘│
└─────────────┼───────────┘
 │
 HTTP │
 │
┌─────────────▼───────────┐
│ MCP Server Container │
│ (GitHub, Database, etc)│
└─────────────────────────┘
```

**Implementation**: Use `@modelcontextprotocol/server-proxy` to bridge connections.

---

### MCP Server Performance Optimization

**Cache frequently accessed data**:

MCP servers can cache responses to reduce latency:

```json
{
 "mcpServers": {
 "context7": {
 "transport": {
 "type": "sse",
 "url": "https://mcp.context7.com/sse"
 },
 "cacheTimeout": 3600
 }
 }
}
```

**Health checks**:

Monitor MCP server availability:

```bash
# Test SSE server
curl -v https://mcp.context7.com/sse

# Test stdio server
npx chrome-devtools-mcp@latest --help
```

---

### Sources
- **Docker MCP Toolkit**: https://www.docker.com/blog/add-mcp-servers-to-claude-code-with-mcp-toolkit/
- **MCP Specification**: https://modelcontextprotocol.io/docs
- **MCP Transports**: https://modelcontextprotocol.io/docs/concepts/transports
- **Server Implementation**: https://modelcontextprotocol.io/docs/concepts/servers

---

## Security Best Practices

### Network Isolation with Firewall

Restrict container network access to only trusted domains, preventing credential exfiltration.

#### IPv6 Bypass Prevention

**Critical Security Issue**: Firewall rules using iptables only filter IPv4 traffic. If IPv6 is enabled, connections can bypass your allowlist entirely.

**The Problem**:
```bash
# Your iptables rules block this:
curl https://malicious-site.com # Blocked (IPv4)

# But IPv6 goes around the firewall:
curl -6 https://malicious-site.com # Allowed! (IPv6 bypass)
```

**Solution**: Disable IPv6 completely at the kernel level before configuring firewall rules.

```bash
# At start of init-firewall.sh (BEFORE any iptables commands)
sysctl -w net.ipv6.conf.all.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.default.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.lo.disable_ipv6=1 >/dev/null 2>&1 || true
```

**Verification**:
```bash
# Verify IPv6 is disabled
sysctl net.ipv6.conf.all.disable_ipv6 # Should show: = 1

# Test IPv6 connections fail
curl -6 https://api.github.com # Should error: "Network is unreachable"
```

**Why This Matters**: Without IPv6 disabled, your firewall provides a false sense of security while leaving a wide-open backdoor.

**Create `.devcontainer/init-firewall.sh`** (Production Implementation):

```bash
#!/bin/bash
set -euo pipefail # Exit on error, undefined vars, pipeline failures
IFS=$'\n\t' # Stricter word splitting

# State file prevents unnecessary reconfiguration on container restart
STATE_FILE="/var/lib/firewall-configured"
if [ -f "$STATE_FILE" ]; then
 echo "Firewall already configured, skipping..."
 exit 0
fi

echo "Starting firewall configuration..."

# Initialize DNS resolution statistics
TOTAL_DOMAINS=0
RESOLVED_DOMAINS=0
FAILED_DOMAINS=0

# === IPv6 SECURITY: Disable IPv6 to prevent bypass ===
echo "Disabling IPv6..."
sysctl -w net.ipv6.conf.all.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.default.disable_ipv6=1 >/dev/null 2>&1 || true
sysctl -w net.ipv6.conf.lo.disable_ipv6=1 >/dev/null 2>&1 || true

# === Preserve Docker DNS (BEFORE flushing) ===
DOCKER_DNS_RULES=$(iptables-save -t nat | grep "127\.0\.0\.11" || true)
DOCKER_NETWORKS=$(ip -o -f inet addr show | grep -v "127.0.0.1" | awk '{print $4}')

# === Create ipset for efficient IP filtering ===
ipset destroy allowed-domains 2>/dev/null || true
ipset create allowed-domains hash:net

# === Fetch GitHub IP ranges (dynamic, comprehensive) ===
echo "Fetching GitHub IP ranges..."
gh_ranges=$(curl -s https://api.github.com/meta)
echo "$gh_ranges" | jq -r '(.web + .api + .git)[]' | aggregate -q | while read -r cidr; do
 echo "Adding GitHub range $cidr"
 ipset add allowed-domains "$cidr" -exist
done

# === Add Anthropic IP ranges (official published ranges) ===
echo "Adding Anthropic IP ranges..."
echo "Adding Anthropic CIDR range 160.79.104.0/23"
ipset add allowed-domains "160.79.104.0/23" -exist

# Add Anthropic specific IP addresses
for ip in "34.162.46.92" "34.162.102.82" "34.162.136.91" "34.162.142.92" "34.162.183.95"; do
 echo "Adding Anthropic IP $ip"
 ipset add allowed-domains "$ip" -exist
done

# === Fetch and add Google Cloud/API IP ranges ===
echo "Fetching Google Cloud/API IP ranges..."
goog_ranges=$(curl -s https://www.gstatic.com/ipranges/goog.json)
echo "$goog_ranges" | jq -r '.prefixes[].ipv4Prefix | select(. != null)' | while read -r cidr; do
 echo "Adding Google range $cidr"
 ipset add allowed-domains "$cidr" -exist
done

# === Fetch and add Cloudflare CDN IP ranges ===
echo "Fetching Cloudflare CDN IP ranges..."
cf_ranges=$(curl -s https://api.cloudflare.com/client/v4/ips)
echo "$cf_ranges" | jq -r '.result.ipv4_cidrs[]' | while read -r cidr; do
 echo "Adding Cloudflare range $cidr"
 ipset add allowed-domains "$cidr" -exist
done

# === Fetch and add AWS IP ranges (covers many AI services: Hugging Face, Replicate, etc.) ===
# Filtered for US East/West regions and EC2/CloudFront services only to limit allowlist size
echo "Fetching AWS IP ranges..."
aws_ranges=$(curl -s https://ip-ranges.amazonaws.com/ip-ranges.json)
echo "$aws_ranges" | jq -r '.prefixes[] | select(.region == "us-east-1" or .region == "us-west-2") | select(.service == "EC2" or .service == "CLOUDFRONT") | .ip_prefix' | aggregate -q | while read -r cidr; do
 echo "Adding AWS range $cidr"
 ipset add allowed-domains "$cidr" -exist
done

# === Resolve and add all trusted domains (defense-in-depth: includes DNS backup) ===
# Defense-in-depth: Services with IP ranges (above) also included here as DNS backup
# This ensures comprehensive coverage and handles edge cases
for domain in \
 "1.1.1.1" "8.8.8.8" "8.8.4.4" \
 "dns.google" \
 "context7.com" \
 "unpkg.com" "cdn.jsdelivr.net" "cdnjs.cloudflare.com" \
 "github.com" "api.github.com" "raw.githubusercontent.com" \
 "github.githubassets.com" "collector.github.com" \
 "ghcr.io" "pkg-containers.githubusercontent.com" \
 "nodejs.org" "registry.npmjs.org" \
 "pypi.org" "files.pythonhosted.org" \
 "astral.sh" "bun.sh" \
 "crates.io" "static.crates.io" "index.crates.io" \
 "docker.io" "registry-1.docker.io" "auth.docker.io" \
 "production.cloudflare.docker.com" \
 "api.anthropic.com" "statsig.anthropic.com" "statsig.com" "sentry.io" \
 "api.openai.com" \
 "aistudio.google.com" "accounts.google.com" \
 "oauth2.googleapis.com" "www.googleapis.com" \
 "storage.googleapis.com" "content.googleapis.com" \
 "generativelanguage.googleapis.com" \
 "marketplace.visualstudio.com" "vscode.blob.core.windows.net" \
 "update.code.visualstudio.com" \
 "docs.mcp.cloudflare.com" "mcp.context7.com" \
 "vercel.com" "ui.shadcn.com" "tailwindcss.com" \
 "radix-ui.com" "fonts.googleapis.com" "fonts.gstatic.com" \
 "react.dev" "reactjs.org" "esm.sh" "lucide.dev" \
 "openrouter.ai" \
 "api.cerebras.ai" "inference.cerebras.ai" "cloud.cerebras.ai" "cerebras.ai" \
 "dashscope.aliyuncs.com" "qwen.ai" "qwenlm.ai" "aliyuncs.com" "alibabacloud.com" \
 "cn-hangzhou.aliyuncs.com" "us-west-1.aliyuncs.com" "ap-southeast-1.aliyuncs.com" \
 "api.minimax.chat" "minimax.chat" \
 "z.ai" \
 "api.cohere.ai" "cohere.ai" \
 "api.together.xyz" "together.xyz" \
 "api.replicate.com" "replicate.com" \
 "api-inference.huggingface.co" "huggingface.co" \
 "api.perplexity.ai" "perplexity.ai" \
 "api.mistral.ai" "mistral.ai" \
 "api.deepinfra.com" "deepinfra.com" \
 "api.fireworks.ai" "fireworks.ai" \
 "api.groq.com" "groq.com" \
 "api.lepton.ai" "lepton.ai" \
 "mancer.tech" "api.mancer.tech" \
 "api.deepseek.com" "deepseek.com" \
 "api.lingyiwanwu.com" "platform.lingyiwanwu.com"; do

 # If already an IP, add directly
 if [[ "$domain" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
 ipset add allowed-domains "$domain" -exist
 continue
 fi

 # Resolve domain and add all IPs with graceful error handling
 TOTAL_DOMAINS=$((TOTAL_DOMAINS + 1))
 echo "Resolving $domain..."
 ips=$(dig +noall +answer A "$domain" | awk '$4 == "A" {print $5}')
 if [ -z "$ips" ]; then
 echo "WARNING: Failed to resolve $domain (continuing...)"
 FAILED_DOMAINS=$((FAILED_DOMAINS + 1))
 continue
 fi

 # Successfully resolved, add IPs to allowlist
 domain_resolved=false
 while read -r ip; do
 if [[ ! "$ip" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
 echo "WARNING: Invalid IP from DNS for $domain: $ip (skipping)"
 continue
 fi
 echo "Adding $ip for $domain"
 ipset add allowed-domains "$ip" -exist
 domain_resolved=true
 done < <(echo "$ips")

 # Count as resolved only if at least one valid IP was added
 if [ "$domain_resolved" = true ]; then
 RESOLVED_DOMAINS=$((RESOLVED_DOMAINS + 1))
 else
 FAILED_DOMAINS=$((FAILED_DOMAINS + 1))
 fi
done

echo ""
echo "IP allowlist built successfully"
echo "DNS Resolution Summary: ${RESOLVED_DOMAINS}/${TOTAL_DOMAINS} domains resolved successfully"
if [ "$FAILED_DOMAINS" -gt 0 ]; then
 echo "  WARNING: ${FAILED_DOMAINS} domains failed to resolve"
fi
echo ""

# === Flush and rebuild iptables ===
iptables -F && iptables -X
iptables -t nat -F && iptables -t nat -X
iptables -t mangle -F && iptables -t mangle -X

# Restore Docker DNS rules
if [ -n "$DOCKER_DNS_RULES" ]; then
 iptables -t nat -N DOCKER_OUTPUT 2>/dev/null || true
 iptables -t nat -N DOCKER_POSTROUTING 2>/dev/null || true
 echo "$DOCKER_DNS_RULES" | xargs -L 1 iptables -t nat
fi

# === Configure base rules ===
iptables -A OUTPUT -p udp --dport 53 -j ACCEPT # DNS
iptables -A INPUT -p udp --sport 53 -j ACCEPT
iptables -A OUTPUT -p tcp --dport 22 -j ACCEPT # SSH
iptables -A INPUT -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT
iptables -A INPUT -i lo -j ACCEPT # Localhost
iptables -A OUTPUT -o lo -j ACCEPT

# === Allow Docker networks (for OTel, inter-container) ===
while read -r network; do
 iptables -A INPUT -s "$network" -j ACCEPT
 iptables -A OUTPUT -d "$network" -j ACCEPT
done < <(echo "$DOCKER_NETWORKS")

# === Default DENY, then allow via ipset ===
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT DROP
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
iptables -A OUTPUT -j REJECT --reject-with icmp-admin-prohibited

# === Configure IPv6 firewall rules (Layer 3 - Defense-in-depth) ===
echo "Configuring IPv6 firewall rules..."
# Set default policies to DROP for IPv6
ip6tables -P INPUT DROP 2>/dev/null || echo " Note: IPv6 may already be disabled"
ip6tables -P FORWARD DROP 2>/dev/null || true
ip6tables -P OUTPUT DROP 2>/dev/null || true

# Allow IPv6 localhost only
ip6tables -A INPUT -i lo -j ACCEPT 2>/dev/null || true
ip6tables -A OUTPUT -o lo -j ACCEPT 2>/dev/null || true

# Allow established IPv6 connections (for localhost)
ip6tables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true
ip6tables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true

# Explicitly REJECT all other IPv6 traffic
ip6tables -A INPUT -j REJECT 2>/dev/null || true
ip6tables -A OUTPUT -j REJECT 2>/dev/null || true
echo "IPv6 firewall rules configured"

echo ""
echo "Firewall configuration complete!"
echo ""

# === Verification ===
echo "Verifying firewall rules..."

# Verify IPv6 is disabled (warning only, not fatal - graceful degradation)
if sysctl net.ipv6.conf.all.disable_ipv6 | grep -q "= 1"; then
 echo " IPv6 is disabled"
else
 echo " WARNING: IPv6 is still enabled (container restrictions may prevent disabling)"
 echo " IPv6 traffic will be blocked by ip6tables rules as a security fallback"
 echo " This is expected in some Docker environments and does not affect security"
fi

# Verify blocked domain
if curl --connect-timeout 5 https://example.com >/dev/null 2>&1; then
 echo " Firewall failed - can reach blocked domain"
 exit 1
else
 echo " Blocked domains unreachable"
fi

# Verify allowed domain
if ! curl --connect-timeout 5 https://api.github.com/zen >/dev/null 2>&1; then
 echo " Firewall failed - can't reach allowed domain"
 exit 1
else
 echo " Allowed domains reachable"
fi

# Verify OpenRouter API access
if ! curl --connect-timeout 5 https://openrouter.ai/api/v1/models >/dev/null 2>&1; then
 echo " Firewall failed - unable to reach OpenRouter"
 exit 1
else
 echo " Can reach OpenRouter as expected"
fi

# Verify Cerebras API access
if ! curl --connect-timeout 5 https://api.cerebras.ai/v1/models >/dev/null 2>&1; then
 echo " Firewall failed - unable to reach Cerebras"
 exit 1
else
 echo " Can reach Cerebras as expected"
fi

# Mark as configured
touch "$STATE_FILE"
echo "Firewall state saved"
```

**Key Features of Production Implementation**:
1. **Three-layer IPv6 security** - Container creation, runtime disable, ip6tables rules
2. **Graceful degradation** - Container starts successfully even if IPv6 can't be disabled
3. **Maximum compatibility** - Works across Docker Desktop, Podman, cloud environments
4. **ipset for efficiency** - Much faster than individual iptables rules for 100+ domains
5. **Dynamic IP range fetching** - Fetches official IP ranges for GitHub, Anthropic, Google, Cloudflare, AWS
6. **AWS IP ranges** - Filtered for US regions (us-east-1, us-west-2) and EC2/CloudFront services
7. **Resilient DNS resolution** - Warns on DNS failures instead of failing container startup, tracks resolution statistics (e.g., "98/102 domains resolved")
8. **DNS resolution backup** - Defense-in-depth: DNS resolution for all domains (including those with IP ranges)
9. **Docker DNS preservation** - Maintains container networking
10. **State file** - Skips reconfiguration on container restart
11. **Comprehensive verification** - Tests IPv6, blocked domains, GitHub, OpenRouter, Cerebras APIs
12. **100+ whitelisted domains** - All package registries, AI APIs (OpenRouter, Cerebras, Qwen, Minimax, z.ai, Cohere, Together, Replicate, Hugging Face, Perplexity, Mistral, DeepInfra, Fireworks, Groq, Lepton, DeepSeek, 01.AI), CDNs covered

**Dockerfile additions**:

```dockerfile
# Install firewall and network tools (including IPv6 support)
RUN apt-get update && apt-get install -y \
 iptables \
 ipset \
 iproute2 \
 dnsutils \
 aggregate \
 curl \
 jq \
 && apt-get clean && rm -rf /var/lib/apt/lists/*

# Copy and configure firewall script
COPY init-firewall.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/init-firewall.sh && \
 echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-firewall.sh" > /etc/sudoers.d/node-firewall && \
 chmod 0440 /etc/sudoers.d/node-firewall
```

**Required tools explained**:
- `iptables` - IPv4 and IPv6 firewall rules (includes ip6tables)
- `ipset` - Efficient IP address set management
- `iproute2` - Network configuration (`ip` command)
- `dnsutils` - DNS resolution (`dig` command)
- `aggregate` - IP range aggregation (GitHub IPs)
- `curl` - HTTP requests (fetch GitHub API, verify firewall)
- `jq` - JSON parsing (GitHub API response)

**devcontainer.json additions** (Maximum Compatibility - Three-Layer Security):

```json
{
 "runArgs": [
 "--cap-drop=ALL", // Drop all capabilities first (security)
 "--cap-add=NET_ADMIN", // Required for iptables/sysctl
 "--cap-add=NET_RAW", // Required for packet filtering
 "--cap-add=SETUID", // Required for sudo operations
 "--cap-add=SETGID", // Required for group switching
 "--cap-add=SYS_ADMIN", // Required for broader kernel parameter control
 "--sysctl=net.ipv6.conf.all.disable_ipv6=1", // Layer 1: Disable IPv6 at container creation
 "--sysctl=net.ipv6.conf.default.disable_ipv6=1",
 "--sysctl=net.ipv6.conf.lo.disable_ipv6=1"
 ],
 "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"
}
```

**Three-Layer Security Architecture**:
- **Layer 1**: Disable IPv6 at container creation via sysctl flags (most reliable)
- **Layer 2**: Attempt runtime IPv6 disable in init script (graceful degradation if Layer 1 fails)
- **Layer 3**: ip6tables DROP rules (security backup if IPv6 remains enabled)

**Testing Firewall**:

```bash
# Inside container - Test allowed domain
curl https://api.anthropic.com # Should work (whitelisted)

# Test blocked domain
curl https://example.com # Should fail (not whitelisted)

# Test IPv6 is disabled (critical security check)
curl -6 https://api.github.com # Should fail: "Network is unreachable"

# Verify IPv6 disabled at kernel level
sysctl net.ipv6.conf.all.disable_ipv6 # Should show: net.ipv6.conf.all.disable_ipv6 = 1
```

### The `--dangerously-skip-permissions` Flag

**What it does**: Bypasses Claude Code's permission prompts for tool execution.

**When to use**:
- Trusted devcontainers with firewall enabled
- Automated CI/CD pipelines
- Personal projects in isolated containers

**When NOT to use**:
- Untrusted codebases
- Open-source projects you haven't audited
- Production environments
- Containers without network restrictions

**Official Warning**: "When executed with `--dangerously-skip-permissions`, devcontainers do not prevent a malicious project from exfiltrating anything accessible in the devcontainer including Claude Code credentials."

**Usage**:
```bash
claude --dangerously-skip-permissions
```

### Protecting Sensitive Files

**Always exclude** local settings from git:

```bash
# In Dockerfile
RUN git config --global core.excludesfile ~/.gitignore_global && \
 echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

**Why?** `.claude/settings.local.json` contains API keys. Committing this file exposes credentials.

### Credential Isolation Best Practices

**Use separate devcontainers for**:
- Different clients (prevents client A's credentials leaking to client B)
- Different security levels (public open-source vs. proprietary)
- Different AI services (separate Claude/Codex/Gemini API keys per project)

**How?** Each devcontainer gets isolated volumes (`${devcontainerId}` ensures uniqueness).

### Additional Security Measures

**Read-only bind mounts**:
```json
{
 "mounts": [
 "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly"
 ]
}
```

**Limit container capabilities**:
```json
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_ADMIN" // Only if firewall needed
 ]
}
```

### ️ The `--security-opt=no-new-privileges` Incompatibility

**Critical Finding** (October 2025 field testing):

The `--security-opt=no-new-privileges` Docker flag **breaks sudo** in devcontainers, causing runtime initialization scripts to fail.

**What it does**:
- Prevents processes from gaining elevated privileges
- Recommended security hardening in many Docker guides
- Sounds like good defense-in-depth

**The Problem**:
```bash
# In postStartCommand:
sudo /usr/local/bin/init-firewall.sh

# Error with no-new-privileges:
sudo: The "no new privileges" flag is set, which prevents sudo from running as root.
sudo: If sudo is running in a container, you may need to adjust the container configuration to disable the flag.
```

**Why it breaks**:
- Firewall configuration requires `sudo` to run `iptables` commands
- `iptables` needs root privileges to modify network rules
- `no-new-privileges` prevents sudo from elevating to root
- Result: Container starts but firewall/config scripts fail with exit code 1

**When you CAN'T use this flag**:
- Any devcontainer that uses `sudo` in lifecycle hooks (postStartCommand, postCreateCommand)
- Devcontainers with iptables firewall configuration
- Init scripts requiring root privileges
- Containers using `sudoers` file for specific commands

**When you CAN use this flag**:
- Devcontainers that never need sudo
- Containers where all root operations happen at build-time (Dockerfile)
- Simple development containers without network restrictions

**Recommended Approach** (if you need both security and sudo):

**Option 1: Don't use no-new-privileges** (recommended)
- Your existing security is already strong:
 - `--cap-drop=ALL` (drop all capabilities)
 - Only add necessary capabilities (`NET_ADMIN`, `NET_RAW`)
 - Non-root user (`remoteUser: "node"`)
 - Network firewall with whitelist (IPv4 + IPv6 disabled)
 - Limited sudoers file (specific scripts only)
- The `no-new-privileges` flag is defensive overkill that breaks necessary functionality

**Option 2: Move root operations to build-time**
```dockerfile
# Instead of postStartCommand with sudo:
# Do firewall setup in Dockerfile (more complex but works with no-new-privileges)

# Dockerfile
RUN /usr/local/bin/init-firewall.sh && \
 # Save iptables rules
 iptables-save > /etc/iptables/rules.v4

# devcontainer.json - can now use no-new-privileges
{
 "runArgs": ["--security-opt=no-new-privileges"],
 "postStartCommand": "iptables-restore < /etc/iptables/rules.v4"
}
```

**Option 3: Architectural alternative**
- Use Docker's network isolation features instead of in-container iptables
- Define network policies in `docker-compose.yml`
- No sudo required, can use `no-new-privileges`

**Lesson Learned**:
Don't blindly apply every security hardening flag. Test with your actual use case. Some "best practices" from generic Docker guides don't account for devcontainer-specific requirements like lifecycle hooks that need elevated privileges.

**Real-world example**:
```json
// BAD - Looks secure but breaks initialization
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_ADMIN",
 "--security-opt=no-new-privileges" // Breaks sudo!
 ],
 "postStartCommand": "sudo /usr/local/bin/init-firewall.sh" // Fails!
}

// GOOD - Secure AND functional
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_ADMIN",
 "--cap-add=NET_RAW",
 "--cap-add=SETUID", // Needed for sudo
 "--cap-add=SETGID" // Needed for sudo
 // no-new-privileges flag removed
 ],
 "postStartCommand": "sudo /usr/local/bin/init-firewall.sh" // Works!
}
```

**Use minimal base images**:
```dockerfile
FROM node:22-slim # Instead of node:22 (500MB smaller)
```

---

### Advanced Security Features


### Enhanced Container Isolation (ECI)

**What is ECI**: Docker Desktop feature that prevents malicious containers from compromising the host system using advanced security techniques.

**Official Documentation**: https://docs.docker.com/security/for-admins/hardened-desktop/enhanced-container-isolation/

#### How ECI Works

**Traditional containers**:
- Share host kernel
- Can potentially escalate privileges
- Access Docker socket (if mounted)
- Read host files (if mounted)

**With ECI**:
- **Security boundary between container and Docker Desktop**
- Linux security modules (SELinux, AppArmor) enforced
- Restricted access to Docker socket
- Limited syscalls via seccomp
- Cannot compromise Docker Desktop even if container breached

#### Enabling ECI

**Docker Desktop** → Settings → General → **"Use Enhanced Container Isolation"** → Apply

**Verify ECI active**:
```bash
docker info | grep "Security Options"
# Should show: seccomp, apparmor/selinux, userns
```

---

### User Namespace Remapping

Map container root user to unprivileged host user.

**Problem**: Container root (UID 0) = host root (UID 0) → security risk.

**Solution**: User namespaces remap container UID 0 to host UID 100000+ (non-privileged).

**Enable user namespaces**:

**/etc/docker/daemon.json**:
```json
{
 "userns-remap": "default"
}
```

**Restart Docker**:
```bash
sudo systemctl restart docker
```

**Verify**:
```bash
docker run --rm alpine id
# Shows: uid=0(root) gid=0(root) (inside container)

# On host, process runs as:
ps aux | grep alpine
# Shows: 100000 (unprivileged user)
```

**Official Docs**: https://docs.docker.com/engine/security/userns-remap/

---

### Network Segmentation

Isolate containers by security level using custom networks.

**Create security zones**:
```bash
# DMZ network (public-facing services)
docker network create --driver bridge dmz-network

# Internal network (databases, private services)
docker network create --driver bridge --internal internal-network

# Admin network (management tools)
docker network create --driver bridge admin-network
```

**docker-compose.yml with segmentation**:
```yaml
services:
 frontend:
 image: myapp-frontend
 networks:
 - dmz-network

 backend:
 image: myapp-backend
 networks:
 - dmz-network
 - internal-network

 database:
 image: postgres:15
 networks:
 - internal-network # Not accessible from DMZ

networks:
 dmz-network:
 external: true
 internal-network:
 external: true
 internal: true # No external access
```

**Official Docs**: https://docs.docker.com/network/drivers/bridge/#use-user-defined-bridge-networks

---

### Git Safety and Branch Protection

**Problem**: AI assistants (or developers) might accidentally commit directly to protected branches (`main`/`master`) or perform destructive operations without proper safeguards.

**Solution**: Pre-commit git hook that technically enforces branch protection by blocking commits to `main` and `master` branches.

#### Why Git Hooks?

**Git hooks are not tracked in `.git/hooks/`** (`.git/` is in `.gitignore`), which means:
- Hooks don't transfer when cloning the repository
- Must be installed manually after cloning or rebuilding containers
- Provide **technical enforcement** (not just guidance)

#### Installation

**Step 1: Create setup script** (`.devcontainer/setup-git-hooks.sh`):

```bash
#!/bin/bash
#
# Setup Git Hooks
#
# Installs git hooks for branch protection and safety.
# Run this after cloning the repository or rebuilding the container.
#

# Strict error handling
set -euo pipefail

# Dynamically resolve repository root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
HOOKS_DIR="$REPO_ROOT/.git/hooks"

# Validate git repository (works with worktrees and submodules)
if ! git rev-parse --git-dir > /dev/null 2>&1; then
    echo "❌ ERROR: Not a git repository"
    echo "Current directory: $(pwd)"
    echo "Repository root: $REPO_ROOT"
    exit 1
fi

# Validate hooks directory is writable
if [ -d "$HOOKS_DIR" ] && [ ! -w "$HOOKS_DIR" ]; then
    echo "❌ ERROR: Hooks directory is not writable: $HOOKS_DIR"
    exit 1
fi

echo "=== Git Hooks Setup ==="
echo ""

# Create hooks directory if it doesn't exist
if [ ! -d "$HOOKS_DIR" ]; then
    echo "Creating hooks directory..."
    mkdir -p "$HOOKS_DIR"
fi

# Install pre-commit hook
echo "Installing pre-commit hook..."
cat > "$HOOKS_DIR/pre-commit" << 'EOF'
#!/bin/bash
#
# Git Pre-Commit Hook: Branch Protection
#
# Prevents direct commits to main/master branches.
# Encourages feature branch workflow for safety.
#

BRANCH=$(git branch --show-current)

# Block commits to protected branches
if [ "$BRANCH" = "main" ] || [ "$BRANCH" = "master" ]; then
    echo ""
    echo "❌ ERROR: Direct commits to '$BRANCH' are not allowed"
    echo ""
    echo "This is a safety measure to protect your work."
    echo ""
    echo "📝 Create a feature branch instead:"
    echo "   git checkout -b feature/your-feature-name"
    echo ""
    echo "Or for session-based work:"
    echo "   git checkout -b session/$(date +%Y%m%d-%H%M)-description"
    echo ""
    echo "⚠️  To bypass this hook (NOT recommended):"
    echo "   git commit --no-verify"
    echo ""
    exit 1
fi

# Success - allow commit
echo "✅ Committing to branch: $BRANCH"
exit 0
EOF

chmod +x "$HOOKS_DIR/pre-commit"

echo "✅ Pre-commit hook installed"
echo ""

# Verify installation
if [ -x "$HOOKS_DIR/pre-commit" ]; then
    echo "✅ Hook is executable"
else
    echo "❌ Hook is not executable!"
    exit 1
fi

echo ""
echo "=== Setup Complete ==="
echo ""
echo "Git hooks have been installed successfully."
echo ""
echo "Features:"
echo "  • Blocks direct commits to main/master"
echo "  • Encourages feature branch workflow"
echo ""
```

**Key Features of setup-git-hooks.sh**:

1. **Dynamic Path Resolution**: Script automatically detects repository root regardless of clone location:
   ```bash
   SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
   REPO_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
   HOOKS_DIR="$REPO_ROOT/.git/hooks"
   ```
   - Works with any repository path (not hard-coded to `/workspaces/claude-devcontainer`)
   - Portable across different environments and clone locations
   - Resolves paths relative to script location

2. **Strict Error Handling**: `set -euo pipefail` ensures robust script execution:
   - `-e`: Exit immediately if any command fails
   - `-u`: Treat unset variables as errors
   - `-o pipefail`: Catch failures in piped commands

3. **Validation Checks**: Script validates prerequisites before installation:
   - Verifies `.git` directory exists (ensures running in git repository)
   - Checks hooks directory is writable (prevents permission errors)
   - Provides clear error messages with diagnostic information

**Step 2: Automatic Installation** (Recommended):

The git hook is automatically installed on every container start via `postStartCommand` in `devcontainer.json`:

```json
"postStartCommand": "sudo /usr/local/bin/init-claude-config.sh && sudo /usr/local/bin/init-codex-config.sh && sudo /usr/local/bin/init-firewall.sh && bash ${containerWorkspaceFolder}/.devcontainer/setup-git-hooks.sh"
```

**Benefits**:
- No manual installation required after container rebuild
- Hooks always present in fresh clones
- Consistent enforcement across team members
- Zero-friction developer experience

**Manual Installation** (if `postStartCommand` not configured):

If automatic installation is not set up, run manually after cloning or rebuilding:

```bash
# From repository root
bash .devcontainer/setup-git-hooks.sh
```

**Expected output**:
```
=== Git Hooks Setup ===

Installing pre-commit hook...
✅ Pre-commit hook installed

✅ Hook is executable

=== Setup Complete ===

Git hooks have been installed successfully.

Features:
  • Blocks direct commits to main/master
  • Encourages feature branch workflow
```

#### Testing the Hook

**Test 1: Verify hook blocks commits to main**

```bash
# Switch to main branch
git checkout main

# Try to commit (should be blocked)
echo "test" > /tmp/test-hook.txt
git add /tmp/test-hook.txt
git commit -m "test"
```

**Expected output** (hook blocks commit):
```
❌ ERROR: Direct commits to 'main' are not allowed

This is a safety measure to protect your work.

📝 Create a feature branch instead:
   git checkout -b feature/your-feature-name

Or for session-based work:
   git checkout -b session/20251029-1430-description

⚠️  To bypass this hook (NOT recommended):
   git commit --no-verify
```

**Test 2: Verify hook allows commits to feature branches**

```bash
# Create and switch to feature branch
git checkout -b feature/test-hook

# Commit should succeed
git add /tmp/test-hook.txt
git commit -m "test commit"
```

**Expected output** (hook allows commit):
```
✅ Committing to branch: feature/test-hook
[feature/test-hook abc1234] test commit
 1 file changed, 1 insertion(+)
```

**Test 3: Clean up test branch**

```bash
# Switch back to main and delete test branch
git checkout main
git branch -D feature/test-hook
rm /tmp/test-hook.txt
```

#### Pre-Work Sync Check (MANDATORY)

**Before creating any new branch**, ALWAYS ensure master is up-to-date with remote:

```bash
# 1. Switch to master
git checkout master

# 2. Fetch latest (safe, doesn't merge)
git fetch origin

# 3. Check status
git status
```

**Status interpretations and actions**:

✅ **"Your branch is up to date with 'origin/master'"** → Proceed with branch creation

⚠️ **"Your branch is behind 'origin/master' by X commits"** → Pull first:
```bash
git pull origin master
git status  # Verify now "up to date"
```

❌ **"Your branch and 'origin/master' have diverged"** → Resolve divergence:
```bash
# Option 1: No local commits (safe reset)
git reset --hard origin/master

# Option 2: Have local commits (merge/rebase)
git pull origin master  # Creates merge commit
# OR
git rebase origin/master  # Linear history
```

**Why this matters**:
- Ensures branches start from latest code
- Reduces merge conflicts later
- Prevents building on outdated codebase
- Maintains clean git history

**Only after master is up-to-date**, create your branch:

```bash
git checkout -b feature/your-feature-name
# OR
git checkout -b session/$(date +%Y%m%d-%H%M)-description
```

#### Branch Naming Conventions

**Feature branches** (long-term work):
```bash
git checkout -b feature/add-authentication
git checkout -b feature/update-api
git checkout -b fix/broken-login
git checkout -b refactor/clean-up-code
```

**Session branches** (exploratory/AI-assisted work):
```bash
# Format: session/YYYYMMDD-HHMM-description
git checkout -b session/20251029-1045-add-firewall
git checkout -b session/20251029-1430-fix-bug
git checkout -b session/20251029-1600-update-docs
```

#### Troubleshooting

**Problem: Hook doesn't block commits**

**Check if hook is installed**:
```bash
test -x .git/hooks/pre-commit && echo "✅ Hook installed" || echo "❌ Hook missing"
```

**If missing, reinstall**:
```bash
bash .devcontainer/setup-git-hooks.sh
```

**Problem: Permission denied error**

**Make hook executable**:
```bash
chmod +x .git/hooks/pre-commit
```

**Verify permissions**:
```bash
ls -la .git/hooks/pre-commit
# Should show: -rwxr-xr-x (note the 'x' permissions)
```

**Problem: Hook needs to be bypassed for emergency fix**

**Temporary bypass** (NOT recommended):
```bash
git commit --no-verify -m "emergency hotfix"
```

**Better approach**:
1. Create hotfix branch: `git checkout -b hotfix/critical-fix`
2. Make your fix and commit normally
3. Merge via pull request workflow

#### Automatic Installation (Optional)

**Add to devcontainer.json postCreateCommand**:

```json
{
  "postCreateCommand": "bash .devcontainer/setup-git-hooks.sh"
}
```

**Trade-offs**:
- ✅ Automatic installation after container creation
- ✅ Developers can't forget to install
- ❌ Runs on every rebuild (adds ~1 second to startup)
- ❌ May be noisy with repeated "hook installed" messages

#### How It Works

1. **Hook execution**: Git automatically runs `.git/hooks/pre-commit` before every commit
2. **Branch check**: Hook reads current branch name with `git branch --show-current`
3. **Protection**: If branch is `main` or `master`, hook exits with code 1 (blocks commit)
4. **Bypass**: Users can override with `--no-verify` flag if absolutely necessary

#### Benefits

- **Technical enforcement**: Not just guidance - actually prevents the commit
- **Zero performance impact**: Only runs during commits (not during file operations)
- **Clear error messages**: Provides helpful guidance when blocking commits
- **Flexible**: Can be bypassed in genuine emergencies
- **Minimal**: Simple bash script, no dependencies

#### Limitations

- **Must be installed manually**: Doesn't transfer with git clone
- **Container rebuilds**: Need to reinstall after rebuilding devcontainer
- **Can be bypassed**: `--no-verify` flag disables all hooks
- **Only affects git commits**: Doesn't prevent file deletion before commits

#### Integration with AI Assistants

**For Claude Code users**, this hook integrates with:
- **CLAUDE.md** - Git Safety Protocol provides workflow guidance
- **git-pr-helper skill** - Assists with PR creation and merge workflow
- **CLAUDE-patterns.md** - Documents git workflow conventions

**Three-layer defense**:
1. **Hook** (enforcement) - Blocks commits technically
2. **CLAUDE.md** (guidance) - Instructions for AI workflow
3. **Skill** (assistance) - Helps with PR/merge operations

#### Complete Test Procedure

```bash
# 1. Verify hook installation
test -x .git/hooks/pre-commit && echo "✅ Installed" || echo "❌ Missing"

# 2. Test main branch protection (should FAIL)
git checkout main
echo "test" > /tmp/test-hook.txt
git add /tmp/test-hook.txt
git commit -m "test"  # Should be blocked

# 3. Clean up
git reset HEAD /tmp/test-hook.txt

# 4. Test feature branch (should SUCCEED)
git checkout -b feature/test-verification
git add /tmp/test-hook.txt
git commit -m "test"  # Should succeed

# 5. Clean up test branch
git checkout main
git branch -D feature/test-verification
rm /tmp/test-hook.txt

# 6. Verify hook still active
test -x .git/hooks/pre-commit && echo "✅ Hook still installed"
```

#### References

- [setup-git-hooks.sh](./setup-git-hooks.sh) - Hook installation script
- [Git Hooks Documentation](https://git-scm.com/docs/githooks) - Official git hooks reference
- [CLAUDE-troubleshooting.md](../CLAUDE-troubleshooting.md) - Detailed troubleshooting guide

---

### GitHub CLI Authentication

The GitHub CLI (`gh`) is pre-installed for creating pull requests and managing repositories from the terminal. It requires one-time authentication that persists across container rebuilds.

#### Why GitHub CLI Matters

**Git workflow integration**:
- Create pull requests: `gh pr create`
- Manage issues: `gh issue list`
- View PR status: `gh pr status`
- Review code: `gh pr view`

**Required for**:
- git-pr-helper skill (PR creation and merge coordination)
- CLAUDE.md Git Safety Protocol workflows
- Pull request-based development workflows

**Without authentication**: Commands fail with:
```
To get started with GitHub CLI, please run:  gh auth login
Alternatively, populate the GH_TOKEN environment variable with a GitHub API authentication token.
```

#### Method 1: Web Browser Authentication (Recommended)

**Interactive setup**:
```bash
gh auth login
```

**Step-by-step flow**:
```
? What account do you want to log into?
  ▸ GitHub.com
    GitHub Enterprise Server

? What is your preferred protocol for Git operations?
    HTTPS
  ▸ SSH

? Authenticate Git with your GitHub credentials?
  ▸ Yes
    No

? How would you like to authenticate GitHub CLI?
  ▸ Login with a web browser
    Paste an authentication token

! First copy your one-time code: XXXX-XXXX
Press Enter to open github.com in your browser...
```

**Browser steps**:
1. Browser opens to https://github.com/login/device
2. Paste the one-time code
3. Click "Authorize GitHub CLI"
4. Return to terminal

**Success message**:
```
✓ Authentication complete.
- gh config set -h github.com git_protocol https
✓ Configured git protocol
✓ Logged in as your-username
```

#### Method 2: Personal Access Token

**When to use**:
- Headless environments (no browser)
- Automation/CI workflows
- Pre-configured authentication

**Create token**:
1. Go to https://github.com/settings/tokens
2. Click "Generate new token" → "Generate new token (classic)"
3. Select scopes:
   - `repo` - Full repository access
   - `workflow` - Update GitHub Actions
   - `read:org` - Read organization data
4. Generate and copy token (shown once)

**Method A: Interactive**:
```bash
gh auth login --with-token
# Paste token and press Enter
```

**Method B: File-based**:
```bash
echo "ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx" > /tmp/gh-token.txt
gh auth login --with-token < /tmp/gh-token.txt
rm /tmp/gh-token.txt  # Clean up
```

**Method C: Environment variable (.env file)**:
```bash
# In .env file
GH_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Restart container to load .env
# gh will automatically use GH_TOKEN
```

#### Persistence

**Storage location**:
```
/home/node/.config/gh/hosts.yml
```

**Docker volume backing**:
```json
{
 "mounts": [
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

**Persistence behavior**:
- ✅ Survives container rebuilds
- ✅ Survives VS Code restarts
- ✅ One-time setup per devcontainer volume
- ❌ Lost only if volume deleted: `docker volume rm ghub-config-xxx`

**Verify persistence**:
```bash
# Before rebuild
gh auth status

# Rebuild container (Cmd+Shift+P → "Rebuild Container")

# After rebuild
gh auth status  # Should still show authenticated
```

#### Verification and Testing

**Check authentication status**:
```bash
gh auth status
```

**Expected output (authenticated)**:
```
github.com
  ✓ Logged in to github.com as your-username (/home/node/.config/gh/hosts.yml)
  ✓ Git operations protocol: https
  ✓ Token: *******************
```

**Expected output (not authenticated)**:
```
github.com
  ✗ Not logged in
  Run 'gh auth login' to authenticate
```

**Test GitHub CLI functionality**:
```bash
# List your repositories
gh repo list

# View pull requests
gh pr list

# Check API rate limit
gh api rate_limit
```

#### Troubleshooting

**Problem**: `gh pr create` fails with authentication error

**Solution**:
```bash
# Check current status
gh auth status

# If not authenticated, run setup
gh auth login

# Follow interactive prompts
```

**Problem**: Authentication lost after container rebuild

**Root cause**: `/home/node/.config/gh` not mounted as volume

**Solution**: Verify devcontainer.json has gh mount:
```json
{
 "mounts": [
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

**Problem**: Token expired or revoked

**Symptoms**:
```
gh: authentication token invalid
```

**Solution**:
```bash
# Re-authenticate
gh auth login

# Or refresh token
gh auth refresh
```

**Problem**: Permission denied errors for certain operations

**Root cause**: Token missing required scopes

**Solution**: Create new token with required scopes (repo, workflow, read:org)

#### Security Best Practices

**Token scope principle**: Request minimum necessary permissions
- PR creation only: `repo` scope sufficient
- GitHub Actions workflows: Add `workflow` scope
- Organization access: Add `read:org` scope

**Token rotation**: Rotate tokens periodically (every 90 days recommended)

**Environment isolation**: Each devcontainer has isolated `/home/node/.config/gh`
- No credential sharing between projects
- Tokens don't leak to host system
- Per-project access control

**Token storage**:
- ✅ Stored in Docker volume (isolated, persistent)
- ✅ Not committed to git (`.gitignore` excludes `.env`)
- ❌ Never hardcode tokens in devcontainer.json

**Revoke compromised tokens**:
1. Go to https://github.com/settings/tokens
2. Find and click token
3. Click "Delete" or "Revoke"
4. Re-run `gh auth login` in container

#### Integration with Git Workflows

**Pull request creation**:
```bash
# Create feature branch
git checkout -b feature/new-feature

# Make changes and commit
git add .
git commit -m "Add new feature"

# Push and create PR (gh auto-pushes if needed)
gh pr create --title "Add new feature" --body "Description"
```

**View PR status**:
```bash
# List PRs for current repo
gh pr list

# View specific PR
gh pr view 123

# Check PR checks/status
gh pr checks
```

**Merge PR**:
```bash
# Merge with default strategy
gh pr merge 123

# Squash merge
gh pr merge 123 --squash

# Rebase merge
gh pr merge 123 --rebase
```

#### References

- [GitHub CLI Documentation](https://cli.github.com/manual/) - Official gh documentation
- [GitHub Personal Access Tokens](https://github.com/settings/tokens) - Create and manage tokens
- [GitHub CLI Authentication](https://cli.github.com/manual/gh_auth_login) - Authentication methods
- [Git Safety Protocol](../CLAUDE.md#git-safety-protocol) - Workflow guidance using gh

---

### Runtime Security Tools

#### gVisor (Application Kernel)

**What**: Sandboxes containers with application kernel for enhanced isolation.

**Install**:
```bash
# Install gVisor
wget https://storage.googleapis.com/gvisor/releases/release/latest/x86_64/runsc
chmod +x runsc
sudo mv runsc /usr/local/bin/

# Configure Docker
sudo mkdir -p /etc/docker
cat <<EOF | sudo tee /etc/docker/daemon.json
{
 "runtimes": {
 "runsc": {
 "path": "/usr/local/bin/runsc"
 }
 }
}
EOF

sudo systemctl restart docker
```

**Use with devcontainer**:
```json
{
 "runArgs": ["--runtime=runsc"]
}
```

**Official Docs**: https://gvisor.dev/docs/user_guide/quick_start/docker/

---

#### Falco (Runtime Threat Detection)

**What**: Detects abnormal behavior in running containers.

**Install**:
```bash
# Helm install
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm install falco falcosecurity/falco
```

**Monitor devcontainers**:
Falco alerts on:
- Unexpected network connections
- File access violations
- Privilege escalation attempts
- Suspicious process spawning

**Official Docs**: https://falco.org/docs/

---

### Seccomp and AppArmor Profiles

Restrict syscalls and capabilities.

**Custom seccomp profile** (restrict-syscalls.json):
```json
{
 "defaultAction": "SCMP_ACT_ERRNO",
 "architectures": ["SCMP_ARCH_X86_64"],
 "syscalls": [
 {
 "names": ["read", "write", "open", "close", "stat", "fstat", "lstat"],
 "action": "SCMP_ACT_ALLOW"
 }
 ]
}
```

**Apply to devcontainer**:
```json
{
 "runArgs": [
 "--security-opt=seccomp=./restrict-syscalls.json"
 ]
}
```

**AppArmor profile**:
```bash
# Load custom profile
sudo apparmor_parser -r -W /etc/apparmor.d/docker-devcontainer
```

**Official Docs**:
- Seccomp: https://docs.docker.com/engine/security/seccomp/
- AppArmor: https://docs.docker.com/engine/security/apparmor/

---

### Capability Restrictions

Drop unnecessary Linux capabilities.

**Best practice**: Drop all, add only required.

```json
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_BIND_SERVICE" // Only if binding to ports <1024
 ]
}
```

**Common capabilities**:
- `NET_BIND_SERVICE`: Bind to privileged ports (<1024)
- `SYS_PTRACE`: Debugging with gdb/strace
- `SYS_ADMIN`: Mount filesystems (usually not needed)

**Check container capabilities**:
```bash
docker inspect <container-id> | jq '.[0].HostConfig.CapAdd'
docker inspect <container-id> | jq '.[0].HostConfig.CapDrop'
```

**Official Docs**: https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities

---

### Security Scanning in CI/CD

Scan devcontainer images before deployment.

**Trivy** (vulnerability scanner):
```yaml
# .github/workflows/security-scan.yml
- name: Build devcontainer
 run: devcontainer build --workspace-folder . --image-name myapp-dev:test

- name: Scan with Trivy
 uses: aquasecurity/trivy-action@master
 with:
 image-ref: 'myapp-dev:test'
 format: 'sarif'
 output: 'trivy-results.sarif'

- name: Upload results to GitHub Security
 uses: github/codeql-action/upload-sarif@v2
 with:
 sarif_file: 'trivy-results.sarif'
```

**Official Docs**: https://github.com/aquasecurity/trivy

---

### Sources
- **Docker Security Overview**: https://docs.docker.com/engine/security/
- **Enhanced Container Isolation**: https://docs.docker.com/security/for-admins/hardened-desktop/enhanced-container-isolation/
- **User Namespaces**: https://docs.docker.com/engine/security/userns-remap/
- **Seccomp Profiles**: https://docs.docker.com/engine/security/seccomp/
- **AppArmor**: https://docs.docker.com/engine/security/apparmor/
- **gVisor**: https://gvisor.dev/docs/
- **Falco**: https://falco.org/docs/
- **Network Security**: https://docs.docker.com/network/network-tutorial-standalone/

---


---


When encountering devcontainer issues, follow this systematic diagnostic process:

### Step 1: Identify Error Category

```
Where did the error occur?
├─ Building container? → Go to Step 2: Build Failures
├─ Starting container? → Go to Step 3: Startup Failures
├─ Inside container (tool not working)? → Go to Step 4: Runtime Issues
└─ VS Code connection? → Go to Step 5: VS Code Integration Issues
```

### Step 2: Build Failures

**Symptoms**: "docker build failed", "command not found during build"

**Debug Process**:

```bash
# 1. Check Docker is running
docker ps # Should NOT error

# 2. View full build logs
# Command Palette → "Dev Containers: Rebuild Container" → Watch Output panel

# 3. Test Dockerfile directly (bypass VS Code)
cd .devcontainer
docker build -t test-build .
# This shows exact line where build fails

# 4. Common fixes:
```

**Common build errors**:

| Error Message | Cause | Fix |
|---------------|-------|-----|
| `E: Package 'xyz' has no installation candidate` | Package name wrong or not in repos | Update `apt-get update` or check spelling |
| `npm ERR! code ENOTFOUND` | Network issue | Check internet, try different npm registry |
| `Permission denied` | Running as wrong user | Check `USER node` comes after `RUN npm install` |
| `/bin/sh: 1: xyz: not found` | PATH not set or tool not installed | Verify tool installation in Dockerfile |

### Step 3: Startup Failures

**Symptoms**: Container builds but fails to start, postStartCommand errors

**Debug Process**:

```bash
# 1. View container logs
docker ps -a # Find container ID (even if stopped)
docker logs <container-id>

# 2. Check postStartCommand (comment it out temporarily)
# In devcontainer.json:
// "postStartCommand": "sudo /usr/local/bin/init-firewall.sh",

# 3. Try starting container manually
docker run -it <image-id> /bin/bash
# Now run postStartCommand manually to see exact error

# 4. Check init scripts have execute permissions
ls -la .devcontainer/*.sh
# Should show: -rwxr-xr-x (x = executable)

# Fix if needed:
chmod +x .devcontainer/*.sh
```

### Step 4: Runtime Issues (Inside Container)

**Symptoms**: Container runs, but "command not found", "permission denied", or tools don't work

**Debug Process**:

```bash
# 1. Verify PATH
echo $PATH
# Should include /usr/local/bin, /home/node/.npm-global/bin, etc.

# 2. Check tool installation
which claude
which node
which python3

# 3. If "command not found":
ls -la /home/node/.npm-global/bin # Check if binary exists
npm list -g --depth=0 # List global npm packages

# 4. Test tool directly with full path
/home/node/.npm-global/bin/claude --version

# 5. Check environment variables
env | grep -i claude
env | grep -i path

# 6. Fix PATH in devcontainer.json
{
 "containerEnv": {
 "PATH": "/usr/local/bin:/home/node/.npm-global/bin:${containerEnv:PATH}"
 }
}
```

### Step 5: VS Code Integration Issues

**Symptoms**: Extensions don't install, ports don't forward, terminal doesn't open

**Debug Process**:

```bash
# 1. Check VS Code Server installed in container
docker exec <container-id> ls -la /home/node/.vscode-server

# 2. Reinstall VS Code Server
# Command Palette → "Dev Containers: Rebuild Container Without Cache"

# 3. Check extension installation
# View → Extensions → Filter to "Installed"
# Should show extensions from devcontainer.json

# 4. Manually install extension
# Command Palette → "Extensions: Install Extension"

# 5. Check port forwarding
# Ports tab in VS Code (bottom panel)
# Manually forward: Right-click port → "Forward Port"

# 6. Reset VS Code Remote connection
# Delete ~/.vscode-server in container
docker exec <container-id> rm -rf /home/node/.vscode-server
# Restart VS Code
```

### Step 6: Nuclear Options (When All Else Fails)

```bash
# 1. Rebuild without cache
# Command Palette → "Dev Containers: Rebuild Container Without Cache"

# 2. Remove container and volumes
docker ps -a | grep "your-project"
docker rm -f <container-id>
docker volume ls | grep "your-project"
docker volume rm <volume-name>

# 3. Clean Docker entirely
docker system prune -a --volumes # CAUTION: Removes everything!

# 4. Restart Docker Desktop
# Quit Docker Desktop → Wait 30 seconds → Restart

# 5. Reset Docker Desktop to factory settings
# Docker Desktop → Troublesoot → Reset to factory defaults
```

---

## Volume Persistence Patterns

Volumes ensure configuration persists across container rebuilds.

### Named Volumes (Recommended for Configs)

**Pattern**: `source=<name>-${devcontainerId},target=<path>,type=volume`

```json
{
 "mounts": [
 "source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
 "source=bashhistory-${devcontainerId},target=/commandhistory,type=volume",
 "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume"
 ]
}
```

**Benefits**:
- Unique per devcontainer instance (`${devcontainerId}` auto-generated)
- Survives container deletion (until `docker volume rm`)
- Fast performance (Docker-managed)
- Easy to inspect: `docker volume ls`, `docker volume inspect <name>`

**Use cases**: API keys, shell history, package caches

### Bind Mounts (Advanced/Special Cases)

**Pattern**: `source=/host/path,target=/container/path,type=bind`

```json
{
 "mounts": [
 "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,readonly",
 "source=${localWorkspaceFolder}/data,target=/data,type=bind"
 ]
}
```

**Benefits**:
- Direct access to host filesystem
- Changes reflect immediately on both sides
- Useful for debugging, shared data

**Cautions**:
- ️ Exposes host filesystem (security risk if container compromised)
- ️ Platform-specific paths (`/Users/` on Mac, `/home/` on Linux, WSL paths on Windows)
- ️ Performance issues on Mac/Windows (Docker Desktop overhead)

**Use cases**: SSH keys (readonly!), large datasets, debugging

### Common Persisted Paths

```json
{
 "mounts": [
 // AI tool configurations (critical!)
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=codex-${devcontainerId},target=/home/node/.codex,type=volume",
 "source=gemini-${devcontainerId},target=/home/node/.gemini,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",

 // Shell history (quality of life)
 "source=bashhistory-${devcontainerId},target=/commandhistory,type=volume",

 // Package manager caches (speeds up rebuilds)
 "source=npm-cache-${devcontainerId},target=/home/node/.npm,type=volume",
 "source=cargo-${devcontainerId},target=/home/node/.cargo,type=volume",
 "source=pip-cache-${devcontainerId},target=/home/node/.cache/pip,type=volume"
 ]
}
```

### Customizing Persistent Mounts for Your Tools

Users should customize the `mounts` array to persist ANY tool configuration they need. Follow the pattern:

**Pattern**:
```
source=<tool-name>-${devcontainerId},target=/home/<user>/<config-path>,type=volume
```

**Universal volumes** (every devcontainer should have):
- `claude-code-bashhistory` → `/commandhistory` - Command history
- `claude-config` → `/home/{user}/.claude` - Claude Code config
- `ghub-config` → `/home/{user}/.config/gh` - GitHub CLI auth

**Language/Runtime volumes** (add based on your stack):

**Node.js/JavaScript/TypeScript**:
- `npm-global` → `/home/node/.npm-global` - Global npm packages (npm install -g)
- `yarn-cache` → `/home/node/.yarn` - Yarn cache

**Python**:
- `pip-cache` → `/home/{user}/.cache/pip` - pip package cache
- `poetry-config` → `/home/{user}/.config/pypoetry` - Poetry config
- `jupyter-config` → `/home/{user}/.jupyter` - Jupyter notebooks

**Rust**:
- `cargo` → `/home/{user}/.cargo` - Cargo packages (also used by Python uv)

**Go**:
- `go-pkg` → `/go/pkg` - Go module cache

**Ruby**:
- `gem` → `/home/{user}/.gem` - Ruby gems

**Java/JVM**:
- `maven` → `/home/{user}/.m2` - Maven packages
- `gradle` → `/home/{user}/.gradle` - Gradle cache

**Multi-AI volumes** (for multi-assistant workflows):
- `codex-config` → `/home/{user}/.codex` - OpenAI Codex config
- `gemini-config` → `/home/{user}/.gemini` - Google Gemini config

**Alternative runtimes**:
- `bun` → `/home/{user}/.bun` - Bun runtime

**Development tool volumes**:

**Container/Orchestration**:
- `docker-config` → `/home/{user}/.docker` - Docker CLI config
- `kubectl-config` → `/home/{user}/.kube` - Kubernetes config

**Infrastructure as Code**:
- `terraform` → `/home/{user}/.terraform.d` - Terraform plugins
- `ansible` → `/home/{user}/.ansible` - Ansible config
- `pulumi` → `/home/{user}/.pulumi` - Pulumi state

**Cloud Providers**:
- `aws-config` → `/home/{user}/.aws` - AWS CLI credentials
- `gcloud-config` → `/home/{user}/.config/gcloud` - Google Cloud SDK
- `azure-config` → `/home/{user}/.azure` - Azure CLI
- `digitalocean` → `/home/{user}/.config/doctl` - DigitalOcean CLI

**Database CLI tools**:
- `psql-config` → `/home/{user}/.psqlrc` and `/home/{user}/.pgpass` - PostgreSQL
- `mysql-config` → `/home/{user}/.my.cnf` - MySQL
- `redis-config` → `/home/{user}/.redisclirc` - Redis CLI
- `mongo-config` → `/home/{user}/.mongorc.js` - MongoDB shell

**Testing/Browser automation**:
- `playwright` → `/home/{user}/.cache/ms-playwright` - Playwright browsers
- `puppeteer` → `/home/{user}/.cache/puppeteer` - Puppeteer browsers
- `cypress` → `/home/{user}/.cache/Cypress` - Cypress

**Build caches**:
- `turborepo` → `/home/{user}/.turbo` - Turborepo cache
- `nx` → `/home/{user}/.nx` - Nx cache
- `bazel` → `/home/{user}/.cache/bazel` - Bazel build cache

**Version managers**:
- `nvm` → `/home/{user}/.nvm` - Node Version Manager
- `rvm` → `/home/{user}/.rvm` - Ruby Version Manager
- `pyenv` → `/home/{user}/.pyenv` - Python version manager

**Example: Full Node.js + Infrastructure setup**:
```json
{
 "mounts": [
 // Universal
 "source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume",
 "source=claude-config-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",

 // Multi-AI
 "source=codex-config-${devcontainerId},target=/home/node/.codex,type=volume",
 "source=gemini-config-${devcontainerId},target=/home/node/.gemini,type=volume",

 // Node.js
 "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume",

 // Cloud/Infrastructure
 "source=docker-config-${devcontainerId},target=/home/node/.docker,type=volume",
 "source=kubectl-config-${devcontainerId},target=/home/node/.kube,type=volume",
 "source=aws-config-${devcontainerId},target=/home/node/.aws,type=volume",

 // Testing
 "source=playwright-${devcontainerId},target=/home/node/.cache/ms-playwright,type=volume"
 ]
}
```

**Finding config locations**:
1. Check tool's documentation for config directory
2. Look for dotfiles in home: `ls -la ~/`
3. Use tool's debug/verbose mode to see config paths
4. Common pattern: `~/.config/<tool>` or `~/.<tool>` or `~/.cache/<tool>`

**Pro tips**:
- Use `${devcontainerId}` for isolation between projects
- Adjust paths for your user (`node` vs `vscode` vs custom)
- Mount as `type=volume` for persistence, `type=bind` for host access
- Add `readonly` for security: `type=bind,readonly`

### Inspecting and Managing Volumes

```bash
# List all volumes
docker volume ls

# Inspect specific volume (shows mount point, size)
docker volume inspect claude-code-config-<devcontainerId>

# Access volume data (advanced - mounts volume to temporary Alpine container)
docker run --rm -v claude-code-config-<devcontainerId>:/data alpine ls -la /data

# Backup volume to tarball
docker run --rm -v claude-code-config-<devcontainerId>:/data -v $(pwd):/backup alpine tar czf /backup/claude-backup.tar.gz /data

# Restore volume from tarball
docker run --rm -v claude-code-config-<devcontainerId>:/data -v $(pwd):/backup alpine tar xzf /backup/claude-backup.tar.gz -C /

# Remove unused volumes
docker volume prune

# Remove specific volume (CAUTION: deletes all data!)
docker volume rm claude-code-config-<devcontainerId>
```

### Volume vs Bind Mount Decision Matrix

| Use Case | Volume | Bind Mount |
|----------|--------|------------|
| API keys, configs | | |
| Shell history | | |
| Package caches | | |
| SSH keys (readonly) | | |
| Large datasets (shared with host) | | |
| Source code | (VS Code mounts this) | |
| Debugging container issues | | |

---

## Platform-Specific Notes

### macOS (Intel and Apple Silicon)

**Docker Desktop Settings**:
- Allocate at least 4GB RAM, 8GB recommended
- Enable VirtioFS for better file sharing performance (Preferences → Experimental Features)

**Apple Silicon (M1/M2/M3) Specifics**:
```dockerfile
# Some packages need platform specification
FROM --platform=linux/amd64 node:22 # Force x86 emulation (slower but compatible)
# OR
FROM node:22 # Native ARM64 (faster, but ensure all tools support ARM)
```

**Common Issues**:
- **Slow file sync**: Use VirtioFS instead of osxfs
- **Chromium crashes**: Install `chromium` instead of `google-chrome` in Dockerfile
- **Python package build failures**: Install build tools: `apt-get install -y build-essential`

### Windows (WSL2 Required)

**Prerequisites**:
1. Windows 10/11 version 21H2 or higher
2. WSL2 enabled: `wsl --install` in PowerShell (Admin)
3. Docker Desktop → Settings → "Use WSL2 based engine"

**File System Best Practices**:
- **Store projects in WSL2 filesystem** (`/home/user/projects/`, accessed as `\\wsl$\Ubuntu\home\user\`)
- **Don't store in Windows filesystem** (`C:\Users\...` is slow via Docker)

**Performance**:
```bash
# Clone projects into WSL2 (FAST)
cd ~
git clone https://github.com/your/project.git
code project

# NOT into Windows drive (SLOW)
cd /mnt/c/Users/You/Documents # Slow Docker access
```

**Common Issues**:
- **"Docker daemon not responding"**: Restart Docker Desktop
- **Slow builds**: Ensure project is in WSL2 filesystem, not `/mnt/c/`
- **Line ending issues**: Configure git in WSL: `git config --global core.autocrlf input`

### Linux (Native Docker)

**Recommended**: Ubuntu 20.04+, Debian 11+, or equivalent

**Installation** (Ubuntu/Debian):
```bash
# Install Docker Engine (not Desktop)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Add user to docker group (no sudo needed)
sudo usermod -aG docker $USER
newgrp docker # Apply without logout

# Verify
docker run hello-world
```

**File Permissions**:
- Linux containers use **same UID/GID** as files
- If user in container is UID 1000, files will be owned by your host user (UID 1000)
- **Fix permissions issues**:
 ```dockerfile
 ARG USER_UID=1000
 ARG USER_GID=1000
 RUN groupmod --gid $USER_GID node && \
 usermod --uid $USER_UID --gid $USER_GID node
 ```

**Common Issues**:
- **Permission denied**: Add user to `docker` group
- **Docker socket errors**: `sudo systemctl start docker`
- **Out of disk space**: `docker system prune -a` (cleans up old images)

### Sources

- **Docker Desktop for Mac**: https://docs.docker.com/desktop/mac/
- **Docker Desktop for Windows**: https://docs.docker.com/desktop/windows/
- **WSL2 Setup Guide**: https://docs.docker.com/desktop/windows/wsl/
- **Docker Engine for Linux**: https://docs.docker.com/engine/install/
- **Apple Silicon Compatibility**: https://docs.docker.com/desktop/mac/apple-silicon/

---

## Resource and Performance Considerations

### Disk Space Requirements

**Typical Usage**:
- Base Node.js devcontainer: ~1GB
- With build tools + Chromium: ~2-3GB
- Python data science stack: ~4-5GB
- **Recommendation**: Keep 20GB free for comfortable development

**Monitoring**:
```bash
# Check Docker disk usage
docker system df

# Detailed breakdown
docker system df -v
```

**Cleanup Strategies**:
```bash
# Remove old containers (keep images/volumes)
docker container prune

# Remove unused images (rebuilds will redownload)
docker image prune -a

# Remove unused volumes (CAUTION: deletes configs if not careful)
docker volume prune

# Weekly maintenance (safe)
docker container prune && docker image prune
```

### Memory Allocation

**Defaults** (Docker Desktop):
- Mac: 2GB (increase to 4-8GB)
- Windows: 2GB (increase to 4-8GB)
- Linux: No limit (uses host RAM)

**Recommendations by Use Case**:
- Simple Node.js/Python dev: 4GB
- Full-stack with databases: 8GB
- Data science (pandas, ML): 8-16GB

**Configure** (Docker Desktop → Preferences → Resources → Memory)

**Monitor**:
```bash
# Real-time container resource usage
docker stats

# Specific container
docker stats <container-id>
```

### CPU Allocation

**Defaults**: Docker Desktop uses available cores

**Limit CPUs** (if needed):
```json
{
 "runArgs": [
 "--cpus=2"
 ]
}
```

### Build Performance Optimization

**Layer Caching**:
```dockerfile
# GOOD: Dependency changes rarely, cache this layer
COPY package.json package-lock.json ./
RUN npm install
COPY . . # Source code changes frequently

# BAD: Any source change rebuilds npm install
COPY . .
RUN npm install
```

**Multi-stage Builds** (advanced):
```dockerfile
# Build stage
FROM node:22 AS builder
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Runtime stage (smaller final image)
FROM node:22-slim
COPY --from=builder /app/dist /app
```

**Parallel Package Installation**:
```dockerfile
# npm: Use npm ci (faster than npm install)
RUN npm ci

# Python: Use uv instead of pip
RUN pip install uv && uv pip install -r requirements.txt
```

**Always Upgrade npm to Latest** (October 2025 best practice):

```dockerfile
FROM node:22

# IMPORTANT: Upgrade npm immediately after base image
# Why: node:22 ships with npm 10.8.x, latest is 10.9.x+
# Benefits: Security patches, performance improvements, bug fixes
RUN npm install -g npm@latest

# Then continue with your Dockerfile...
```

**Why this matters**:
- Base images ship with npm version from their build date (often months old)
- npm releases security patches frequently
- Newer npm versions have performance optimizations
- `apt-get update` won't upgrade npm (it's installed via Node.js, not apt)

**Real-world impact**:
```bash
# Without npm upgrade (node:22 default):
npm --version # 10.8.2

# With npm upgrade:
npm --version # 10.9.2 (latest at time of build)
```

**Performance benefit**:
- npm 10.9+ has improved lockfile handling
- Faster `npm install` operations
- Better error messages for troubleshooting

**Best practice location in Dockerfile**:
```dockerfile
FROM node:22

ARG TZ
ENV TZ="$TZ"

# DO THIS EARLY (before installing other packages)
RUN npm install -g npm@latest

# Then continue with system packages
RUN apt-get update && apt-get install -y ...
```

**Why early in Dockerfile**:
- Ensures all subsequent npm operations use latest version
- Prevents version inconsistencies
- Better layer caching (npm version rarely changes)

### BuildKit Cache Mounts (5-10x Faster Rebuilds)

**Critical Performance Optimization** (October 2025 best practice):

BuildKit cache mounts dramatically speed up Docker builds by caching package downloads between builds.

**Problem with traditional builds**:
```dockerfile
# BAD: Redownloads packages on EVERY rebuild
RUN apt-get update && apt-get install -y \
 git curl wget chromium
```

**Result**: Even minor Dockerfile changes force re-downloading 500MB+ of packages

**Solution: BuildKit cache mounts**:
```dockerfile
# GOOD: Packages cached, only download new/changed ones
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
 --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
 apt-get update && apt-get install -y \
 git curl wget chromium
```

**Performance Impact**:
- **First build**: ~10 minutes (downloads everything)
- **Subsequent builds**: ~2 minutes (reuses cached packages)
- **Speedup**: 5-10x faster rebuilds

**How it works**:
1. `--mount=type=cache` creates a persistent cache directory
2. `target=/var/cache/apt` is where apt stores downloaded .deb files
3. `target=/var/lib/apt/lists` is where apt stores package metadata
4. `sharing=locked` prevents race conditions if multiple builds run concurrently
5. Cache survives Docker layer invalidation

**Complete Example**:

```dockerfile
FROM node:22

# Enable BuildKit (required)
# Set in Docker Desktop or via DOCKER_BUILDKIT=1 docker build

# Upgrade npm to latest with cache
RUN --mount=type=cache,target=/root/.npm \
 npm install -g npm@latest

# Install system packages with cache
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
 --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
 apt-get update && apt-get install -y --no-install-recommends \
 git \
 curl \
 ripgrep \
 fd-find \
 chromium \
 && apt-get clean && rm -rf /var/lib/apt/lists/*

# Note: The "apt-get clean && rm -rf /var/lib/apt/lists/*" at the end
# is still useful to keep the final image layer small, even though
# the cache mount keeps the packages cached separately

USER node

# Note: For production devcontainers, install CLI tools via postCreateCommand
# to avoid volume persistence conflicts. This example shows BuildKit caching only.
# Cache npm packages during global installs (demonstration purpose)
RUN --mount=type=cache,target=/home/node/.npm,uid=1000 \
 npm install -g @anthropic-ai/claude-code@latest

# Recommended: Move to devcontainer.json instead:
# "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest"
```

**Common Cache Locations**:

| Package Manager | Cache Mount Target |
|----------------|-------------------|
| **apt** (Debian/Ubuntu) | `/var/cache/apt` and `/var/lib/apt/lists` |
| **npm** | `/home/node/.npm` or `/root/.npm` |
| **pip** | `/root/.cache/pip` |
| **cargo** (Rust) | `/usr/local/cargo/registry` |
| **go** | `/go/pkg/mod` |

**Enabling BuildKit** (if not already enabled):

```bash
# Method 1: Environment variable (per-build)
DOCKER_BUILDKIT=1 docker build .devcontainer

# Method 2: Docker Desktop settings
# Docker Desktop → Preferences → Docker Engine
# Add: { "features": { "buildkit": true } }

# Method 3: Daemon config (persistent)
# /etc/docker/daemon.json
{
 "features": {
 "buildkit": true
 }
}
```

**VS Code devcontainer.json** (uses BuildKit automatically if Docker Desktop has it enabled):
```json
{
 "build": {
 "dockerfile": "Dockerfile"
 // BuildKit enabled by default in recent Docker Desktop versions
 }
}
```

**Debugging Cache Issues**:

```bash
# View BuildKit cache usage
docker system df -v | grep buildkit

# Clear BuildKit cache (if needed)
docker builder prune

# Build with cache disabled (debugging)
DOCKER_BUILDKIT=1 docker build --no-cache .devcontainer
```

**When NOT to use cache mounts**:
- CI/CD systems without persistent Docker layer cache (cache won't help)
- Security-sensitive builds requiring fresh downloads every time
- Docker versions < 18.09 (BuildKit not available)

**When to ALWAYS use cache mounts**:
- Local development with frequent rebuilds
- Team devcontainers (everyone benefits from caching)
- Large base images (Chromium, ML frameworks, databases)
- Multi-stage builds (cache intermediate stages)

**Combining with .dockerignore**:

Cache mounts work best when combined with `.dockerignore`:

```bash
# .dockerignore - prevents invalidating cache
node_modules/
.git/
.env
*.log
.DS_Store
```

**Real-world impact example**:

```dockerfile
# Before BuildKit cache mounts:
# Rebuild after changing one line: 10 minutes (redownloads Chromium, build tools)

# After BuildKit cache mounts:
# Same rebuild: 2 minutes (uses cached packages)
# Savings: 8 minutes per rebuild
# Over 10 rebuilds per week: 80 minutes saved
```

**Best Practice Checklist**:
- [ ] Use `--mount=type=cache` for apt/yum/apk package managers
- [ ] Use `--mount=type=cache` for language package managers (npm, pip, cargo)
- [ ] Set `sharing=locked` for multi-stage builds or parallel builds
- [ ] Keep `apt-get clean` at end (doesn't affect cache, reduces layer size)
- [ ] Use appropriate UID in cache mount if running as non-root user
- [ ] Document BuildKit requirement in README for team members

### Network Performance

**DNS Issues**:
```json
{
 "runArgs": [
 "--dns=8.8.8.8",
 "--dns=1.1.1.1"
 ]
}
```

### Startup Time Optimization

**Slow postStartCommand?**
```json
{
 // BAD: Runs sequentially
 "postStartCommand": "npm install && pip install -r requirements.txt && rake setup",

 // GOOD: Run in background, non-blocking
 "postStartCommand": "npm install &"
}
```

### Sources

- **Docker Resource Management**: https://docs.docker.com/config/containers/resource_constraints/
- **Docker Desktop Resource Settings**: https://docs.docker.com/desktop/settings/
- **Performance Best Practices**: https://docs.docker.com/develop/dev-best-practices/
- **Build Cache Optimization**: https://docs.docker.com/build/cache/

---

## Step-by-Step Debug Process

## Common Mistakes and Gotchas

### 1. Installing Tools as Root, Then Switching to Node User

**Mistake**:
```dockerfile
USER node
RUN apt-get install -y git # ERROR: Permission denied
```

**Fix**: Install system packages as root, then switch to node:
```dockerfile
USER root
RUN apt-get install -y git
USER node
```

### 2. Not Persisting Volumes for AI Configurations

**Mistake**:
```json
{
 "mounts": [] // No volumes!
}
```

**Result**: API keys lost on every rebuild

**Fix**:
```json
{
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

### 3. Using `npm install` Instead of `npm ci` in Dockerfile

**Mistake**:
```dockerfile
RUN npm install # Slower, non-deterministic
```

**Fix**:
```dockerfile
# For Dockerfile builds (deterministic, faster)
RUN npm ci

# For postCreateCommand (flexible, after container starts)
"postCreateCommand": "npm install"
```

### 4. Forgetting UTF-8 Locale Configuration

**Mistake**: Omitting locale setup → AI tools get encoding errors

**Fix**: Always include:
```dockerfile
RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen && \
 locale-gen
ENV LANG=en_US.UTF-8 \
 LANGUAGE=en_US:en \
 LC_ALL=en_US.UTF-8
```

### 5. Codex CLI Landlock Sandbox Error in Docker Containers

**Problem**: When running `codex` commands, you see:
```
thread 'main' panicked at linux-sandbox/src/linux_run_main.rs:30:9:
error running landlock: Sandbox(LandlockRestrict)
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
```

**Root Cause**:
- Docker Desktop's LinuxKit kernel doesn't include **Landlock** support
- Landlock is a Linux security module (LSM) required by Codex's default sandbox
- LinuxKit uses a minimal kernel configuration for performance
- Known limitation of containerized environments

**Why This Happens**:
```bash
# Check if Landlock is available
cat /proc/sys/kernel/landlock/version
# => No such file or directory (not in LinuxKit kernel)

# Your kernel
uname -r
# => 6.10.14-linuxkit (minimal kernel config)
```

**Solution**: OpenAI's Official Recommendation

Disable Codex sandboxing in containers - Docker provides isolation instead.

**Configuration**: `~/.codex/config.toml`
```toml
sandbox_mode = "danger-full-access"
approval_policy = "never"
```

**Why This Is Safe**:
- Docker container already provides process isolation
- Network firewall restricts outbound connections (init-firewall.sh)
- Container runs as non-root user (node)
- Limited Linux capabilities (NET_ADMIN, NET_RAW, SETUID, SETGID only)
- OpenAI officially recommends this for Docker environments

**Verification**:
```bash
# Test Codex works
codex --version
# => codex-cli 0.50.0

# Test command execution
codex exec "echo 'Hello from Codex'"
# => Should execute successfully without sandbox errors

# Verify config
cat ~/.codex/config.toml | grep sandbox_mode
# => sandbox_mode = "danger-full-access"
```

**Devcontainer Auto-Configuration**:

This repository's devcontainer automatically applies this fix:
- **Template**: `config.toml.template` in `.devcontainer/`
- **Init script**: `init-codex-config.sh` copies template on startup
- **Persistence**: Configuration survives rebuilds via volume: `codex-config-${devcontainerId}`

**Manual Fix** (if needed):
```bash
# Create config directory
mkdir -p ~/.codex ~/.config/gh

# Create config file
cat > ~/.codex/config.toml <<EOF
model = "gpt-5"
model_reasoning_effort = "medium"
sandbox_mode = "danger-full-access"
approval_policy = "never"
EOF
```

**References**:
- [OpenAI Codex Sandbox Documentation](https://github.com/openai/codex/blob/main/docs/sandbox.md)
- [GitHub Issue: Unable to skip sandboxing #973](https://github.com/openai/codex/issues/973)
- [Docker + Codex discussion](https://github.com/Diatonic-AI/codex-cli-docker-mcp)

**Alternative Solutions** (not recommended):
- Adding `SYS_ADMIN` capability doesn't help (kernel doesn't support Landlock)
- Environment variable `CODEX_UNSAFE_ALLOW_NO_SANDBOX` has limited support
- Switching to different Linux kernel (breaks Docker Desktop compatibility)

**Best Practice**: Trust your container's isolation layer, disable Codex's redundant sandboxing.

**️ Known Limitation: VSCode Extension**

**IMPORTANT**: The above configuration **only works for Codex CLI**, not the VSCode extension.

**VSCode Extension Issue**:
- VSCode extension does NOT read `sandbox_mode` or `approval_policy` from config.toml
- Extension only reads `model` and `model_reasoning_effort` settings
- Extension always tries to use Landlock sandboxing (fails in Docker)
- 📋 Tracked as [GitHub Issue #5041](https://github.com/openai/codex/issues/5041)

**OpenAI Team Response** (from issue #5041):
> "Currently we actually do not read or write our `network_access` and `sandbox_mode` to config.toml but only the `model` and `model_reasoning_effort` settings. We are currently working on a custom mode which will allow you to use approval and sandbox policy from config.toml."

**Workaround**:
- Use **Codex CLI** instead of VSCode extension: `codex exec "your prompt"`
- CLI fully respects config.toml and works perfectly in Docker
- ⏳ Wait for OpenAI to implement config.toml support in extension (no ETA)

**Why VSCode Extension Fails**:
```
User runs command in VSCode extension
 ↓
Extension starts: codex app-server (without sandbox flags)
 ↓
app-server tries to use Landlock sandbox (ignores config.toml)
 ↓
Landlock not available in LinuxKit kernel
 ↓
Error: Sandbox(LandlockRestrict)
```

**Why CLI Works**:
```
User runs: codex exec "prompt"
 ↓
CLI reads ~/.codex/config.toml
 ↓
Uses sandbox_mode = "danger-full-access"
 ↓
No Landlock required
 ↓
 Command executes successfully
```

**Status**: This is a known limitation with no official workaround. Use the CLI until OpenAI adds config.toml support to the extension.

### 6. Hardcoding Absolute Paths in devcontainer.json

**Mistake**:
```json
{
 "workspaceFolder": "/workspaces/my-project" // Breaks if project renamed
}
```

**Fix**:
```json
{
 "workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}" // Dynamic
}
```

### 6. Not Ignoring `.claude/settings.local.json` in Git

**Mistake**: Committing API keys to git

**Fix**: Always configure in Dockerfile:
```dockerfile
RUN git config --global core.excludesfile ~/.gitignore_global && \
 echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

### 7. Using Bind Mounts for Credentials

**Mistake**:
```json
{
 "mounts": [
 "source=${localEnv:HOME}/.claude,target=/home/node/.claude,type=bind"
 ]
}
```

**Problem**: Host credentials leak into container (security risk)

**Fix**: Use named volumes (isolated per container):
```json
{
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

### 8. Running `docker system prune -a --volumes` Without Thinking

**Mistake**: Deleting ALL volumes (loses all API keys)

**Fix**: Selectively remove:
```bash
docker volume ls | grep "project-name"
docker volume rm <specific-volume>
```

### 9. Not Testing Dockerfile Independently

**Mistake**: Only testing via VS Code (slow iteration)

**Fix**: Test Dockerfile directly:
```bash
cd .devcontainer
docker build -t test .
docker run -it test /bin/bash
```

### 10. Using Windows Paths in WSL2 Devcontainers

**Mistake**:
```bash
# Slow! Project in /mnt/c/Users/...
```

**Fix**: Clone projects into WSL2 filesystem:
```bash
cd ~ # /home/user (fast)
git clone ...
```

### 11. Adding `--security-opt=no-new-privileges` Without Testing sudo

**Mistake** (October 2025 field finding):
```json
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_ADMIN",
 "--security-opt=no-new-privileges" // Breaks sudo!
 ],
 "postStartCommand": "sudo /usr/local/bin/init-firewall.sh"
}
```

**Error**:
```bash
sudo: The "no new privileges" flag is set, which prevents sudo from running as root.
[215179 ms] postStartCommand from devcontainer.json failed with exit code 1.
```

**Why it breaks**:
- The `--security-opt=no-new-privileges` flag prevents ALL privilege escalation
- This includes `sudo` (which needs to escalate from user to root)
- Any lifecycle hooks using `sudo` will fail silently
- Container appears to start but initialization scripts don't run

**Real-world impact**:
- Firewall configuration fails (no network restrictions applied)
- MCP server setup doesn't complete
- Database initialization skipped
- Devcontainer unusable despite successful build

**Fix**:

**Option 1: Remove the flag** (recommended if you need sudo):
```json
{
 "runArgs": [
 "--cap-drop=ALL",
 "--cap-add=NET_ADMIN",
 "--cap-add=NET_RAW",
 "--cap-add=SETUID", // Required for sudo
 "--cap-add=SETGID" // Required for sudo
 // no-new-privileges removed
 ]
}
```

**Option 2: Move root operations to build-time**:
```dockerfile
# Dockerfile - do everything requiring root at build time
RUN /usr/local/bin/init-firewall.sh && \
 iptables-save > /etc/iptables/rules.v4

# devcontainer.json - restore without sudo
{
 "postStartCommand": "iptables-restore < /etc/iptables/rules.v4"
}
```

**Lesson**: Don't blindly apply security hardening flags from generic Docker guides without testing with your specific devcontainer use case.

### 12. Not Upgrading npm in Dockerfile

**Mistake**:
```dockerfile
FROM node:22
# Assumes npm is latest (it's not!)
RUN npm install -g @anthropic-ai/claude-code@latest
```

**Problem**:
- `node:22` ships with npm from its build date (e.g., npm 10.8.2)
- Latest npm might be 10.9.2+ with bug fixes and security patches
- `apt-get update` won't upgrade npm (it's not an apt package)

**Real-world notification**:
```bash
npm notice New patch version of npm available! 10.8.2 -> 10.9.2
npm notice Run `npm install -g npm@10.9.2` to update!
```

**Fix**:
```dockerfile
FROM node:22

# ALWAYS upgrade npm first (in Dockerfile is OK)
RUN npm install -g npm@latest

# CLI tools installed via postCreateCommand (best practice)
# See devcontainer.json below
ENV NPM_CONFIG_PREFIX=/home/node/.npm-global
ENV PATH=$PATH:/home/node/.npm-global/bin
USER node
```

```json
// devcontainer.json
{
  "build": {"dockerfile": "Dockerfile"},
  "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest",
  "mounts": [
    "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume"
  ]
}
```

**Why it matters**:
- Security vulnerabilities patched in newer npm versions
- Performance improvements (faster installs, better caching)
- Bug fixes for obscure edge cases
- postCreateCommand avoids volume persistence conflicts (installs AFTER volumes mount)
- Takes 10 seconds during build, saves hours of debugging later

### 13. Not Using BuildKit Cache Mounts (Slow Rebuilds)

**Mistake**:
```dockerfile
# Redownloads 500MB+ of packages on EVERY rebuild
RUN apt-get update && apt-get install -y \
 chromium \
 build-essential \
 git
```

**Result**:
- First build: 10 minutes
- Rebuild after changing ONE line: 10 minutes (redownloads everything)
- Team members frustrated by slow iteration

**Fix**:
```dockerfile
# Caches packages, only downloads new/changed ones
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
 --mount=type=cache,target=/var/lib/apt/lists,sharing=locked \
 apt-get update && apt-get install -y \
 chromium \
 build-essential \
 git \
 && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**Performance improvement**:
- First build: 10 minutes (same)
- Subsequent rebuilds: 2 minutes (5x faster!)
- Over 10 rebuilds: Saves 80 minutes

**When you notice this**:
- Frequent Dockerfile changes (debugging, adding tools)
- Team complaining about slow devcontainer builds
- Seeing "Downloading..." repeatedly for same packages

### 14. Missing `"init": true` for Process Management

**Mistake**:
```json
{
 "name": "My Devcontainer",
 "build": {"dockerfile": "Dockerfile"}
 // Missing init process manager
}
```

**Symptoms**:
- Zombie processes accumulate (`<defunct>` in `ps aux`)
- Signals not properly forwarded (Ctrl+C doesn't work as expected)
- Background processes don't clean up
- Container shutdown takes longer than expected

**Fix**:
```json
{
 "name": "My Devcontainer",
 "init": true, // Enables tini process manager
 "build": {"dockerfile": "Dockerfile"}
}
```

**What `"init": true` does**:
- Adds `tini` or similar init process as PID 1
- Properly reaps zombie processes
- Forwards signals correctly (SIGTERM, SIGINT)
- Ensures clean container shutdown

**Verification**:
```bash
# Inside container with init: true
ps aux | head -2
# Should see: tini or /bin/sh or node as PID 1 (not your app directly)

# Without init: true
ps aux | head -2
# Might see: your app as PID 1 (problematic)
```

**When to ALWAYS use**:
- Containers running long-lived processes
- Containers with background jobs
- Devcontainers where you run tests frequently
- Production-like development environments

**Modern devcontainer best practice**: Always include `"init": true` unless you have a specific reason not to.

### 15. Setting Ownership on Subdirectory Instead of Parent Directory

**Mistake**:
```dockerfile
# Create multiple subdirectories under .config
RUN mkdir -p /home/node/.config/gh /home/node/.config/other && \
  chown -R node:node /home/node/.config/gh  # Only sets ownership on subdirectory!
```

**Error**:
```
mkdir: cannot create directory '/home/node/.config/fish': Permission denied
ERROR: command failed: mkdir -p /home/node/.config/fish
```

**Root Cause**:
- `mkdir -p /home/node/.config/gh` creates both `/home/node/.config` AND `/home/node/.config/gh`
- Parent directory `.config` is owned by root (default)
- `chown` only sets ownership on the subdirectory (`.config/gh`)
- Later installers (e.g., `uv` for Python) try to create their own subdirectories under `.config` (e.g., `.config/fish`)
- Non-root user cannot create new directories in root-owned parent directory

**Real-world impact**:
- Docker build fails during tool installation (uv, fish, other shell configs)
- Error appears late in build process, wasting time on preceding steps
- Multiple tools affected: any installer needing to create config subdirectories

**Fix**:
```dockerfile
# Set ownership on parent directory, not just subdirectory
RUN mkdir -p /home/node/.config/gh /home/node/.config/other && \
  chown -R node:node /home/node/.config  # Owns entire .config tree
```

**Why this works**:
- `chown -R` on parent directory sets ownership recursively on all existing AND future subdirectories
- When non-root user creates new subdirectories, they inherit proper ownership
- Single ownership command covers all config subdirectories (gh, fish, npm, etc.)

**Verification**:
```bash
# Check ownership of parent directory
ls -ld /home/node/.config
# Should show: drwxr-xr-x node node

# Check ownership of subdirectories
ls -la /home/node/.config/
# All subdirectories should show: node node

# Test creating new subdirectory as node user
su - node -c "mkdir -p /home/node/.config/test"
# Should succeed without permission errors
```

**Pattern to remember**:
- ❌ `chown -R user:user /path/parent/child` (only owns child)
- ✅ `chown -R user:user /path/parent` (owns parent + all children)

**When you see this**:
- Permission errors during `RUN` commands that create files in `~/.config`
- Installers like `uv`, `fish`, `zsh` failing with "Permission denied"
- Build succeeds up to a certain point, then fails on config directory creation

---

## Quick Reference

### Essential Commands

```bash
# Open project in devcontainer
code /path/to/project

# Rebuild container
# Command Palette → "Dev Containers: Rebuild Container"

# List running containers
docker ps

# View container logs
docker logs <container-id>

# Execute command in container
docker exec -it <container-id> bash

# Clean up Docker resources
docker system prune # Safe (removes stopped containers, unused images)
docker system prune -a --volumes # Nuclear (removes EVERYTHING)
```

### File Checklist

- [ ] `.devcontainer/devcontainer.json` (required)
- [ ] `.devcontainer/Dockerfile` (required)
- [ ] `.devcontainer/init-claude-config.sh` (optional, MCP automation)
- [ ] `.devcontainer/mcp.json.template` (optional, MCP servers)
- [ ] `.devcontainer/settings.json.template` (optional, Claude settings)
- [ ] `.devcontainer/init-firewall.sh` (optional, security)

### Minimal Working Example

**devcontainer.json**:
```json
{
 "name": "Claude Code",
 "build": {"dockerfile": "Dockerfile"},
 "customizations": {
 "vscode": {"extensions": ["anthropic.claude-code"]}
 },
 "postCreateCommand": "npm install -g @anthropic-ai/claude-code@latest",
 "remoteUser": "node",
 "mounts": [
  "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
  "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume",
  "source=npm-global-${devcontainerId},target=/home/node/.npm-global,type=volume"
 ]
}
```

**Dockerfile**:
```dockerfile
FROM node:22
RUN apt-get update && apt-get install -y git && apt-get clean
USER node
# Claude Code installed via postCreateCommand (after npm-global volume mounts)
ENV NPM_CONFIG_PREFIX=/home/node/.npm-global
ENV PATH=$PATH:/home/node/.npm-global/bin
RUN git config --global core.excludesfile ~/.gitignore_global && \
 echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

### Official Resources

- **Claude Code Devcontainers**: https://docs.claude.com/en/docs/claude-code/devcontainer
- **VS Code Devcontainers**: https://code.visualstudio.com/docs/devcontainers/containers
- **Docker Documentation**: https://docs.docker.com/
- **MCP Protocol**: https://modelcontextprotocol.io
- **Dev Containers Spec**: https://containers.dev/

---

## Multi-Container Patterns (Docker Compose)

For complex setups (app + database + cache), use Docker Compose with devcontainers.

**Official Docker Compose Documentation**: https://docs.docker.com/compose/compose-file/
**Dev Container Compose Spec**: https://containers.dev/implementors/json_reference/#compose-specific

### Example: Next.js + PostgreSQL + Redis

**Create `docker-compose.yml` (in project root)**:

```yaml
version: '3.8'
services:
 app:
 build:
 context: .
 dockerfile: .devcontainer/Dockerfile
 volumes:
 - .:/workspaces/my-app:cached
 command: sleep infinity
 environment:
 DATABASE_URL: postgresql://postgres:postgres@db:5432/myapp
 REDIS_URL: redis://redis:6379
 depends_on:
 - db
 - redis

 db:
 image: postgres:15
 environment:
 POSTGRES_USER: postgres
 POSTGRES_PASSWORD: postgres
 POSTGRES_DB: myapp
 volumes:
 - postgres-data:/var/lib/postgresql/data

 redis:
 image: redis:7-alpine
 volumes:
 - redis-data:/data

volumes:
 postgres-data:
 redis-data:
```

**Update devcontainer.json**:

```json
{
 "name": "Next.js Full Stack",
 "dockerComposeFile": "../docker-compose.yml",
 "service": "app",
 "workspaceFolder": "/workspaces/my-app",
 "customizations": {
 "vscode": {
 "extensions": ["anthropic.claude-code"]
 }
 },
 "forwardPorts": [3000, 5432, 6379],
 "postStartCommand": "npm install",
 "remoteUser": "node"
}
```

**Key Points**:
- `dockerComposeFile`: Points to docker-compose.yml
- `service`: Which service is the "dev" container (where VS Code connects)
- Services can communicate by service name (`db:5432`, `redis:6379`)
- Separate volumes for databases persist data across restarts

### Testing Multi-Container Setup

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs app
docker-compose logs db

# Connect to database from app container
docker-compose exec app psql $DATABASE_URL

# Stop all services
docker-compose down

# Stop and remove volumes (deletes database data!)
docker-compose down -v
```

---

## DevContainer Features

VS Code devcontainers support a powerful "Features" system for installing common tools without modifying the Dockerfile.

### What Are Features?

**Features** are self-contained, reusable units that install tools and configure the environment. Think of them as "npm packages" for devcontainers.

**Official Feature Registry**: https://containers.dev/features
**Features Specification**: https://containers.dev/implementors/features/
**Features Distribution**: https://containers.dev/implementors/features-distribution/

### Common Features

#### Git

```json
{
 "features": {
 "ghcr.io/devcontainers/features/git:1": {
 "version": "latest",
 "ppa": true
 }
 }
}
```

#### Docker-in-Docker

```json
{
 "features": {
 "ghcr.io/devcontainers/features/docker-in-docker:2": {
 "version": "latest",
 "moby": true
 }
 }
}
```

#### Node.js (Additional Versions)

```json
{
 "features": {
 "ghcr.io/devcontainers/features/node:1": {
 "version": "18"
 }
 }
}
```

#### Python

```json
{
 "features": {
 "ghcr.io/devcontainers/features/python:1": {
 "version": "3.11"
 }
 }
}
```

#### AWS CLI

```json
{
 "features": {
 "ghcr.io/devcontainers/features/aws-cli:1": {
 "version": "latest"
 }
 }
}
```

### Example: Multi-Tool Setup

```json
{
 "name": "Full-Stack Dev",
 "image": "mcr.microsoft.com/devcontainers/base:ubuntu",
 "features": {
 "ghcr.io/devcontainers/features/node:1": {"version": "20"},
 "ghcr.io/devcontainers/features/python:1": {"version": "3.11"},
 "ghcr.io/devcontainers/features/docker-in-docker:2": {},
 "ghcr.io/devcontainers/features/kubectl-helm-minikube:1": {},
 "ghcr.io/devcontainers/features/github-cli:1": {}
 }
}
```

### Features vs. Dockerfile

| Aspect | Features | Dockerfile |
|--------|----------|------------|
| **Ease of use** | Simple JSON | Requires Docker knowledge |
| **Reusability** | Shared across projects | Project-specific |
| **Customization** | Limited to feature options | Full control |
| **Build time** | Often cached | Depends on layer caching |
| **Best for** | Common tools | Custom setups |

### When to Use Features

 **Use Features when:**
- Installing common tools (Git, Docker, AWS CLI, kubectl)
- Sharing configuration across multiple projects
- Want simpler devcontainer.json without Dockerfile

 **Use Dockerfile when:**
- Installing custom/proprietary tools
- Need fine-grained control over installation
- Complex multi-step setup required

### Creating Custom Features

You can create custom features for internal tools:

**Example structure**:
```
my-feature/
├── devcontainer-feature.json
└── install.sh
```

**devcontainer-feature.json**:
```json
{
 "id": "my-custom-tool",
 "version": "1.0.0",
 "name": "My Custom Tool",
 "description": "Installs my custom tool",
 "options": {
 "version": {
 "type": "string",
 "default": "latest"
 }
 }
}
```

**install.sh**:
```bash
#!/bin/bash
set -e

VERSION=${VERSION:-"latest"}
echo "Installing My Custom Tool ${VERSION}..."
# Installation commands here
```

Host in a git repo and reference:
```json
{
 "features": {
 "https://github.com/myorg/devcontainer-features/my-custom-tool": {
 "version": "1.0.0"
 }
 }
}
```

---

## Frequently Asked Questions

### General Questions

**Q: Do I need to rebuild the container every time I change my code?**

No! Your code lives in a volume mount. Only rebuild when:
- Changing `.devcontainer/devcontainer.json`
- Changing `.devcontainer/Dockerfile`
- Adding VS Code extensions
- Installing new system packages

**Q: Can I run devcontainers without VS Code?**

Technically yes (using Dev Container CLI), but VS Code integration is the primary use case. For non-VS Code workflows, consider:
- Docker Compose directly
- GitHub Codespaces
- Docker-based CI/CD

**Q: How much disk space do devcontainers use?**

Typical usage:
- Base container: 500MB-2GB
- Per-project volumes: 50-200MB
- Total for 10 projects: ~5-10GB

Monitor with: `docker system df`

**Q: Can I use devcontainers with GitHub Codespaces?**

Yes! GitHub Codespaces uses the exact same `.devcontainer/` configuration. Your devcontainer works locally and in Codespaces without modification.

**Q: What happens to my data if I delete the container?**

- **Named volumes** (claude-${devcontainerId}): Persist until manually deleted
- **Bind mounts**: Data remains on host
- **Container filesystem**: Deleted with container

Always use volumes for API keys and configs!

**Q: Can I have multiple devcontainers in one project?**

Yes! Create multiple devcontainer.json files:

```
.devcontainer/
├── backend/
│ └── devcontainer.json
├── frontend/
│ └── devcontainer.json
└── devcontainer.json # Default
```

Open with: Command Palette → "Dev Containers: Open Folder in Container" → Select configuration

### Performance Questions

**Q: Why is my devcontainer slow on Mac/Windows?**

File I/O between host and container has overhead on Mac/Windows (not Linux).

**Solutions**:
- Use named volumes instead of bind mounts for dependencies (`node_modules/`, `.venv/`)
- Enable VirtioFS (Mac: Docker Desktop → Experimental Features)
- Store projects in WSL2 filesystem (Windows)

**Q: How can I speed up container builds?**

```dockerfile
# 1. Order layers by change frequency (least → most)
FROM node:22
RUN apt-get update && apt-get install -y git # Rarely changes
COPY package*.json ./ # Changes sometimes
RUN npm install # Changes when package*.json changes
COPY . . # Changes often

# 2. Use build cache
# Command Palette → "Dev Containers: Rebuild Container" (NOT "Rebuild Without Cache")

# 3. Minimize layers
RUN apt-get update && apt-get install -y \
 git \
 curl \
 && apt-get clean && rm -rf /var/lib/apt/lists/* # All in one layer
```

**Q: My container uses too much RAM. How do I limit it?**

```json
{
 "runArgs": [
 "--memory=4g",
 "--memory-swap=4g"
 ]
}
```

### Security Questions

**Q: Is it safe to use --dangerously-skip-permissions?**

**Only in trusted environments**:
- Your own projects in isolated devcontainers with firewall
- CI/CD pipelines with restricted network
- Open-source projects you didn't audit
- Untrusted codebases

The flag bypasses permission prompts, allowing automated execution. Malicious code could exfiltrate your API keys.

**Q: How do I prevent accidentally committing API keys?**

```dockerfile
# In Dockerfile (automatic protection)
RUN git config --global core.excludesfile ~/.gitignore_global && \
 echo ".claude/settings.local.json" > /home/node/.gitignore_global
```

This ensures `.claude/settings.local.json` (which contains API keys) never gets committed.

**Q: Can containers access my host machine?**

Not by default. Containers are isolated unless you explicitly:
- Bind mount host directories (`type=bind`)
- Forward ports
- Add capabilities (`--cap-add`)

Best practice: Only mount what's needed, preferably read-only.

### Multi-AI Questions

**Q: Can I run Claude Code, Copilot, and Gemini in the same container?**

Yes! Install all tools and configure separate volumes:

```dockerfile
RUN npm install -g \
 @anthropic-ai/claude-code@latest \
 @openai/codex \
 @google/gemini-cli
```

```json
{
 "mounts": [
 "source=claude-${devcontainerId},target=/home/node/.claude,type=volume",
 "source=codex-${devcontainerId},target=/home/node/.codex,type=volume",
 "source=gemini-${devcontainerId},target=/home/node/.gemini,type=volume",
 "source=ghub-config-${devcontainerId},target=/home/node/.config/gh,type=volume"
 ]
}
```

Each AI gets isolated API keys and settings. GitHub CLI persists authentication tokens.

**Q: How do I switch between AI assistants?**

Each has its own CLI command:
```bash
claude # Anthropic Claude Code
codex # OpenAI Codex
gemini # Google Gemini CLI
```

Or use VS Code extensions (switch via sidebar).

### Troubleshooting Questions

**Q: "Reopen in Container" button disappeared after I clicked it once. How do I get back?**

The green icon in bottom-left corner of VS Code. Click it → "Reopen in Container"

Or: Command Palette → "Dev Containers: Reopen in Container"

**Q: How do I access my container if VS Code won't connect?**

```bash
# Find container ID
docker ps

# Execute bash inside
docker exec -it <container-id> bash

# Now you can debug from inside
claude --version
ls -la ~/.claude
cat ~/.claude/mcp.json | jq
```

**Q: My Dockerfile builds locally but fails in VS Code. Why?**

VS Code builds from the project root, not `.devcontainer/` directory.

**Fix paths in Dockerfile**:
```dockerfile
# If devcontainer.json has "dockerfile": "Dockerfile"
# Then COPY paths are relative to .devcontainer/

# Good
COPY init-firewall.sh /usr/local/bin/

# Bad
COPY .devcontainer/init-firewall.sh /usr/local/bin/
```

**Q: How do I completely reset a devcontainer?**

```bash
# 1. Remove container
docker ps -a | grep "project-name"
docker rm -f <container-id>

# 2. Remove volumes (CAUTION: Deletes API keys!)
docker volume ls | grep "project-name"
docker volume rm <volume-name>

# 3. Rebuild
# Command Palette → "Dev Containers: Rebuild Container Without Cache"
```

### MCP Questions

**Q: What's the difference between SSE and stdio MCP servers?**

**SSE (Server-Sent Events)**:
- Remote servers (hosted externally)
- Examples: Context7, Cloudflare Docs
- Requires internet
- No local installation

**stdio (Standard Input/Output)**:
- Local processes (npm packages)
- Examples: Chrome DevTools
- Works offline
- Requires npm installation

**Q: Can I use MCP servers without Claude Code?**

MCP is specific to Claude Code. Other AI assistants have their own extension systems:
- Copilot: GitHub Copilot API
- Cursor: Cursor Rules
- Codex: OpenAI Plugins

**Q: My MCP server shows "not responding". What should I check?**

```bash
# For SSE servers
curl -v https://mcp.context7.com/sse # Should respond

# For stdio servers
npx chrome-devtools-mcp@latest --help # Should run

# Check mcp.json syntax
cat ~/.claude/mcp.json | jq # Should parse without errors

# View Claude logs
claude --verbose
```

---

## AI Assistant Guidelines

> **For AI Assistants**: When helping users create or debug devcontainers:

### Decision-Making Framework

1. **Assess User Experience**:
 - Beginner? → Start with minimal example, explain each line
 - Intermediate? → Provide working example with customization options
 - Advanced? → Discuss trade-offs, security implications

2. **Understand Requirements**:
 - What's the primary language? → Choose base image
 - Need databases? → Suggest Docker Compose pattern
 - Security concerns? → Recommend firewall, volume isolation
 - Team environment? → Emphasize reproducibility

3. **Provide Progressive Solutions**:
 - **First**: Minimal working setup (get them running)
 - **Then**: Add features (MCP servers, multi-AI, security)
 - **Finally**: Optimize (caching, performance, cleanup)

4. **Always Include**:
 - UTF-8 locale configuration
 - Volume mounts for `.claude/` (and other AI configs)
 - Git exclusion of `.claude/settings.local.json`
 - Explanation of "why" not just "how"

5. **Test Incrementally**:
 - Suggest testing Dockerfile with `docker build -t test .`
 - Recommend building → testing → adding features → rebuilding
 - Don't give 500-line config without incremental validation

6. **Reference Official Docs**:
 - Link to https://docs.claude.com/en/docs/claude-code/devcontainer
 - Cite VS Code devcontainers docs for advanced features
 - Point to official MCP docs for server configuration

7. **Explain Trade-offs**:
 - Security vs. convenience (firewall vs. open network)
 - Performance vs. disk space (slim images vs. feature-rich)
 - Simplicity vs. robustness (minimal config vs. production-ready)

### Common User Questions (Suggested Responses)

**"How do I add Python to my Node devcontainer?"**
```dockerfile
# In Dockerfile after base image
RUN apt-get update && apt-get install -y \
 python3 \
 python3-pip \
 python3-venv \
 && apt-get clean && rm -rf /var/lib/apt/lists/*
```

**"Can I use my existing Dockerfile?"**
Yes, but recommend separation:
- Production: `Dockerfile` (optimized for size, security)
- Development: `.devcontainer/Dockerfile` (includes dev tools, AI assistants)

**"How do I share my devcontainer with my team?"**
Commit `.devcontainer/` to git. Team members:
1. Pull repo
2. Open in VS Code
3. Click "Reopen in Container"

**"Will this work on Windows?"**
Yes, if using WSL2:
- Docker Desktop → Settings → "Use WSL2 based engine"
- Clone projects into WSL2 filesystem (not `/mnt/c/`), for performance

**"How do I debug build failures?"**
1. Test Dockerfile directly: `docker build -t test .devcontainer/`
2. View full error output (not truncated VS Code log)
3. Use `RUN echo "Checkpoint 1"` to isolate failing line
4. Check [Step-by-Step Debug Process](#step-by-step-debug-process)

**"Should I use devcontainers for [X]?"**
- Multi-developer teams
- Projects with complex dependencies
- Security-sensitive work (client projects)
- Cross-platform development
- Simple scripts (overkill)
- GPU-intensive ML (complex setup)
- GUI desktop apps

---

**Document Version**: 2.0
**Last Updated**: 2025-10
**Maintained By**: Community
**License**: MIT
**Feedback**: https://github.com/anthropics/claude-code/discussions

---

> **For AI Assistants**: You've reached the end of this comprehensive guide. Remember:
> - **Understand before implementing** - Ask clarifying questions
> - **Start simple, iterate** - Don't overwhelm with 500-line configs
> - **Explain trade-offs** - Security, performance, complexity
> - **Test incrementally** - Build → Test → Add feature → Rebuild
> - **Reference official docs** - https://docs.claude.com/en/docs/claude-code/devcontainer
> - **Prioritize user success** - Working devcontainer > perfect devcontainer

**Your goal**: Help users achieve a **working devcontainer** that solves their problem, not to showcase every advanced feature.
